

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>4.1 Grid approximation 网格近似 &#8212; Bayesian Inference with Python</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter4/chapter4_part2';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Leture6: MCMC" href="../chapter5/chapter5_part1.html" />
    <link rel="prev" title="Lecture 5: Bayesian Inference: From Traditional Foundations to Current Practices" href="chapter4_part1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../chapter_overview/intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Bayesian Inference with Python - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Bayesian Inference with Python - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../chapter_overview/intro.html">
                    序言
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">0. 课程概述</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_overview/Part1.html">为什么要学习贝叶斯推断?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_overview/Part2.html">贝叶斯推断的三个例子</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_overview/Part3.html">本课程的主要内容与形式</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">1. 初识贝叶斯法则(Bayes'Rule)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter1_Bayesrule/Bayesrule_part1.html">1.0 本课程演示平台: 和鲸平台</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter1_Bayesrule/Bayesrule_part2.html">1.1 单一事件的贝叶斯模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter1_Bayesrule/Bayesrule_part3.html">1.2 随机变量的贝叶斯模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter1_Bayesrule/Bayesrule_part4.html">1.3 贝叶斯与频率主义的简单对比</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">2. 一个真正的贝叶斯模型——Beta-Binomial Model</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter2_Beta_Binomial/BetaBinomial_part1.html">2.0 先验分布: Beta分布</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter2_Beta_Binomial/BetaBinomial_part2.html">2.1 似然函数: Binomial分布</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter2_Beta_Binomial/BetaBinomial_part3.html">2.2 后验分布</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter2_Beta_Binomial/BetaBinomial_part4.html">2.3 通过模拟可视化来观察模型</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">3. Balance and Sequentiality in Bayesian Analyses</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter3/Lecture4_part1.html">3.0 回顾Bayes'Rule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter3/Lecture4_part2.html">3.1 不同数据对后验的影响</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter3/Lecture4_part3.html">3.2 不同似然对后验的影响</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter3/Lecture4_part4.html">3.3 不同先验对后验的影响</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">4. Bayesian Inference:From Traditional Foundations to Current Practices</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="chapter4_part1.html">4.0 内容回顾</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">4.1 Grid approximation 网格近似</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">5. Markov Chain Monte Carlo(MCMC)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter5/chapter5_part1.html">5.0 Monte Carlo &amp; Markov Chain</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter5/chapter5_part2.html">5.1 Metropolis-Hastings(MH)算法</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">6. Posterior Inference &amp; Estimation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter6/chapter6_part1.html">6.0 A Beta-Binomial example in pymc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter6/chapter6_part2.html">6.1 MCMC诊断</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">7. A Simple Linear Regression Model with PyMC</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter7/chapter7_part1.html">7.0 贝叶斯一般线性回归模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter7/chapter7_part2.html">7.1 先验预测</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter7/chapter7_part3.html">7.2 后验预测</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/hcp4715/PyBayesianBook" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/hcp4715/PyBayesianBook/issues/new?title=Issue%20on%20page%20%2Fchapter4/chapter4_part2.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapter4/chapter4_part2.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>4.1 Grid approximation 网格近似</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">4.1 Grid approximation 网格近似</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-beta-binomial-example">A Beta-Binomial example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">示例：网络近似估计后验分布</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step1">Step1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step2-3">Step2&amp;3</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step4">Step4</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">练习</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">模型设定</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mu-sigma">增加难度：估计<span class="math notranslate nohighlight">\(\mu\)</span> 和 <span class="math notranslate nohighlight">\(\sigma\)</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">网格近似的局限性</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#markov-chain-monte-carlo-mcmc">Markov chain Monte Carlo(MCMC)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mcmc">MCMC 的采样特点</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="grid-approximation">
<h1>4.1 Grid approximation 网格近似<a class="headerlink" href="#grid-approximation" title="Permalink to this heading">#</a></h1>
<p><img alt="alt text" src="../_images/image-42.png" /></p>
<blockquote>
<div><ul class="simple">
<li><p>想象有一张图像(图三)，但你不能完整地看到它。不过你可以从左到右每次取一个这个图像中的一个小格来观察它。</p></li>
<li><p>只要格子越细，最后组合在一起就会与完整的图片更近似</p></li>
</ul>
</div></blockquote>
<p>在网格近似中，后验分布<span class="math notranslate nohighlight">\(f(θ|y)\)</span>其实就是完整的图片。我们可以选择有限个<span class="math notranslate nohighlight">\(θ\)</span>，并观察对应的<span class="math notranslate nohighlight">\(f(θ|y)\)</span>，以此来近似完整的后验分布。</p>
<ul class="simple">
<li><p>以一个参数为例，网络近似可以分为以下四个步骤：</p></li>
</ul>
<p>1.选定一系列离散的<span class="math notranslate nohighlight">\(θ\)</span>值</p>
<p>2.计算每个<span class="math notranslate nohighlight">\(θ\)</span>值对应的先验分布<span class="math notranslate nohighlight">\(f(θ)\)</span>和似然函数<span class="math notranslate nohighlight">\(L(θ|y)\)</span></p>
<p>3.对于所有的<span class="math notranslate nohighlight">\(θ\)</span>值，计算<span class="math notranslate nohighlight">\(f(θ)\)</span>和<span class="math notranslate nohighlight">\(L(θ|y)\)</span>二者的乘积并相加，再进行归一化</p>
<p>4.归一化后，根据<span class="math notranslate nohighlight">\(θ\)</span>值的后验概率分布，随机抽取N个<span class="math notranslate nohighlight">\(θ\)</span>值</p>
<section id="a-beta-binomial-example">
<h2>A Beta-Binomial example<a class="headerlink" href="#a-beta-binomial-example" title="Permalink to this heading">#</a></h2>
<p>假设先验<span class="math notranslate nohighlight">\(\pi\)</span>服从Beta分布：</p>
<div class="math notranslate nohighlight">
\[
\pi \sim Beta(\alpha=70,\beta=30)
\]</div>
<p>似然函数：</p>
<div class="math notranslate nohighlight">
\[
Y|\pi \sim Bin(n,\pi)
\]</div>
<ul class="simple">
<li><p>假设<span class="math notranslate nohighlight">\(\pi\)</span>反映的是正确率，似然函数反映的则是在某个正确率下，总trial为100次时，正确次数的分布概率情况。</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\pi \sim \text{Beta}(70, 30)
\]</div>
<div class="math notranslate nohighlight">
\[
Y|\pi \sim \text{Bin}(100, \pi)
\]</div>
<ul class="simple">
<li><p>在观察到<span class="math notranslate nohighlight">\(n\)</span>次事件中有<span class="math notranslate nohighlight">\(Y=y\)</span>次目标事件后，<span class="math notranslate nohighlight">\(\pi\)</span>的后验分布可以用<span class="math notranslate nohighlight">\(Beta\)</span>模型来描述，反映了先验<span class="math notranslate nohighlight">\(（通过\alpha和\beta）\)</span>和数据<span class="math notranslate nohighlight">\((通过y和n)\)</span>的影响：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\pi | (Y = y) \sim \text{Beta}(\alpha + y, \beta + n - y)
\]</div>
<ul class="simple">
<li><p>假设正确次数为90，我们通过共轭先验的公式，可以直接计算出<span class="math notranslate nohighlight">\(Beta\)</span>后验分布的两个参数：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
Y+\alpha=90+70, \beta+n-Y=30+100-90
\]</div>
<div class="math notranslate nohighlight">
\[
\pi|(Y=90)\sim Beta(160,40)
\]</div>
<p>这个结果可以用来对我们使用网络近似的后验进行验证。</p>
</section>
<section id="id1">
<h2>示例：网络近似估计后验分布<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<section id="step1">
<h3>Step1<a class="headerlink" href="#step1" title="Permalink to this heading">#</a></h3>
<p>首先，我们先在0.5到1这个区间内取一系列的值，总共取11个值，也就是每隔0.05取一个。</p>
<div class="math notranslate nohighlight">
\[
\pi \in {0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1}
\]</div>
<p>导入需要的包：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
<p>从0.5到1之间取出11个值：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pi_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;从0.5~1内的连续变量π中取出11个值:&quot;</span><span class="p">,</span> <span class="n">pi_grid</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step2-3">
<h3>Step2&amp;3<a class="headerlink" href="#step2-3" title="Permalink to this heading">#</a></h3>
<p>在每一个<span class="math notranslate nohighlight">\(\pi\)</span>下，计算先验分布<span class="math notranslate nohighlight">\(Beta(70,30)\)</span>，与似然函数<span class="math notranslate nohighlight">\(Bin(100,\pi)(Y=90)\)</span>的乘积，计算总和并进行归一化：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">pi_grid</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="mi">90</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">pi_grid</span><span class="p">)</span>
<span class="n">posterior</span> <span class="o">=</span> <span class="n">prior</span> <span class="o">*</span> <span class="n">likelihood</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">prior</span> <span class="o">*</span> <span class="n">likelihood</span><span class="p">)</span>
</pre></div>
</div>
<p>我们将后验分布可视化出来：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 使用 plt.stem() 绘制垂直柱状图，表示在 pi_grid 上的 posterior 分布</span>
<span class="n">plt</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span>
    <span class="n">pi_grid</span><span class="p">,</span>
    <span class="n">posterior</span><span class="p">,</span>  
    <span class="n">linefmt</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
    <span class="n">bottom</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># 设置 y 轴范围在 0 到 1 之间</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;pi_grid&quot;</span><span class="p">)</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Posterior&quot;</span><span class="p">)</span>  
<span class="c1"># 去除图形的上方和右侧的边框</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</pre></div>
</div>
<center><img width = '450' height ='300' src="image-5.png">
</center>
<p>图中每个黑点就是<span class="math notranslate nohighlight">\(\pi\)</span>的取值，分别计算出后验概率，对他进行归一化，最后就得到了后验分布。但这个分别和我们真正的后验分布还差的很多，因此我们可以进一步进行可视化。</p>
</section>
<section id="step4">
<h3>Step4<a class="headerlink" href="#step4" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>得到后验结果<span class="math notranslate nohighlight">\((π)\)</span>的分布后，从这个分布中抽样10000次，对后验进行可视化。</p></li>
</ul>
<p>从上图可以看出，<span class="math notranslate nohighlight">\(\pi=0.8\)</span>的后验概率显著高于其他点，所以大多数样本会集中在<span class="math notranslate nohighlight">\(\pi=0.8\)</span>附近。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">84735</span><span class="p">)</span>

<span class="c1">#  从 posterior 分布中抽取 10000 个样本</span>
<span class="n">posterior_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
    <span class="n">pi_grid</span><span class="p">,</span> 
    <span class="n">size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
    <span class="n">p</span><span class="o">=</span><span class="n">posterior</span><span class="p">,</span>  
    <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># 将抽取的样本存储在 DataFrame 中，列名为 &quot;pi_sample&quot;</span>
<span class="n">posterior_sample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span><span class="s2">&quot;pi_sample&quot;</span><span class="p">:</span> <span class="n">posterior_sample</span><span class="p">}</span>
<span class="p">)</span>  

<span class="c1"># 对 posterior_sample 中的样本进行计数，并使用 normalize=True 将计数转换为相对频率</span>
<span class="n">posterior_sample</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span>
    <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="alt text" src="../_images/image-62.png" /></p>
<p><strong>抽样结果图示</strong></p>
<p>抽样结果显示，<span class="math notranslate nohighlight">\(π\)</span>大多数集中在 0.80 附近，少部分在 0.75 和 0.85 附近。</p>
<ul class="simple">
<li><p>接下来，我们可以将抽样得到的后验分布与理论上的<span class="math notranslate nohighlight">\(Beta\)</span>分布<span class="math notranslate nohighlight">\(Beta(160,40)\)</span>进行对比，以检验抽样的准确性。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x_beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>  <span class="c1"># 生成10000 个点，范围在 [0, 1] 之间</span>

<span class="n">y_beta</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_beta</span><span class="p">,</span> <span class="mi">160</span><span class="p">,</span> <span class="mi">40</span><span class="p">)</span>  <span class="c1"># 生成 Beta(160,40)</span>

<span class="c1"># 绘制共轭方法计算得到的后验 beta(160,40)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_beta</span><span class="p">,</span> <span class="n">y_beta</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;posterior of conjucated distribution&quot;</span><span class="p">)</span> 

<span class="c1"># 绘制网格方法抽样后得到的结果</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span>
    <span class="n">posterior_sample</span><span class="p">[</span><span class="s2">&quot;pi_sample&quot;</span><span class="p">],</span>  
    <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;posterior of grid search&quot;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="alt text" src="../_images/image-71.png" /></p>
<p>这里可以看出，网络近似得到的后验分布与<span class="math notranslate nohighlight">\(Beta(160,40)\)</span>具有几分相似，但由于取值较少，形状上还差的较多，因此我们增大取值的个数。</p>
<p><strong>增加网格数</strong></p>
<ul class="simple">
<li><p>这个结果当然过度简化了后验分布，还记得我们刚刚提到，只要取的网格越多，对后验的估计会更准确。</p></li>
<li><p>那么，现在<span class="math notranslate nohighlight">\(\pi\)</span>不取11个值，而是在0~1之间取101个值(每隔0.01取1个)</p></li>
<li><p>同样，我们执行上述4个步骤：</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 生成一个 101 个点，范围在 [0, 1] 之间</span>
<span class="n">pi_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">101</span><span class="p">)</span>  
<span class="c1"># 生成 Beta(70,30)</span>
<span class="n">prior</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">pi_grid</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>  

<span class="c1"># 生成二项分布, 参数为 n=100（总试验次数），k=90（正确次数），以及 pi_grid 中的每个概率值</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span>
    <span class="mi">90</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">pi_grid</span>
<span class="p">)</span>  

<span class="c1"># 计算后验概率，即先验概率和似然函数的乘积，然后除以归一化常数（分母和）</span>
<span class="n">posterior</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">prior</span> <span class="o">*</span> <span class="n">likelihood</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">prior</span> <span class="o">*</span> <span class="n">likelihood</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 画图</span>
<span class="n">plt</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">pi_grid</span><span class="p">,</span> <span class="n">posterior</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="alt text" src="../_images/image-81.png" /></p>
<p>其实我们要做的就是把likelihood的数量增加即可，甚至可以增加到1001个<span class="math notranslate nohighlight">\(\pi\)</span>值。可以看到，在这次的取样中，<span class="math notranslate nohighlight">\(\pi\)</span>的取值更加多样。</p>
<p>接下来，和上面的步骤一样，从后验中抽取10000个样本形成后验分布：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">84735</span><span class="p">)</span>

<span class="c1"># 从 posterior 分布中抽取 10000 个样本</span>
<span class="n">posterior_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
    <span class="n">pi_grid</span><span class="p">,</span>  
    <span class="n">size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>  
    <span class="n">p</span><span class="o">=</span><span class="n">posterior</span><span class="p">,</span>  
    <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>  

<span class="c1"># 将抽取的样本存储在 DataFrame 中，列名为 &quot;pi_sample&quot;</span>
<span class="n">posterior_sample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span><span class="s2">&quot;pi_sample&quot;</span><span class="p">:</span> <span class="n">posterior_sample</span><span class="p">}</span>
<span class="p">)</span>  

<span class="c1"># 对 posterior_sample 中的样本进行计数，并使用 normalize=True 将计数转换为相对频率</span>
<span class="n">posterior_sample</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span>
    <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>抽样结果图示</strong></p>
<p>对比一下抽样得到的后验分布图 和 实际的后验分布<span class="math notranslate nohighlight">\(Beta(110,30)\)</span></p>
<p>相比于上一次，这一次的结果更加接近真实的后验分布</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 生成一个 10000 个点，范围在 [0, 1] 之间</span>
<span class="n">x_beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>
<span class="c1"># 生成Beta(160,40)  </span>
<span class="n">y_beta</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_beta</span><span class="p">,</span> <span class="mi">160</span><span class="p">,</span> <span class="mi">40</span><span class="p">)</span>  

<span class="c1"># 绘制共轭方法计算得到的后验 beta(160,40)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_beta</span><span class="p">,</span> <span class="n">y_beta</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;posterior of conjucated distribution&quot;</span><span class="p">)</span>  

<span class="c1"># 绘制网格方法抽样后得到的结果</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span>
    <span class="n">posterior_sample</span><span class="p">[</span><span class="s2">&quot;pi_sample&quot;</span><span class="p">],</span>  
    <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;posterior of grid search&quot;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="alt text" src="../_images/image-91.png" /></p>
<ul class="simple">
<li><p>大家可以看到，网络近似获得的后验分布已经非常接近共轭分布。如果继续增大网格数，那么会越来越接近。</p></li>
</ul>
</section>
</section>
<section id="id2">
<h2>练习<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><p>📃以Normal-Normal模型为例来练习网格近似</p>
</div></blockquote>
<p>在 Normal-Normal 模型 中，观测数据和参数之间的关系是通过正态分布来表示的。</p>
<section id="id3">
<h3>模型设定<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>假设<span class="math notranslate nohighlight">\(\mu\)</span>是参与者在随机点运动任务中的平均反应时间（单位：ms）,<span class="math notranslate nohighlight">\(\sigma\)</span>是参与者在随机点运动任务中的标准差（单位：ms）。</p></li>
<li><p>先验分布设为正态分布，我们假设参与者的平均反应时间约为 500 ms，标准差为 100 ms。</p></li>
</ul>
<blockquote>
<div><p>对于<span class="math notranslate nohighlight">\(\mu\)</span>，其先验分布为<span class="math notranslate nohighlight">\(\mu \sim Normal(500,200)\)</span>
对于<span class="math notranslate nohighlight">\(\sigma\)</span>，其先验分布为<span class="math notranslate nohighlight">\(\sigma \sim Normal(100,50)\)</span></p>
</div></blockquote>
<ul class="simple">
<li><p>观测数据<span class="math notranslate nohighlight">\(Y\)</span>表示参与者在实验中实际的反应时。假设我们收集了被试完成 10 次实验的反应时。</p></li>
<li><p>例如 [691., 582., 628., 729., 699., 472., 626., 538., 542., 583.] ms。</p></li>
</ul>
<p>目标：通过网络近似法计算<span class="math notranslate nohighlight">\(\mu\)</span>的后验分布。</p>
<div class="math notranslate nohighlight">
\[
Y_i|\mu \stackrel{ind}{\sim} Normal(\mu,\sigma^2)
\]</div>
<div class="math notranslate nohighlight">
\[
\mu \sim Normal(\mu_0,\sigma^2_0)
\]</div>
<div class="math notranslate nohighlight">
\[
\sigma \sim Normal(\mu_1,\sigma^2_1)
\]</div>
<p>首先，我们仅考虑只有一种参数的情况。 即假设我们已知<span class="math notranslate nohighlight">\(\sigma\)</span>为80，而<span class="math notranslate nohighlight">\(\mu\)</span>未知。</p>
<p><span class="math notranslate nohighlight">\(\mu\)</span>的先验为正态分布，即<span class="math notranslate nohighlight">\(N(500,200)\)</span></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># 生成模拟数据</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">550</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><p>代码解释：numpy一般用于数值计算或者矩阵相关的计算；st包主要用来做一些统计分析；plt则是用来绘图的包。
np.random.seed(0)则是设置一个随机种子，确保后续根据这一seed进行复制。
接下来，生成了一个模拟数据data，loc=550代表均值为550，scale=80代表标准差为80，size=10代表生成一个包含10个元素的数组。</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 展示数据</span>
<span class="n">data</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>输出：array([691., 582., 628., 729., 699., 472., 626., 538., 542., 583.])</p>
<blockquote>
<div><p>这里的round()是指保留小数点的几位，（0）就是指整数</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">##---------------------------------------------------------------------------</span>
<span class="c1">#                            设置网格范围和步长</span>
<span class="c1">#                            1. 假设被试反应的反应时范围为 200 到 800 ms</span>
<span class="c1">#                            2. 设定网格步长为10 (后续可以修改为20,50,100等)</span>
<span class="c1"># ---------------------------------------------------------------------------</span>
<span class="c1"># mu_grid = np.linspace(..., ..., 20)</span>
</pre></div>
</div>
<blockquote>
<div><p>这个mu_grid就是一个在下限200上限800的范围内包含了20个数的数组，是一个一维的数据。</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">##---------------------------------------------------------------------------</span>
<span class="c1">#                            计算先验概率</span>
<span class="c1">#                            1. 设定先验概率服从正态分布</span>
<span class="c1">#                            2. 先验均值为500, 标准差为100</span>
<span class="c1"># ---------------------------------------------------------------------------</span>
<span class="c1"># prior_mean = ... </span>
<span class="c1"># prior_std = ...</span>
</pre></div>
</div>
<blockquote>
<div><p>我们之前假设先验概率是服从正态分布的，因此这里的均值填500，标准差填100。接下来我们要计算先验分布的概率，应当为：prior_prob = st.norm.pdf(mu_grid, loc=prior_mean, scale=prior_std)</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">##---------------------------------------------------------------------------</span>
<span class="c1">#                            计算似然函数</span>
<span class="c1"># ---------------------------------------------------------------------------</span>
<span class="c1"># likelihood = ...</span>
</pre></div>
</div>
<blockquote>
<div><p>首先，似然函数是对每一个观测数据的可能性，前面的网格个数不止一个值，它是很多个值一起的联合概率，因此这里的for循环相当于从mu_grid中抽出每一个<span class="math notranslate nohighlight">\(\mu\)</span>，我们的likelihood应当是：
likelihood = np.array(
[np.prod(st.norm.pdf(data, loc=mu, scale=80) for mu in mu_grid)]
)</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">##---------------------------------------------------------------------------</span>
<span class="c1">#                            计算后验</span>
<span class="c1"># ---------------------------------------------------------------------------</span>
<span class="c1"># posterior_prob = ...</span>

<span class="c1"># 归一化后验概率</span>
</pre></div>
</div>
<blockquote>
<div><p>后验应当是：posterior_prob = prior_prob * likelihood
归一化后验概率：posterior_prob /=np.sum(posterior_prob)</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">##---------------------------------------------------------------------------</span>
<span class="c1">#                            计算找到后验概率的最大值对应的参数</span>
<span class="c1"># ---------------------------------------------------------------------------</span>
<span class="c1"># max_posterior = ...</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;最大后验概率对应的参数值：&quot;</span><span class="p">,</span> <span class="n">theta_grid</span><span class="p">[</span><span class="n">max_posterior</span><span class="p">])</span>
</pre></div>
</div>
<blockquote>
<div><p>这里我们使用np.argmax()，它能够用于找到数组中最大值的一个索引位置。
因此，应当是：max_posterior = np.argmax(posterior_prob)</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 绘制结果</span>
<span class="c1">#plt.plot(x,y)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mu_grid</span><span class="p">,</span> <span class="n">prior_prob</span> <span class="o">/</span> <span class="n">prior_prob</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;prior&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mu_grid</span><span class="p">,</span> <span class="n">posterior_prob</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;posterior of grid method&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">posterior_prob</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;true data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Grid search posterior distribution&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$\mu$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Density&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="alt text" src="../_images/image-101.png" /></p>
<blockquote>
<div><p>plt.vlines是绘制垂直线，x轴对应的是均值，最低点是y轴的0值，最高点是max。
plt.legend是指集中显示图例，也就是左上角的小方块。</p>
</div></blockquote>
<ul class="simple">
<li><p>通过设置不同的网格数，大家可以观察一下后验分布的变化，例如将网格数增加到100，200等等。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">##---------------------------------------------------------------------------</span>
<span class="c1">#                            通过共轭方法计算后验概率 (具体算法见补充材料)</span>
<span class="c1"># ---------------------------------------------------------------------------</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span><span class="mi">800</span><span class="p">,</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">prior_mean</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">prior_variance</span> <span class="o">=</span> <span class="mi">200</span><span class="o">**</span><span class="mi">2</span>
<span class="n">sigma2</span> <span class="o">=</span> <span class="mi">80</span><span class="o">**</span><span class="mi">2</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>  <span class="c1"># 观测数据的数量</span>
<span class="n">posterior_mean</span> <span class="o">=</span> <span class="p">(</span><span class="n">prior_mean</span> <span class="o">/</span> <span class="n">prior_variance</span> <span class="o">+</span> <span class="n">data</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">sigma2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">prior_variance</span> <span class="o">+</span> <span class="n">n</span> <span class="o">/</span> <span class="n">sigma2</span><span class="p">)</span>
<span class="n">posterior_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="mi">1</span> <span class="o">/</span> <span class="n">prior_variance</span> <span class="o">+</span> <span class="n">n</span> <span class="o">/</span> <span class="n">sigma2</span><span class="p">)</span><span class="o">**-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">posterior_conjucate</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">posterior_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">posterior_std</span><span class="p">)</span>

<span class="c1"># 绘制结果</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">posterior_conjucate</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;posterior of conjucated method&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">posterior_conjucate</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;true data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Conjucated posterior distribution&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$\mu$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Density&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="mu-sigma">
<h3>增加难度：估计<span class="math notranslate nohighlight">\(\mu\)</span> 和 <span class="math notranslate nohighlight">\(\sigma\)</span><a class="headerlink" href="#mu-sigma" title="Permalink to this heading">#</a></h3>
<p>上面只考虑了估计<span class="math notranslate nohighlight">\(\mu\)</span>参数，下面我们增加难度，增加考虑估计<span class="math notranslate nohighlight">\(\sigma\)</span>参数。</p>
<p>我们假设<span class="math notranslate nohighlight">\(\mu\)</span>和<span class="math notranslate nohighlight">\(\sigma\)</span>的先验服从正态分布，即：</p>
<ul class="simple">
<li><p>对于<span class="math notranslate nohighlight">\(\mu\)</span>，其先验分布为<span class="math notranslate nohighlight">\(\mu \sim Normal(500,200)\)</span></p></li>
<li><p>对于<span class="math notranslate nohighlight">\(\sigma\)</span>，其先验分布为<span class="math notranslate nohighlight">\(\sigma \sim Normal(100,50)\)</span></p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">##---------------------------------------------------------------------------</span>
<span class="c1">#                            设置网格范围和步长</span>
<span class="c1">#                            1. 假设被试反应的反应时范围为 200 到 800 ms</span>
<span class="c1">#                            2. 假设被试反应时的方差范围为 20 到 200</span>
<span class="c1"># ---------------------------------------------------------------------------</span>
<span class="n">n_step</span> <span class="o">=</span> <span class="mi">20</span>
<span class="c1"># mean_grid = ...  请补充...</span>
<span class="c1"># std_grid = ...   请补充...</span>

<span class="n">mean_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">800</span><span class="p">,</span> <span class="n">n_step</span><span class="p">)</span>
<span class="n">std_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="n">n_step</span><span class="p">)</span>
<span class="n">mean_mesh</span><span class="p">,</span> <span class="n">std_mesh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">mean_grid</span><span class="p">,</span> <span class="n">std_grid</span><span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><p>由于我们现在要估计两个参数，因此需要利用np.meshgrid()生成一个二维坐标矩阵。</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">##---------------------------------------------------------------------------</span>
<span class="c1">#                            计算先验概率</span>
<span class="c1">#                            1. 设定先验概率服从正态分布</span>
<span class="c1">#                            2. 先验均值为500，标准差为100</span>
<span class="c1"># ---------------------------------------------------------------------------</span>

<span class="c1"># prior_mean = ...        </span>
<span class="c1"># prior_std = ...         </span>
<span class="n">prior_mean_mean</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">prior_mean_std</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">prior_std_mean</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">prior_std_std</span> <span class="o">=</span> <span class="mi">50</span>

<span class="n">prior_mean</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">mean_mesh</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">prior_mean_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">prior_mean_std</span><span class="p">)</span>
<span class="n">prior_std</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">std_mesh</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">prior_std_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">prior_std_std</span><span class="p">)</span>
<span class="n">prior_grid</span> <span class="o">=</span> <span class="n">prior_mean</span> <span class="o">*</span> <span class="n">prior_std</span>
<span class="c1"># 显示 prior_grid 的形状</span>
<span class="n">prior_grid</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">##---------------------------------------------------------------------------</span>
<span class="c1">#                            计算似然函数</span>
<span class="c1">#                            1. 先计算一种参数条件下的似然值</span>
<span class="c1">#                            2. 通过for循环计算所有参数条件下的似然值，并储存在likelihood_grid中</span>
<span class="c1"># ---------------------------------------------------------------------------</span>
<span class="c1"># likelihood_single = ...</span>
<span class="c1"># likelihood_grid = np.zeros((n_step, n_step))</span>

<span class="c1">#定义一个全0矩阵</span>
<span class="n">likelihood_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_step</span><span class="p">,</span> <span class="n">n_step</span><span class="p">))</span>
<span class="k">for</span> <span class="n">mean_index</span><span class="p">,</span> <span class="n">mean</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mean_grid</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">std_index</span><span class="p">,</span> <span class="n">std</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">std_gird</span><span class="p">):</span>
    <span class="n">likelihood_i</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">std</span><span class="p">)</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span>
    <span class="n">likelihood_grid</span><span class="p">[</span><span class="n">mean_index</span><span class="p">,</span> <span class="n">std_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">likelihood_i</span>

<span class="n">likelihood_grid</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">##---------------------------------------------------------------------------</span>
<span class="c1">#                            计算grid的后验概率</span>
<span class="c1"># ---------------------------------------------------------------------------</span>
<span class="c1"># posterior_grid = ...</span>

<span class="n">posterior_grid</span> <span class="o">/=</span> <span class="n">posterior_grid</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>  <span class="c1"># 归一化</span>

<span class="c1"># 显示 posterior_grid 的形状</span>
<span class="n">posterior_grid</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">##---------------------------------------------------------------------------</span>
<span class="c1">#                            计算找到后验概率的最大值对应的参数</span>
<span class="c1"># ---------------------------------------------------------------------------</span>
<span class="c1"># max_idx = ...</span>
<span class="c1"># estimated_mean = ...</span>
<span class="c1"># estimated_std = ...</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Estimated Mean: </span><span class="si">{</span><span class="n">estimated_mean</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Estimated Standard Deviation: </span><span class="si">{</span><span class="n">estimated_std</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 绘制后验概率分布图</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">prior_mean_mean</span><span class="p">,</span> <span class="n">prior_std_mean</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;prior&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">data</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">estimated_mean</span><span class="p">,</span> <span class="n">estimated_std</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;max_posterior&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Mean&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Standard Deviation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Posterior Distribution&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="mi">800</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
<section id="id4">
<h2>网格近似的局限性<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h2>
<p>😎或许你也注意到了，上述模型还是只有一到俩个参数的情况</p>
<p>当模型的参数越来越多时，网格近似就会遇到“维数灾难问题”，例如当参数增加到3个、4个甚至更多。</p>
<p>在这里我们只需要简单理解为：<strong>当模型参数越来越多时，网格近似需要的计算成本也越来越高。</strong></p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="markov-chain-monte-carlo-mcmc">
<h1>Markov chain Monte Carlo(MCMC)<a class="headerlink" href="#markov-chain-monte-carlo-mcmc" title="Permalink to this heading">#</a></h1>
<p>在计算具有多个参数的后验分布时，有一种有效的方法叫做马尔科夫链蒙特卡洛(MCMC)，可以用于模拟和近似后验概率分布。</p>
<p><em><strong>Markov chain</strong></em></p>
<ul class="simple">
<li><p>前一个MC中的Markov 来源于一个俄国数学家的名字 Andrey Markov。</p></li>
<li><p>他研究并提出一种数学方法，被命名为马尔科夫链。用于描述状态空间中经过从一个状态到另一个状态的转换的随机过程。</p></li>
<li><p>该过程要求具备 <strong>“无记忆性”</strong>，即下一状态的概率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关。</p></li>
<li><p>马尔可夫链在机器学习和深度学习中非常广泛，例如分层隐马尔可夫模型HMM (Hidden Markov Model)和卡尔曼滤波模型。</p></li>
</ul>
<p><em><strong>Monte Carlo</strong></em></p>
<ul class="simple">
<li><p>而后一个MC (Monte Carlo)则是一个赌场的名字。据说来自于 20 世纪 40 年代绝密核武器项目的，其中斯坦尼斯拉夫-乌拉姆、约翰-冯-诺伊曼和他们在洛斯阿拉莫斯国家实验室的合作者使用马尔可夫链来模拟和更好地理解中子旅行现象（Eckhardt，1987）。洛斯阿拉莫斯团队将他们的工作称为 “蒙特卡洛”，据说这一选择是受到法国里维埃拉富丽堂皇的蒙特卡洛赌场的启发。</p></li>
</ul>
<section id="mcmc">
<h2>MCMC 的采样特点<a class="headerlink" href="#mcmc" title="Permalink to this heading">#</a></h2>
<p>1、和网格法类似，MCMC并不会从后验分布<span class="math notranslate nohighlight">\(f(\theta |y)\)</span>中直接采样</p>
<p>2、并且区分与网格法，MCMC的样本不是互相独立的——下一个样本值依赖于上一个样本值</p>
<p><img alt="alt text" src="../_images/image-111.png" /></p>
<blockquote>
<div><p>source: <a class="reference external" href="https://zhuanlan.zhihu.com/p/250146007">https://zhuanlan.zhihu.com/p/250146007</a></p>
</div></blockquote>
<p>根据上面这个图例，MCMC主要讲的是如何从一个状态转移到下一个状态。虽然说起来很简单，但状态变多后，转换次数变多后，操作起来就会很复杂。</p>
<p>假设后验分布仍是关于<span class="math notranslate nohighlight">\(\theta\)</span>的分布，{<span class="math notranslate nohighlight">\(\theta^{(1)},\theta^{(2)},....\theta^{(N)}\)</span>}构成了一个长度为N的马尔科夫链</p>
<ul class="simple">
<li><p>其中，<span class="math notranslate nohighlight">\(\theta^{(2)}\)</span>的结果依赖于<span class="math notranslate nohighlight">\(\theta^{(1)}\)</span>，<span class="math notranslate nohighlight">\(\theta^{(3)}\)</span>的结果又依赖于<span class="math notranslate nohighlight">\(\theta^{(2)}\)</span>….</p></li>
<li><p>总的来说，<span class="math notranslate nohighlight">\(\theta^{(i+1)}\)</span>的结果依赖于<span class="math notranslate nohighlight">\(\theta^{(i)}\)</span>和收集到的数据y</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
f(\theta^{(i+1)}|\theta^{(1)},\theta^{(2)},...\theta^{(i)},y) = f(\theta^{(i+1)}|\theta^{(i)}, y)
\]</div>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\theta^{(i+1)}\)</span>独立于<span class="math notranslate nohighlight">\(\theta^{(i-1)}\)</span>，这就是马尔科夫链的“无记忆性”特点</p>
</div></blockquote>
<p><strong>好消息是：</strong></p>
<ul class="simple">
<li><p>我们无需从零开始编写这些复杂的算法。目前已经有不少高效的工具，它们可以帮助我们轻松实现复杂的MCMC采样的问题，从而帮助我们实现复杂的贝叶斯模型。</p></li>
</ul>
<p><strong>概率编程语言：</strong></p>
<ul class="simple">
<li><p>这些工具被统称为概率编程语言（Probability Programming Languages），简称PPL。它们包括但不限于以下几种：</p></li>
<li><p><a class="reference external" href="https://mc-stan.org/">stan</a></p></li>
<li><p><a class="reference external" href="https://www.pymc.io/welcome.html">PyMC</a></p></li>
<li><p><a class="reference external" href="https://sourceforge.net/projects/mcmc-jags/">JAGS</a></p></li>
<li><p><a class="reference external" href="http://www.bayesianscientific.org/resource/bugs-openbugs-winbugs/">BUGS (Bayesian Inference Using Gibbs Sampling)</a></p></li>
<li><p><a class="reference external" href="https://turinglang.org/docs/tutorials/docs-00-getting-started/index.html">julia turing</a></p></li>
</ul>
<p><strong>What is PyMC ?</strong></p>
<p><img alt="alt text" src="../_images/image-121.png" /></p>
<p>PyMC是一个在Python中基于 概率编程语音(probabilistic program language, PPL) 的工具，允许用户使用简单的Python API构建贝叶斯模型，并使用马尔可夫链蒙特卡洛（MCMC）方法进行拟合。</p>
<p>特点：</p>
<ul class="simple">
<li><p>PyMC致力于使贝叶斯建模尽可能简单，使用户能够专注于问题本身，而不是方法。</p></li>
<li><p>包括最先进的推断算法，包括MCMC（NUTS）和变分推断（ADVI）。</p></li>
<li><p>高效快速：使用PyTensor作为计算后端，通过C、Numba或JAX进行编译，可以将模型运行在GPU上，并受益于复杂的图优化。</p></li>
<li><p>提供后续的分析方法：包括概率分布、高斯过程、ABC、SMC等等。它与ArviZ集成得很好，用于可视化和诊断，以及与Bambi集成用于高级混合效应模型。</p></li>
<li><p>注重社区：在讨论区提问问题，参加MeetUp活动，关注他们的Twitter，并开始贡献。</p></li>
</ul>
<p><em><strong>课程预告：</strong></em></p>
<p>在接下来的课程中，我们将深入探讨 马尔可夫链蒙特卡洛(MCMC) 方法的具体原理。MCMC是一种强大的统计模拟技术，用于估计贝叶斯模型中的参数。</p>
<p>我们将重点介绍如何使用 PyMC 这一概率编程语言来进行MCMC模拟的基本过程。通过PyMC，我们可以更加高效地进行贝叶斯统计分析，无需担心底层算法的实现细节。</p>
<p><strong>💐补充材料</strong></p>
<p>Normal-Normal conjugate family
除了 Beta-Binomial 外，最常见的共轭分布是：Normal-Normal。</p>
<ul class="simple">
<li><p>以随机点运动任务（Random Dot Motion Task）为例</p></li>
</ul>
<p>假设我们打算开始进行一项随机点运动任务实验，尚未开始招募被试。为了对被试在不同条件下的表现进行推断，我们参考了先前的文献Vafaei Shooshtari et al. (2019)，他们的研究表明，当随机点的一致性为5%时，个体的平均正确率约为 70%。</p>
<p>为了更新我们对被试在随机点一致性为5%时的平均正确率的信念，我们计划通过贝叶斯推断收集10000名被试的实验数据，并使用Normal-Normal 贝叶斯模型来估计更新后的正确率。</p>
<blockquote>
<div><p>Shooshtari, S. V., Sadrabadi, J. E., Azizi, Z., &amp; Ebrahimpour, R. (2019). Confidence representation of perceptual decision by EEG and eye data in a random dot motion task. Neuroscience, 406, 510–527. <a class="reference external" href="https://doi.org/10.1016/j.neuroscience.2019.03.031">https://doi.org/10.1016/j.neuroscience.2019.03.031</a></p>
</div></blockquote>
<p><strong>正态模型的应用</strong></p>
<p>在这个实验中，我们假设被试的正确率服从正态分布，即：</p>
<div class="math notranslate nohighlight">
\[
Y \sim N(\mu,\sigma^2)
\]</div>
<p>其中：</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Y_i\)</span>是第i个被试在随机点一致性为5%时的正确率</p></li>
<li><p><span class="math notranslate nohighlight">\(\mu\)</span>是我们要估计的平均正确率</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma\)</span>是已知的正确率标准差</p></li>
</ul>
<p>根据 Vafaei Shooshtari et al. (2019) 的研究结果，我们对<span class="math notranslate nohighlight">\(\mu\)</span>（平均正确率）的初始信念假设为正态分布，即先验分布为：</p>
<div class="math notranslate nohighlight">
\[
\mu \sim N(\theta, \tau^2)
\]</div>
<p>注：</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\theta=0.70\)</span>，表示我们根据文献得出的先验均值（70%）</p></li>
<li><p><span class="math notranslate nohighlight">\(\tau^2\)</span>是先验的方差，表示我们对这个均值的初始不确定性</p></li>
</ul>
<p><strong>似然函数</strong></p>
<p>根据正态分布假设，样本数据的似然函数可以写为：</p>
<div class="math notranslate nohighlight">
\[
L(\mu|\overrightarrow{y})\propto \mathop{\prod} \limits_{i=1}^n exp[-\frac{(y_i-\mu)^2}{2\sigma^2}]
\]</div>
<p>其中，<span class="math notranslate nohighlight">\(y_i\)</span>是每个被试的观测正确率，<span class="math notranslate nohighlight">\(\sigma^2\)</span>是已知的正确率方差</p>
<p><strong>正态-正态共轭关系</strong></p>
<p>由于我们选择了正态分布作为<span class="math notranslate nohighlight">\(μ\)</span>的先验，并且似然函数也是正态分布，因此，利用正态-正态共轭，后验分布仍然是正态分布。后验分布的形式为：</p>
<div class="math notranslate nohighlight">
\[
\mu|\overrightarrow{y} \sim N(\frac{\theta \sigma^2+\overline{y}n\tau^2}{n\tau^2+\sigma^2},\frac{\tau^2\sigma^2}{n\tau^2+\sigma^2})
\]</div>
<p>其中：</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\overline{y}\)</span>是样本的均值（观测到的平均正确率）</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma^2\)</span>是已知的正确率方差</p></li>
<li><p><span class="math notranslate nohighlight">\(\tau^2\)</span>是先验的方差</p></li>
</ul>
<p><strong>后验分布分析</strong></p>
<ul class="simple">
<li><p><strong>后验均值</strong>：后验均值是先验均值<span class="math notranslate nohighlight">\(\theta\)</span>和样本均值<span class="math notranslate nohighlight">\(\overline{y}\)</span>的加权平均：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
posterior mean = \theta \frac{\sigma^2}{n\tau^2+\sigma^2}+\overline{y}\frac{n\tau^2}{n\tau^2+\sigma^2}
\]</div>
<ul class="simple">
<li><p><strong>后验方差</strong>：后验方差受先验的方差<span class="math notranslate nohighlight">\(r^2\)</span>和样本数据的方差<span class="math notranslate nohighlight">\(\sigma^2\)</span>的共同影响：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
posterior variance = \frac{\tau^2\sigma^2}{n\tau^2+\sigma^2}
\]</div>
<p>随着样本量<span class="math notranslate nohighlight">\(n\)</span>的增加，后验均值逐渐依赖于观测数据，而对先验的依赖减小。同时，后验方差随着样本量的增加而减小，意味着我们对<span class="math notranslate nohighlight">\(μ\)</span>的估计将变得更加精确。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="c1"># 定义正确率范围</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>  <span class="c1"># 正确率在0到1之间</span>

<span class="c1"># 定义先验分布 (基于文献，正确率均值为70%)</span>
<span class="n">prior_mean</span> <span class="o">=</span> <span class="mf">0.70</span>
<span class="n">prior_std</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">prior_y</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">prior_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">prior_std</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
    <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prior_mean</span><span class="p">,</span> <span class="n">prior_std</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># 生成似然分布 (基于新实验数据，正确率均值为75%)</span>
<span class="n">likelihood_mean</span> <span class="o">=</span> <span class="mf">0.75</span>
<span class="n">likelihood_std</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">likelihood_values</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">likelihood_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">likelihood_std</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
    <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">likelihood_mean</span><span class="p">,</span> <span class="n">likelihood_std</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># 计算后验分布</span>
<span class="n">posterior_mean</span> <span class="o">=</span> <span class="p">(</span><span class="n">prior_mean</span> <span class="o">*</span> <span class="n">likelihood_std</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">likelihood_mean</span> <span class="o">*</span> <span class="n">prior_std</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span>
    <span class="n">prior_std</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">likelihood_std</span><span class="o">**</span><span class="mi">2</span>
<span class="p">)</span>
<span class="n">posterior_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
    <span class="p">(</span><span class="n">prior_std</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">likelihood_std</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">prior_std</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">likelihood_std</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">posterior</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">posterior_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">posterior_std</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
    <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">posterior_mean</span><span class="p">,</span> <span class="n">posterior_std</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># 绘制先验、似然和后验分布</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prior_y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#f0e442&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;prior&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prior_y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#f0e442&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">likelihood_values</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#0071b2&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;likelihood&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">likelihood_values</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#0071b2&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">posterior</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#009e74&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;posterior&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">posterior</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#009e74&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="c1"># 设置 x 和 y 轴标签</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$\mu$ for accuracy (correct response rate)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;density&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="c1"># 移除图的上、右边框线</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>

<span class="c1"># 展示图像</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>补充：Gamma-Poisson conjugate family</strong></p>
<p>Gamma-Poisson共轭家族是一组统计模型，其中Poisson分布用于描述计数数据，而Gamma分布作为其参数的先验分布。</p>
<ul class="simple">
<li><p>Poisson分布是一种离散概率分布，用于描述在固定时间间隔或空间区域内发生某一事件的次数。</p></li>
<li><p>Gamma分布是一种连续概率分布，用于描述等待时间直到第k个事件发生的时间长度，或者作为正态分布方差的共轭先验。</p></li>
</ul>
<p><strong>例子：随机点运动任务中的被试招募：</strong></p>
<p>假设一位心理学研究者每天都需要每天招募新的被试参与随机点运动任务实验。</p>
<p>他认为平均下来，每天可以招募到 12 个被试，这个数字大约在 5 到 20 之间浮动。</p>
<p>我们假设研究者平均每天招募到的被试数量为<span class="math notranslate nohighlight">\(\lambda\)</span></p>
<p>🤔我们该使用哪种分布来描述下面这个例子？</p>
<p>需要注意的是，通常我们会：</p>
<ul class="simple">
<li><p>为<span class="math notranslate nohighlight">\(\lambda\)</span>选择一个合适的先验</p></li>
<li><p>接着收集数据，并且选择一个合适的数据模型</p></li>
<li><p>结合先验与数据，更新我们对<span class="math notranslate nohighlight">\(\lambda\)</span>的信念</p></li>
</ul>
<p><strong>Poisson分布</strong></p>
<p>泊松分布(Poisson distribution) 适用于描述在一定时间间隔内事件发生的次数。</p>
<p>Poisson分布的概率质量函数(pmf)可以表示为：</p>
<div class="math notranslate nohighlight">
\[
f(y)=\frac{\lambda^ye^{-\lambda}}{y^!}
\]</div>
<ul class="simple">
<li><p>Poisson分布只有一个参数<span class="math notranslate nohighlight">\(\lambda\)</span>，表示事情发生平均发生率(event rate)或事件发生的期望次数。</p></li>
<li><p><span class="math notranslate nohighlight">\(y\)</span>是数据，指在一定时间间隔中事件发生的次数。</p></li>
<li><p><span class="math notranslate nohighlight">\(f(y)\)</span>表示在某单位时间内，某事件<span class="math notranslate nohighlight">\(y\)</span>发生的平均次数的概率。</p></li>
</ul>
<p>例如，假设研究者平均每天可以招募 12 个被试（<span class="math notranslate nohighlight">\(\lambda\)</span>=12），那么在一天内招募到 5 个被试的概率<span class="math notranslate nohighlight">\(f(5)\)</span>招募到 10 名被试的概率<span class="math notranslate nohighlight">\(f(10)\)</span>，或招募到 15 名被试的概率<span class="math notranslate nohighlight">\(f(15)\)</span>都可以通过Poisson分布进行计算。</p>
<p><strong>Poisson分布图示</strong></p>
<p>下图展示了不同<span class="math notranslate nohighlight">\(\lambda\)</span>下，事件发生y次的可能性分布</p>
<p><img alt="alt text" src="../_images/image-131.png" /></p>
<p><strong>Potential priors</strong></p>
<p>🤔思考：</p>
<p>我们有如下形式的Poisson 似然函数：</p>
<div class="math notranslate nohighlight">
\[
L(\lambda|\overrightarrow{y})=\frac{\lambda^{\sum y_i}e^{-n\lambda}}{\prod^n_{i=1}y_i!}\propto \lambda^ke^{-\tau\lambda}
\]</div>
<p>从公式中可以看到，似然函数具有类似于<span class="math notranslate nohighlight">\(\lambda^ke^{-\tau\lambda}\)</span>的结构</p>
<p>那么，哪种先验分布与这种似然函数相匹配，从而作为 Poisson 分布的共轭先验？</p>
<p>1.Gamma模型：<span class="math notranslate nohighlight">\(f(\lambda) \propto \lambda^{s-1}e^{-\tau\lambda}\)</span></p>
<p>2.Weibull模型：<span class="math notranslate nohighlight">\(f(\lambda) \propto \lambda^{s-1}e^{(-\tau\lambda)^s}\)</span></p>
<p>3.”F”模型：<span class="math notranslate nohighlight">\(f(\lambda) \propto \lambda^{\frac{s}{2}-1}(1+\lambda)^{-s}\)</span></p>
<p>从形式上看，Gamma 分布与 Poisson 似然函数最匹配，
在 Poisson 分布中，Gamma 分布是<span class="math notranslate nohighlight">\(\lambda\)</span>的共轭先验，计算后会得到简便的后验分布。</p>
<p><strong>共轭性</strong></p>
<p>Gamma分布是一种连续概率分布，用于描述等待时间直到第k个事件发生的时间长度，或者作为正态分布方差的共轭先验。其概率密度函数（PDF）由以下公式给出：</p>
<div class="math notranslate nohighlight">
\[
f(\lambda|\alpha,\beta) = \frac{\beta^\alpha \lambda^{\alpha-1}e^{-\beta\lambda}}{\Gamma(\alpha)}
\]</div>
<p>其中，<span class="math notranslate nohighlight">\(\lambda\)</span>是分布的随机变量，<span class="math notranslate nohighlight">\(\alpha和\beta\)</span>是Gamma分布的形状参数和速率（或尺度）参数，<span class="math notranslate nohighlight">\(\Gamma(\alpha)\)</span>是Gamma函数。</p>
<p>当使用Gamma分布作为Poisson分布参数<span class="math notranslate nohighlight">\(\lambda\)</span>的先验分布时，得到的后验分布也属于Gamma分布。这种关系称为共轭性。具体来说，如果先验分布是Gamma分布，即：</p>
<div class="math notranslate nohighlight">
\[
\lambda \sim Gamma(\alpha,\beta)
\]</div>
<p>并且我们观测到Poisson数据<span class="math notranslate nohighlight">\(Y=y\)</span>，那么后验分布也是Gamma分布，其参数更新为：</p>
<div class="math notranslate nohighlight">
\[
\lambda|Y=y\sim Gamma(\alpha+y,\beta+1)
\]</div>
<p>这种共轭关系使得Gamma分布成为Poisson分布参数的自然选择，因为它保持了数学上的简洁性，使得后验分布的推导和分析变得容易。</p>
<p><strong>Critiques of conjugate family models</strong></p>
<p>共轭族的优势在于方便理解和计算，这种便利性也带来了缺点：</p>
<p>1.共轭先验模型可能并不能适应你的先验信念。</p>
<ul class="simple">
<li><p>例如，正态模型总是围绕均值<span class="math notranslate nohighlight">\(\mu\)</span>对称。因此，如果你的先验认识不是对称的，那么正态先验模型可能就不适合作为先验</p></li>
</ul>
<p>2.共轭族模型并不允许有一个完全平坦的先验(uniform prior)。</p>
<ul class="simple">
<li><p>虽然我们可以通过设置<span class="math notranslate nohighlight">\(\alpha=\beta=1\)</span>来使得 Beta 先验变得更加平坦，但无论是 Normal 还是 Gamma 先验（或任何具有无限支持的适当模型）都无法调整为完全平坦。</p></li>
<li><p>我们能做的最好的办法就是调整先验，使其具有非常高的方差，这样它们就几乎是平的了。</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter4"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="chapter4_part1.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Lecture 5: Bayesian Inference: From Traditional Foundations to Current Practices</p>
      </div>
    </a>
    <a class="right-next"
       href="../chapter5/chapter5_part1.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Leture6: MCMC</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">4.1 Grid approximation 网格近似</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-beta-binomial-example">A Beta-Binomial example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">示例：网络近似估计后验分布</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step1">Step1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step2-3">Step2&amp;3</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step4">Step4</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">练习</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">模型设定</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mu-sigma">增加难度：估计<span class="math notranslate nohighlight">\(\mu\)</span> 和 <span class="math notranslate nohighlight">\(\sigma\)</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">网格近似的局限性</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#markov-chain-monte-carlo-mcmc">Markov chain Monte Carlo(MCMC)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mcmc">MCMC 的采样特点</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr. Hu Chuan-Peng
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>