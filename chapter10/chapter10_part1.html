
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Evaluating Regression Models &#8212; Bayesian Inference with Python</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter10/chapter10_part1';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="练习：当自变量为连续变量" href="chapter10_part2.html" />
    <link rel="prev" title="练习" href="../chapter9/chapter9_part4.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../chapter_overview/intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Bayesian Inference with Python - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Bayesian Inference with Python - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../chapter_overview/intro.html">
                    序言
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">0. 课程概述</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_overview/Part1.html">为什么要学习贝叶斯推断?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_overview/Part2.html">贝叶斯推断的三个例子</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_overview/Part3.html">本课程的主要内容与形式</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">1. 初识贝叶斯法则(Bayes'Rule)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter1_Bayesrule/Bayesrule_part1.html">1.0 本课程演示平台: 和鲸平台</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter1_Bayesrule/Bayesrule_part2.html">1.1 单一事件的贝叶斯模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter1_Bayesrule/Bayesrule_part3.html">1.2 随机变量的贝叶斯模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter1_Bayesrule/Bayesrule_part4.html">1.3 贝叶斯与频率主义的简单对比</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">2. 一个真正的贝叶斯模型——Beta-Binomial Model</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter2_Beta_Binomial/BetaBinomial_part1.html">2.0 先验分布: Beta分布</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter2_Beta_Binomial/BetaBinomial_part2.html">2.1 似然函数: Binomial分布</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter2_Beta_Binomial/BetaBinomial_part3.html">2.2 后验分布</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter2_Beta_Binomial/BetaBinomial_part4.html">2.3 通过模拟可视化来观察模型</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">3. Balance and Sequentiality in Bayesian Analyses</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter3/Lecture4_part1.html">3.0 回顾Bayes'Rule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter3/Lecture4_part2.html">3.1 不同数据对后验的影响</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter3/Lecture4_part3.html">3.2 不同似然对后验的影响</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter3/Lecture4_part4.html">3.3 不同先验对后验的影响</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">4. Bayesian Inference:From Traditional Foundations to Current Practices</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter4/chapter4_part1.html">4.0 内容回顾</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter4/chapter4_part2.html">4.1 Grid approximation 网格近似</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">5. Markov Chain Monte Carlo(MCMC)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter5/chapter5_part1.html">5.0 Monte Carlo &amp; Markov Chain</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter5/chapter5_part2.html">5.1 Metropolis-Hastings(MH)算法</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">6. Posterior Inference &amp; Estimation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter6/chapter6_part1.html">6.0 A Beta-Binomial example in pymc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter6/chapter6_part2.html">6.1 MCMC诊断</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">7. A Simple Linear Regression Model with PyMC</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter7/chapter7_part1.html">7.0 贝叶斯一般线性回归模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter7/chapter7_part2.html">7.1 先验预测</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter7/chapter7_part3.html">7.2 后验预测</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">8. Bayes Factor</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter8/chapter8_part1.html">8.0 传统零假设显著性检验 vs 贝叶斯因子</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter8/chapter8_part2.html">8.1 贝叶斯因子的计算与应用</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">9. Multivariable linear regression</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter9/chapter9_part1.html">9.0 三水平的简单线性回归模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter9/chapter9_part2.html">9.1 2×3的多元线性回归模型：无交互</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter9/chapter9_part3.html">9.2 2×3的多元线性回归模型：有交互</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter9/chapter9_part4.html">9.3 练习</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">10. Evaluating Regression Models</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">10.0 贝叶斯回顾模型的评估</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter10_part2.html">10.1 练习</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">11. Logistic Regression</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter11/chapter11_part1.html">11.0 贝叶斯逻辑回归</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter11/chapter11_part2.html">11.1 练习</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">12. Hierarchical Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter12/chapter12_part1.html">12.0 层级数据结构与完全池化模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter12/chapter12_part2.html">12.1 非池化模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter12/chapter12_part3.html">12.2 部分池化模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter12/chapter12_part4.html">12.3 开放式练习</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">13. Hierarchical Regression Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter13/chapter13_part1.html">13.0 普通线性模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter13/chapter13_part2.html">13.1 变化截距模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter13/chapter13_part3.html">13.2 变化斜率模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter13/chapter13_part4.html">13.3 变化截距和斜率模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter13/chapter13_part5.html">13.4 分层模型中的组层面预测因子</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter13/chapter13_part6.html">13.5 练习</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">14. 课程回顾与复习</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter14/chapter14.html">14.0 课程回顾与复习</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/hcp4715/PyBayesianBook" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/hcp4715/PyBayesianBook/issues/new?title=Issue%20on%20page%20%2Fchapter10/chapter10_part1.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapter10/chapter10_part1.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Evaluating Regression Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vs">贝叶斯回归模型 vs 传统线性回归模型</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-evaluation-comparison">模型评估与比较 (Model Evaluation &amp; Comparison)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#is-the-model-fair">模型公正吗？(Is the model fair?)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-wrong-is-the-model">这个模型可能有多错误(How wrong is the model?)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">模型假设的影响</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">模型评估</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#median-absolute-error-mae">绝对误差的中位数，median absolute error (MAE)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation">交叉验证(cross validation)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bias-variance-trade-off">偏差-方差权衡 (Bias-Variance Trade-off)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">模型评估指标的代码演示</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mae">计算MAE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#elpd-loo">计算ELPD-LOO</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dicpython">补充：DIC在python中的实现</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="evaluating-regression-models">
<h1>Evaluating Regression Models<a class="headerlink" href="#evaluating-regression-models" title="Link to this heading">#</a></h1>
<p>🤔问题回顾：</p>
<ul class="simple">
<li><p>贝叶斯回归模型和传统的线性回归模型得到的结论是否一致？</p></li>
</ul>
<section id="vs">
<h2>贝叶斯回归模型 vs 传统线性回归模型<a class="headerlink" href="#vs" title="Link to this heading">#</a></h2>
<p>首先，让我们回顾上节课定义的三种线性模型，并通过PyMC进行定义和拟合。</p>
<style>
.center 
{
  width: auto;
  display: table;
  margin-left: auto;
  margin-right: auto;
}
</style>
<div class="center">
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p>模型</p></th>
<th class="head text-center"><p>参数</p></th>
<th class="head text-center"><p>解释</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>model1</p></td>
<td class="text-center"><p>RT~Label</p></td>
<td class="text-center"><p>简单线性回归模型：自变量为两水平的离散变量</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>model2</p></td>
<td class="text-center"><p>RT~Label+Matching</p></td>
<td class="text-center"><p>多元回归模型：自变量为两水平的离散变量和多水平的离散变量</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>model3</p></td>
<td class="text-center"><p>RT ~ Label + Matching + Label:Matching</p></td>
<td class="text-center"><p>多元回归模型：自变量额外增加了两个自变量间的交互作用</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 导入 pymc 模型包，和 arviz 等分析工具 </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pymc</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">arviz</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">az</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">st</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">xarray</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">xr</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="c1"># 忽略不必要的警告</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
  <span class="n">df_raw</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;/home/mw/input/bayes3797/Kolvoort_2020_HBM_Exp1_Clean.csv&#39;</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
  <span class="n">df_raw</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;/data/Kolvoort_2020_HBM_Exp1_Clean.csv&#39;</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;Subject&#39;</span><span class="p">,</span><span class="s1">&#39;Label&#39;</span><span class="p">,</span> <span class="s1">&#39;Matching&#39;</span><span class="p">],</span> <span class="n">as_index</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="s1">&#39;RT_sec&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># 将 Label 列的数字编码转为文字标签</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;Self&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;Friend&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="s1">&#39;Stranger&#39;</span><span class="p">})</span>

<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Matching&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Matching&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="s1">&#39;Matching&#39;</span><span class="p">:</span> <span class="s1">&#39;matching&#39;</span><span class="p">,</span> <span class="s1">&#39;Nonmatching&#39;</span><span class="p">:</span> <span class="s1">&#39;nonmatching&#39;</span><span class="p">})</span>

<span class="c1"># 设置索引</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;index&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;index&quot;</span><span class="p">)</span>

<span class="c1"># 将 Label 列转换为有序的分类变量</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Label&#39;</span><span class="p">],</span> <span class="n">categories</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Self&#39;</span><span class="p">,</span> <span class="s1">&#39;Friend&#39;</span><span class="p">,</span> <span class="s1">&#39;Stranger&#39;</span><span class="p">],</span> <span class="n">ordered</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># 将分类变量转换为哑变量</span>
<span class="n">X1</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Label&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Friend&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">X2</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Label&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Stranger&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="c1"># Matching 条件的哑变量</span>
<span class="n">Matching</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Matching&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;matching&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>  

<span class="c1"># Friend 和 Matching 的交互</span>
<span class="n">Interaction_1</span> <span class="o">=</span> <span class="n">X1</span> <span class="o">*</span> <span class="n">Matching</span>  

<span class="c1"># Stranger 和 Matching 的交互</span>
<span class="n">Interaction_2</span> <span class="o">=</span> <span class="n">X2</span> <span class="o">*</span> <span class="n">Matching</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 建立模型1</span>
<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model1</span><span class="p">:</span>
    <span class="c1"># 定义先验分布参数</span>
    <span class="n">beta_0</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;beta_0&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">beta_1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;beta_1&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">beta_2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;beta_2&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    
    <span class="c1"># 线性模型表达式</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">beta_0</span> <span class="o">+</span> <span class="n">beta_1</span> <span class="o">*</span> <span class="n">X1</span> <span class="o">+</span> <span class="n">beta_2</span> <span class="o">*</span> <span class="n">X2</span>
    
    <span class="c1"># 观测数据的似然函数</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;Y_obs&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;RT_sec&#39;</span><span class="p">])</span>

<span class="c1"># 建立模型2和模型3</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model2</span><span class="p">:</span>
    <span class="c1"># 先验分布</span>
    <span class="n">beta_0</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;beta_0&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  
    <span class="n">beta_1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;beta_1&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  
    <span class="n">beta_2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;beta_2&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  
    <span class="n">beta_3</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;beta_3&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>  
    
    <span class="c1"># 线性模型</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">beta_0</span> <span class="o">+</span> <span class="n">beta_1</span> <span class="o">*</span> <span class="n">X1</span> <span class="o">+</span> <span class="n">beta_2</span> <span class="o">*</span> <span class="n">X2</span> <span class="o">+</span> <span class="n">beta_3</span> <span class="o">*</span> <span class="n">Matching</span>
    
    <span class="c1"># 观测数据的似然函数</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;Y_obs&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;RT_sec&#39;</span><span class="p">])</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model3</span><span class="p">:</span>
    <span class="c1"># 定义先验分布</span>
    <span class="n">beta_0</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;beta_0&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  
    <span class="n">beta_1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;beta_1&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
    <span class="n">beta_2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;beta_2&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  
    <span class="n">beta_3</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;beta_3&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  
    <span class="n">beta_4</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;beta_4&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
    <span class="n">beta_5</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;beta_5&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>  
    
    <span class="c1"># 线性模型</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="p">(</span><span class="n">beta_0</span> <span class="o">+</span> <span class="n">beta_1</span> <span class="o">*</span> <span class="n">X1</span> <span class="o">+</span> <span class="n">beta_2</span> <span class="o">*</span> <span class="n">X2</span> <span class="o">+</span> <span class="n">beta_3</span> <span class="o">*</span> <span class="n">Matching</span> <span class="o">+</span>
          <span class="n">beta_4</span> <span class="o">*</span> <span class="n">Interaction_1</span> <span class="o">+</span> <span class="n">beta_5</span> <span class="o">*</span> <span class="n">Interaction_2</span><span class="p">)</span>
    
    <span class="c1"># 观测数据的似然函数</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;Y_obs&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;RT_sec&#39;</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#===========================</span>
<span class="c1">#     注意！！！以下代码可能需要运行3分钟左右</span>
<span class="c1">#===========================</span>

<span class="k">def</span><span class="w"> </span><span class="nf">run_model_sampling</span><span class="p">(</span><span class="n">save_name</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">draws</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">chains</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="mi">84735</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    运行模型采样，并在结果不存在时进行采样，存在时直接加载结果。</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - save_name: 用于保存或加载结果的文件名（无扩展名）</span>
<span class="sd">    - model: pymc 模型</span>
<span class="sd">    - draws: 采样次数 (默认5000)</span>
<span class="sd">    - tune: 调整采样策略的次数 (默认1000)</span>
<span class="sd">    - chains: 链数 (默认4)</span>
<span class="sd">    - random_seed: 随机种子 (默认84735)</span>

<span class="sd">    Returns:</span>
<span class="sd">    - trace: 采样结果</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># 检查是否存在保存的.nc文件</span>
    <span class="n">nc_file</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">save_name</span><span class="si">}</span><span class="s2">.nc&quot;</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">nc_file</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;加载现有的采样结果：</span><span class="si">{</span><span class="n">nc_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># 如果文件存在，则加载采样结果</span>
        <span class="n">trace</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">from_netcdf</span><span class="p">(</span><span class="n">nc_file</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>

        <span class="k">assert</span> <span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;模型未定义，请先定义模型&quot;</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;没有找到现有的采样结果，正在执行采样：</span><span class="si">{</span><span class="n">save_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># 如果文件不存在，则进行采样计算</span>
        <span class="k">with</span> <span class="n">model</span><span class="p">:</span>
            <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_prior_predictive</span><span class="p">(</span><span class="n">draws</span><span class="o">=</span><span class="n">draws</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">random_seed</span><span class="p">)</span>
            <span class="n">idata</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">draws</span><span class="o">=</span><span class="n">draws</span><span class="p">,</span>                   <span class="c1"># 使用mcmc方法进行采样，draws为采样次数</span>
                              <span class="n">tune</span><span class="o">=</span><span class="n">tune</span><span class="p">,</span>                    <span class="c1"># tune为调整采样策略的次数</span>
                              <span class="n">chains</span><span class="o">=</span><span class="n">chains</span><span class="p">,</span>                <span class="c1"># 链数</span>
                              <span class="n">discard_tuned_samples</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>   <span class="c1"># tune的结果将在采样结束后被丢弃</span>
                              <span class="n">idata_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;log_likelihood&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">},</span>
                              <span class="n">random_seed</span><span class="o">=</span><span class="n">random_seed</span><span class="p">)</span>      <span class="c1"># 后验采样</span>

            <span class="n">trace</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">idata</span><span class="p">)</span>
            <span class="c1"># 进行后验预测并扩展推断数据</span>
            <span class="n">pm</span><span class="o">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">extend_inferencedata</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">random_seed</span><span class="p">)</span>
            
            <span class="c1"># 保存结果到指定文件</span>
        <span class="n">trace</span><span class="o">.</span><span class="n">to_netcdf</span><span class="p">(</span><span class="n">nc_file</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">trace</span>

<span class="c1"># 运行所有三个模型</span>
<span class="n">model1_trace</span> <span class="o">=</span> <span class="n">run_model_sampling</span><span class="p">(</span><span class="s2">&quot;lec10_model1&quot;</span><span class="p">,</span><span class="n">model1</span><span class="p">)</span>
<span class="n">model2_trace</span> <span class="o">=</span> <span class="n">run_model_sampling</span><span class="p">(</span><span class="s2">&quot;lec10_model2&quot;</span><span class="p">,</span><span class="n">model2</span><span class="p">)</span>
<span class="n">model3_trace</span> <span class="o">=</span> <span class="n">run_model_sampling</span><span class="p">(</span><span class="s2">&quot;lec10_model3&quot;</span><span class="p">,</span><span class="n">model3</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>传统线性回归：</strong></p>
<ul class="simple">
<li><p>以model3为例，使用statsmodels库中的OLS函数（最小二乘法）来构建一个传统的线性回归模型，并将其结果与贝叶斯模型的结果进行比较：</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">statsmodels.api</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sm</span>

<span class="c1"># 构建设计矩阵</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
        <span class="s1">&#39;X1&#39;</span><span class="p">:</span> <span class="n">X1</span><span class="p">,</span> 
        <span class="s1">&#39;X2&#39;</span><span class="p">:</span> <span class="n">X2</span><span class="p">,</span> 
        <span class="s1">&#39;Matching&#39;</span><span class="p">:</span> <span class="n">Matching</span><span class="p">,</span>
        <span class="s1">&#39;Interaction_1&#39;</span><span class="p">:</span> <span class="n">Interaction_1</span><span class="p">,</span>
        <span class="s1">&#39;Interaction_2&#39;</span><span class="p">:</span> <span class="n">Interaction_2</span>
    <span class="p">})</span>
<span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;RT_sec&#39;</span><span class="p">]</span>

<span class="c1"># 传统线性回归模型</span>
<span class="n">model0</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># 打印回归结果</span>
<span class="n">model0</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 注意，可以通过 az.plot_bf() 函数来计算贝叶斯因子（Bayes Factor）。</span>
<span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">model3_trace</span><span class="p">,</span> <span class="n">hdi_prob</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>将两个模型结果进行对比</strong></p>
<style>
.center 
{
  width: auto;
  display: table;
  margin-left: auto;
  margin-right: auto;
}
</style>
<div class="center">
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p>参数</p></th>
<th class="head text-center"><p>贝叶斯回归（Bayesian Regression）</p></th>
<th class="head text-center"><p>传统线性回归（OLS Regression）</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><span class="math notranslate nohighlight">\(\beta_0\)</span></p></td>
<td class="text-center"><p>Mean: 0.729, SD: 0.024, HDI: [0.682, 0.775], BF10: 0.2</p></td>
<td class="text-center"><p>Mean: 0.7277, SE: 0.024, 95% CI: [0.681, 0.775], <span class="math notranslate nohighlight">\(P=0.000\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><span class="math notranslate nohighlight">\(\beta_1\)</span></p></td>
<td class="text-center"><p>Mean: 0.047, SD: 0.034, HDI: [-0.021, 0.112], BF10: 0.09</p></td>
<td class="text-center"><p>Mean: 0.0488, SE: 0.034, 95% CI: [-0.018, 0.115], <span class="math notranslate nohighlight">\(P=0.149\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><span class="math notranslate nohighlight">\(\beta_2\)</span></p></td>
<td class="text-center"><p>Mean: 0.032, SD: 0.034, HDI: [-0.034, 0.097], BF10: 0.05</p></td>
<td class="text-center"><p>Mean: 0.0326, SE: 0.034, 95% CI: [-0.034, 0.099], <span class="math notranslate nohighlight">\(P=0.333\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><span class="math notranslate nohighlight">\(\beta_3\)</span></p></td>
<td class="text-center"><p>Mean: -0.051, SD: 0.033, HDI: [-0.117, 0.012], BF10: 0.1</p></td>
<td class="text-center"><p>Mean: -0.0501, SE: 0.034, 95% CI: [-0.116, 0.016], <span class="math notranslate nohighlight">\(P=0.139\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><span class="math notranslate nohighlight">\(\beta_4\)</span></p></td>
<td class="text-center"><p>Mean: 0.032, SD: 0.047, HDI: [-0.061, 0.122], BF10: 0.06</p></td>
<td class="text-center"><p>Mean: 0.0305, SE: 0.048, 95% CI: [-0.063, 0.124], <span class="math notranslate nohighlight">\(P=0.523\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><span class="math notranslate nohighlight">\(\beta_5\)</span></p></td>
<td class="text-center"><p>Mean: 0.058, SD: 0.047, HDI: [-0.034, 0.150], BF10: 0.1</p></td>
<td class="text-center"><p>Mean: 0.0568, SE: 0.048, 95% CI:  [-0.037, 0.151], <span class="math notranslate nohighlight">\(P=0.234\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><span class="math notranslate nohighlight">\(\sigma\)</span></p></td>
<td class="text-center"><p>Mean: 0.133, SD: 0.007, HDI: [0.120, 0.147]</p></td>
<td class="text-center"><p>-</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>模型R²</p></td>
<td class="text-center"><p>-</p></td>
<td class="text-center"><p>R-squared: 0.062</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>模型调整R²</p></td>
<td class="text-center"><p>-</p></td>
<td class="text-center"><p>Adjusted R-squared: 0.036</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>F-statistic</p></td>
<td class="text-center"><p>-</p></td>
<td class="text-center"><p>F-statistic: 2.362, <span class="math notranslate nohighlight">\(P=0.0418\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>Log-Likelihood</p></td>
<td class="text-center"><p>-</p></td>
<td class="text-center"><p>Log-Likelihood: 115.01</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>AIC</p></td>
<td class="text-center"><p>-</p></td>
<td class="text-center"><p>AIC:-218.0</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>BIC</p></td>
<td class="text-center"><p>-</p></td>
<td class="text-center"><p>BIC: -198.7</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<ul class="simple">
<li><p>从结果的对比我们可以看出，贝叶斯回归和传统线性回归在各项参数上都是高度相似的。但是贝叶斯统计有一个好处，那就是<strong>可以支持零假设</strong>。</p></li>
</ul>
</section>
<section id="model-evaluation-comparison">
<h2>模型评估与比较 (Model Evaluation &amp; Comparison)<a class="headerlink" href="#model-evaluation-comparison" title="Link to this heading">#</a></h2>
<p>在模型评估中，贝叶斯回归和传统线性回归模型在参数估计上的结果非常接近。但是，它们的区别在于<strong>对参数的不确定性评估</strong>。</p>
<ul class="simple">
<li><p>贝叶斯模型提供了明确的参数分布，包括 均值、标准差 和 高密度区间（HDI），这使得我们可以更清晰地了解参数估计的不确定性。</p></li>
<li><p>而传统线性回归则侧重于给出参数的点估计，并通过 标准误差 和 95% 置信区间 进行评估。虽然传统模型没有明确给出不确定性，但它通过 <em>p 值、R²</em> 等统计量提供了其他重要信息。</p></li>
</ul>
<p><strong>🤔思考</strong></p>
<p>传统回归分析提供了更多的 模型评估指标📊，如 R²、调整后的 R²、F 统计量、对数似然、AIC 和 BIC 等。这些指标不仅帮助我们评估模型的拟合优度，还能有效地比较不同模型的复杂性和预测效果。</p>
<ul class="simple">
<li><p><em><strong>那么，哪一个模型对于数据的预测效果最好呢？我们又该如何通过这些评估指标来做出更有力的比较呢？</strong></em></p></li>
</ul>
<p>也就是说：</p>
<ul class="simple">
<li><p>我们需要找到一个最符合我们当前数据特点的模型，这个模型最可能产生我们当前的数据。那么从心理学的角度来讲，它反映的一些变量就能代表我们所关心的、潜在的、无法观测的一些心理过程。</p></li>
</ul>
<p>📈💡接下来的步骤：</p>
<p>我们将深入讨论如何使用具体的 评估指标 来量化模型性能，并根据这些指标对模型进行评估和比较。</p>
<p><img alt="alt text" src="../_images/image.png" /></p>
<p><strong>什么是模型评估？</strong></p>
<p>模型评估则是指对模型是否公平性、有效性、可信性进行评估，既可以是对单个模型，也可以是对多个模型进行。</p>
<ul class="simple">
<li><p>模型评估与比较(Model evaluation &amp; comparison)的目的在于选择最好的模型。</p></li>
</ul>
<p><strong>为什么需要模型比较？</strong></p>
<style>
.center 
{
  width: auto;
  display: table;
  margin-left: auto;
  margin-right: auto;
}
</style>
<div class="center">
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p>模型</p></th>
<th class="head text-center"><p>参数</p></th>
<th class="head text-center"><p>解释</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>model1</p></td>
<td class="text-center"><p>RT~Label</p></td>
<td class="text-center"><p>简单线性回归模型：自变量为两水平的离散变量</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>model2</p></td>
<td class="text-center"><p>RT~Label+Matching</p></td>
<td class="text-center"><p>多元回归模型：自变量为两水平的离散变量和多水平的离散变量</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>model3</p></td>
<td class="text-center"><p>RT ~ Label + Matching + Label:Matching</p></td>
<td class="text-center"><p>多元回归模型：自变量额外增加了两个自变量间的交互作用</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<p>1、例如，比较 mode3 和 model2 可以帮助我们确定“Label”和“Matching”之间的交互或调节作用。</p>
<p>2、例如，比较 model2 和 model1 可以衡量增加预测因子是否能提升模型的预测能力。</p>
<ul class="simple">
<li><p>总之，模型比较的目的随着研究目的的变化而变化。</p></li>
</ul>
<p>我们可以从以下三个原则来思考“模型评估与比较”的问题：</p>
<p><strong>1、模型本身公正吗？(How fair is the model?)</strong></p>
<ul class="simple">
<li><p>公正性(How fair)：模型在数据收集和分析的整个流程中的公正性。</p></li>
</ul>
<p><strong>2、模型存在错误吗？(How wrong is the model?)</strong></p>
<ul class="simple">
<li><p>错误程度(How wrong)：模型在实践中是否有效？即是否能够准确地预测样本数据。</p></li>
</ul>
<p><strong>3、后验预测模型有多准确？(How accurate are the posterior predictive models?)</strong></p>
<ul class="simple">
<li><p>准确性(How accurate)：模型是否反映现实规律？即是否能够准确地预测样本外数据。</p></li>
</ul>
<section id="is-the-model-fair">
<h3>模型公正吗？(Is the model fair?)<a class="headerlink" href="#is-the-model-fair" title="Link to this heading">#</a></h3>
<p>模型公正性是一个上位概念，它描述了模型是否符合我们(社会、道德、伦理)的预期，而不仅是关注模型和样本数据的关系。</p>
<p>我们可以借助几个相关问题来理解和思考模型的公正性：</p>
<p>1、数据的收集过程是怎样的？</p>
<ul class="simple">
<li><p>数据的收集过程直接影响模型的公正性。如果数据收集的过程存在偏见或不充分考虑多样性，那么模型就可能会产生不公正的结果。</p></li>
<li><p>例如，某些群体的数据可能被忽视或代表性不足，导致模型结果不具备广泛的适用性或公平性。</p></li>
</ul>
<p>2、数据由谁收集，数据收集的目的是什么？</p>
<ul class="simple">
<li><p>数据收集者的身份、意图和研究目的，都会影响数据的性质和使用方式。</p></li>
<li><p>资本主义的核心观念推动了个体主义和竞争性思维，可能导致研究样本的偏倚，削弱了全球不同文化和社会背景的代表性。</p></li>
</ul>
<p>我们从实际研究经历出发，可以发现，从数据收集到数据分析的一整个过程中，我们研究者可能会把自身的一些偏见引入其中。例如，最常见的一种数据收集偏见则是采用大学生被试作为样本，但是在大学生群体中得到的结果是否能够推广到整个人口学的大群体可能会存在问题，比如研究结果涉及到政策制定的时候就可能会出现较大偏差，此时考虑群体的多样性问题就变得非常重要。</p>
<p><strong>1. 数据的收集的过程公平吗？</strong></p>
<p>在本示例研究中，数据来源于基于自我匹配范式的实验数据，这些数据通过线下认知实验收集而得。</p>
<ul class="simple">
<li><p>数据收集过程是公平的，被试填写了实验的知情同意书，并获得相应的报酬。</p></li>
<li><p>此外，数据收集过程是匿名化的，保护了被试的隐私。</p></li>
</ul>
<p>潜在偏见，如：在数据收集过程中，仅选取大学生群体作为样本，而忽略其他重要的人群。</p>
<p><strong>心理学研究背后的内隐哲学观</strong></p>
<p>在研究过程中未被明确提及，却深刻影响研究设计和解释的潜在观念和假设形成了心理学研究背后的内隐哲学观。</p>
<p>主要包括普遍性假设导致的对文化差异考量不足，以及资本主义核心观念导致的研究样本偏倚。这些内隐观念可能使研究忽视文化多样性和社会不平等，从而影响研究的全面性、准确性和应用价值。</p>
<style>
.center 
{
  width: auto;
  display: table;
  margin-left: auto;
  margin-right: auto;
}
</style>
<div class="center">
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p>内隐哲学观方面</p></th>
<th class="head text-center"><p>重要性</p></th>
<th class="head text-center"><p>作用</p></th>
<th class="head text-center"><p>影响</p></th>
<th class="head text-center"><p>新的提倡</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>普遍性假设与文化差异考量不足</p></td>
<td class="text-center"><p>构建准确全面且具文化适应性理论</p></td>
<td class="text-center"><p>使研究忽略文化因素，影响各环节</p></td>
<td class="text-center"><p>限制理论普适性，阻碍心理学全球发展</p></td>
<td class="text-center"><p>数据收集多样化、文化敏感性培训、理论构建多元视角</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>资本主义核心观念与研究样本偏倚</p></td>
<td class="text-center"><p>确保研究样本多样性和代表性</p></td>
<td class="text-center"><p>导致样本选择偏向西方或资本主义文化个体</p></td>
<td class="text-center"><p>研究结果有偏差，不利于跨文化研究</p></td>
<td class="text-center"><p>扩大样本来源、提高研究者文化敏感性、融合多元文化理论</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<blockquote>
<div><p>参考文献：Bettache, K. (2024). Where Is Capitalism? Unmasking Its Hidden Role in Psychology. Personality and Social Psychology Review, 0(0). <a class="reference external" href="https://doi.org/10.1177/10888683241287570">https://doi.org/10.1177/10888683241287570</a></p>
</div></blockquote>
<p>举例：当我们中国研究者或者非西方研究者在投稿过程中可能会碰到一个问题，那就是当样本全部来自于你所在的地区时，审稿人会认为取样不够国际化，即研究结论不一定能推广到其他种族。然而，当样本是英国或美国群体时，审稿人会觉得没有问题，认为使用英美地区样本得到的研究结果是可以推广到其他种族的，是国际化的。</p>
<p><strong>2. 研究目的，以及数据收集的目的公正吗？</strong></p>
<p>在本示例研究中，研究目的来源自心理学家的好奇和假设。这是合理的，因为心理学研究是一种探索性的研究方法。（无利益冲突）</p>
<p>一些极端的反例：</p>
<ul class="simple">
<li><p>如果研究项目来源于开发缓解压力药的厂商。那么，研究目的就可能被操纵，以支持药厂的销售。</p></li>
<li><p>例如，有目的的选择被试，有目的性的将实验目告诉被试，从而收集到符合预期的数据。</p></li>
</ul>
<p>从这张图中，你可以发现什么？🤔</p>
<p><img alt="alt text" src="../_images/image-1.png" /></p>
<blockquote>
<div><p>参考文献：Ghai, S., Forscher, P.S. &amp; Chuan-Peng, H. Big-team science does not guarantee generalizability. Nat Hum Behav 8, 1053–1056 (2024). <a class="reference external" href="https://doi.org/10.1038/s41562-024-01902-y">https://doi.org/10.1038/s41562-024-01902-y</a></p>
</div></blockquote>
<ul class="simple">
<li><p>上面是作者自己和其他合作者对一个已发表的数据进行的再分析结果以及可视化。原来的研究认为自己的研究结论可以被叫做globalize，即全世界通用的一个原则。这是因为它在全世界几十个国家收集了数据，因此在数据来源上确实是比较多样化的。</p></li>
<li><p>然而，我们来看一些每一个国家的数据，可以看出，无论是尼日利亚、中国还是美国，被试的年龄基本上都集中在18-35之间，也就是说参与研究的绝大部分都是年轻被试。我们再来看被试的受教育程度，这个部分的偏差就更大了，绝大多数参与研究的被试都是受过高等教育的，这实际上和各自国家的实际不符。因此，如果这样的研究结论用以指定某些国际性政策的话，它会涉及很大程度上的偏见。</p></li>
</ul>
<p><strong>数据由谁收集，数据收集的目的是什么？</strong></p>
<p>数据收集者的身份、意图和研究目的，都会影响数据的性质和使用方式。</p>
<p>研究者可能内隐地假设心理学现象具有普遍性，但未充分考虑文化差异，这种内隐假设影响了结果的解释，忽视了不同社会和文化背景对心理现象的深刻影响(Ghai, Forscher, &amp; Chuan-Peng, 2024)。</p>
<p><strong>3.模型分析的结果，将对个人和社会产生什么影响？</strong></p>
<p>在本示例研究中，研究结果(模型分析的结果)具有一定的理论意义和实际意义。</p>
<ul class="simple">
<li><p>在理论层面， 自我匹配范式中的模型能够帮助揭示个体如何处理与“自我”相关的信息。</p></li>
<li><p>在实际意义层面，通过这些模型，可以更精确地识别个体在自我认知过程中的偏差。</p></li>
</ul>
<p><strong>4. 分析过程中包含的偏见？</strong></p>
<p>一些反例：</p>
<ul class="simple">
<li><p>假设在一次研究中使用多种问卷收集多种因变量，然后选择有相关性的变量进行报告?</p></li>
<li><p>在多因素实验设计中，通过增加变量来获得显著的交互作用，并尝试多种简单效应分析。</p></li>
</ul>
<p><strong>在心理学研究中，模型公正性往往与”心理学研究的可重复性”相关。</strong></p>
<ul class="simple">
<li><p>数据的收集过程是怎样的？</p></li>
<li><p>数据由谁收集，数据收集的目的是什么？</p></li>
<li><p>数据收集的过程，以及分析的结果，将对个人和社会产生什么影响？</p></li>
<li><p>分析过程中可能会包含哪些偏见</p></li>
<li><p>p-hacking/HARKing</p></li>
</ul>
<p><img alt="alt text" src="../_images/image-2.png" /></p>
<blockquote>
<div><p>来源：胡传鹏, …, 彭凯平. (2016). 心理学研究中的可重复性问题:从危机到契机. 心理科学进展, 24(9), 1504-1518. doi: 10.3724/SP.J.1042.2016.01504</p>
</div></blockquote>
</section>
<section id="how-wrong-is-the-model">
<h3>这个模型可能有多错误(How wrong is the model?)<a class="headerlink" href="#how-wrong-is-the-model" title="Link to this heading">#</a></h3>
<div class="math notranslate nohighlight">
\[
“all~models~are~wrong, but~some~are~useful. ——~George Box”
\]</div>
<p>我们一般讲模型的时候都会引用George Box的话——“所有模型都是错误的，但有一些模型是有用的。”</p>
<p>🤔为什么会这么说呢？</p>
<p>实际上，我们在评估模型或比较模型时，并不是说哪个模型一定是对的，因为我们都知道没有绝对正确的模型。因此，我们关注的是模型错误的程度怎么样，以及模型多大程度上与现实相符合。</p>
<ul class="simple">
<li><p>尽管统计模型是对更复杂现实的简化表达，良好的统计模型仍然可以是有用的，并可以增进我们对世界复杂性的理解。</p></li>
<li><p>因此，在评估模型时，要问的下一个问题不是模型是否错误(is the model wrong?)，而是模型错误的程度(How wrong is the model?)</p></li>
</ul>
<p>🤔思考贝叶斯线性回归模型的假设在多大程度上与现实相符？</p>
</section>
<section id="id1">
<h3>模型假设的影响<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>🤔 我们知道模型存在前提预设(assumption)，如果这些模型的前提预设不成立，模型会变得多糟糕？</p>
<p>在lec9中，我们使用一个线性模型来定义标签“Label”与反应时间“RT”之间的关系，并且指定了该模型成立的一些前提预设。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
Y_i=\beta_0 + \beta_1X_i + \epsilon ~~~ \epsilon\sim N(0,\sigma^2) \\
Y_i|\beta_0,\beta_1,\sigma \overset{ind}{\sim} N(\mu_i,\sigma^2)~with~\mu_i=\beta_0+\beta_1X_i
\end{split}\]</div>
<p>回归模型需要满足如下假设：</p>
<p>1.独立观测假设：每个观测值<span class="math notranslate nohighlight">\(Y_i\)</span>是相互独立的，即一个观测值不受其他观测的影响</p>
<p>2.线性关系假设：预测值<span class="math notranslate nohighlight">\(\mu_i\)</span>和自变量<span class="math notranslate nohighlight">\(X_i\)</span>之间可以用线性关系来描述，即：<span class="math notranslate nohighlight">\(\mu_i=\beta_0+\beta_1X_i\)</span></p>
<p>3.方差同质性假设：在任意自变量的取值下，观测值<span class="math notranslate nohighlight">\(Y_i\)</span>都会以<span class="math notranslate nohighlight">\(\mu_i\)</span>为中心，同样的标准差<span class="math notranslate nohighlight">\(\sigma\)</span>呈正态分布变化。</p>
<p><em><strong>当假设1 (独立观测假设) 被违反时：</strong></em></p>
<ul class="simple">
<li><p>在心理学的实验数据中，观测值之间常常存在依赖关系 (dependent)。</p></li>
<li><p>比如，反应时数据在单个被试内、或某种特定刺激类型内可能表现得更加同质：</p></li>
</ul>
<p>（1）有的被试（Participant）总是比其他人反应得更快；</p>
<p>（2）有的刺激类型（Stimulus）可能总是导致更快的反应。</p>
<p>这种观测值的相互关联会导致对结果的不准确估计，具体体现在：</p>
<ul class="simple">
<li><p>过低的标准误：错误高估了参数的显著性；</p></li>
<li><p>错误的效应估计：未能正确捕捉组间差异。</p></li>
</ul>
<p>解决这种关联问题需要采用层级模型（Hierarchical Models），特别是<strong>层级贝叶斯模型（Hierarchical Bayesian Models）</strong>。这种方法能够同时建模个体差异（如被试间的反应）和组间差异（如刺激类型的影响）。</p>
<p>例如，在下图中：</p>
<ul class="simple">
<li><p>左图可能低估了被试间的变异性，假设所有被试的反应时间都完全由刺激难度解释。</p></li>
<li><p>右图通过引入随机截距（Random Intercept）更好地捕捉了被试间的差异，使得模型更贴合数据的实际结构。</p></li>
</ul>
<p><img alt="alt text" src="../_images/image-3.png" /></p>
<p>1、左图：单一模型（无随机效应）</p>
<ul class="simple">
<li><p>仅考虑整体平均效应，没有控制“被试”或“刺激”的特定差异。</p></li>
<li><p>每个数据点的误差条（灰色线条）表示高水平的变异性，线性趋势可能无法很好地反映个体间差异。</p></li>
</ul>
<p>2、右图：考虑随机截距模型（Random Intercept Model）</p>
<ul class="simple">
<li><p>模型中引入了被试间的随机截距（by-participant random intercept），将不同被试的反应时间（RT）的基本差异纳入建模过程。</p></li>
<li><p>虚线代表各被试的随机截距，展示了“被试间”的系统性差异；实线代表整体效应估计（包含群体水平的趋势）。</p></li>
<li><p>结果更加细化，并能够同时反映群体趋势和个体变异。</p></li>
</ul>
<blockquote>
<div><p>source: Brown, V. A. (2021). An Introduction to Linear Mixed-Effects Modeling in R. Advances in Methods and Practices in Psychological Science, 4(1), 2515245920960351. <a class="reference external" href="https://doi.org/10.1177/2515245920960351">https://doi.org/10.1177/2515245920960351</a></p>
</div></blockquote>
<p><em><strong>当假设2(线性关系假设)和假设3(方差同质性假设)被违反时：</strong></em></p>
<ul class="simple">
<li><p>假设2(线性关系假设)违反的情况：在左图中，我们可以看到，Y和X之间的关系并非线性的，更像是一种曲线关系。</p></li>
</ul>
<p>假设3(方差同质性假设)违反的情况：并且，随着X的增大，Y的变异性越来越大。</p>
<p>这要导致的后果是，后验预测分布比实际观测值的分布差异很大(右图)</p>
<p><img alt="alt text" src="../_images/image-4.png" /></p>
<p><strong>对模型进行修改</strong></p>
<ul class="simple">
<li><p>考虑到并不是所有数据都会满足这些假设，当这些假设被违反时，我们需要考虑修改模型。</p></li>
</ul>
<ol class="arabic simple">
<li><p>对于违反假设1 的情况，我们在之后会学习使用层级贝叶斯模型来处理相互关联的数据。</p></li>
<li><p>对于违反假设2和3的情况，通常有两种处理方式</p></li>
</ol>
<p>a. 使用不同的数据模型</p>
<p>不假设实际值与观测值之间的关系是正态的<span class="math notranslate nohighlight">\(Y_i \sim N(\mu_i,\sigma^2)\)</span></p>
<p>我们后续会学习使用其他回归模型来描述其数据关系，比如泊松回归、二项回归、负二项回归。</p>
<p>b. 对数据进行变换</p>
<p>如果数据模型并不是我们要担心的问题，我们可以对数据进行变换，仍然可以对变换后的数据可以使用正态模型：</p>
<ul class="simple">
<li><p>对Y进行变换：<span class="math notranslate nohighlight">\(g(Y_i)|\beta_0,\beta_1,\sigma \overset{ind}{\sim}N(\mu_i,\sigma^2),\mu_i=\beta_0+\beta_1X_i\)</span></p></li>
<li><p>对X进行变换：<span class="math notranslate nohighlight">\(Y_i|\beta_0,\beta_1,\sigma \overset{ind}{\sim}N(\mu_i,\sigma^2),\mu_i=\beta_0+\beta_1h(X_i)\)</span></p></li>
<li><p>同时对Y和X进行变换：<span class="math notranslate nohighlight">\(g(Y_i)|\beta_0,\beta_1,\sigma \overset{ind}{\sim}N(\mu_i,\sigma^2),\mu_i=\beta_0+\beta_1h(X_i)\)</span></p></li>
</ul>
<p>在刚才的例子中，我们对Y的取值进行了一个对数变换</p>
<div class="math notranslate nohighlight">
\[
log(Y_i)|\beta_0,\beta_1,\sigma \overset{ind}{\sim}N(\mu_i,\sigma^2)~with~\mu_i=\beta_0+\beta_1X_i
\]</div>
<ul class="simple">
<li><p>在变换之后，可以看到log(Y)与X之间的关系仍然是线性的，且随着X的增大，Y的变异性仍然是一致的。</p></li>
<li><p>可以使用正态的线性模型来拟合log(Y)的后验分布。</p></li>
<li><p>这部分内容将在逻辑回归（logistics regression）部分进行详细介绍，这里先不作深入解释。</p></li>
</ul>
<p><img alt="alt text" src="../_images/image-5.png" /></p>
</section>
<section id="id2">
<h3>模型评估<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<p>一般情况下，我们的贝叶斯模型不会是完全不公平的，或者错得太离谱的。 但除了这些问题，<strong>更为重要的是，模型是否可以用来准确预测新数据 Y 的结果</strong>。</p>
<ul class="simple">
<li><p>如果说模型公平性和模型错误描述的是模型在质量上的优劣，那模型评估与比较就是在数量上衡量模型预测的准确性。</p></li>
</ul>
<p>我们可以通过什么指标来评估预测模型的整体质量呢？</p>
<ul class="simple">
<li><p>绝对指标，衡量模型对于样本的预测能力。</p></li>
<li><p>相对指标，衡量模型对于样本外数据的预测能力，也考虑了模型的复杂度。</p></li>
</ul>
<p>首先，先向大家介绍可用于评估模型在样本数据上的预测能力的绝对指标 —- <strong>绝对误差的中位数，median absolute error (MAE)</strong></p>
<ul class="simple">
<li><p>用以衡量观测值与其后验预测均值之间的典型差异。</p></li>
</ul>
</section>
<section id="median-absolute-error-mae">
<h3>绝对误差的中位数，median absolute error (MAE)<a class="headerlink" href="#median-absolute-error-mae" title="Link to this heading">#</a></h3>
<p>定义：MAE是观测值（<span class="math notranslate nohighlight">\(Y_i\)</span>）和后验预测均值（<span class="math notranslate nohighlight">\(Y_i'\)</span>）的绝对误差的中位数，公式为：</p>
<div class="math notranslate nohighlight">
\[
MAE = median(|Y_i-Y_i'|)
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Y_i\)</span>:实际观测值</p></li>
<li><p><span class="math notranslate nohighlight">\(Y_i'\)</span>：模型后验预测的均值</p></li>
<li><p>假设<span class="math notranslate nohighlight">\(Y_1,Y_2......,Y_n\)</span>表示n个观测结果</p></li>
<li><p>每个<span class="math notranslate nohighlight">\(Y_i\)</span>都有对应的后验预测值，其均值为<span class="math notranslate nohighlight">\(Y_i'\)</span></p></li>
</ul>
<p>作用：衡量模型预测值和实际观测值之间的典型差异。</p>
<p>特点：</p>
<ul class="simple">
<li><p>MAE是绝对误差的典型值，对异常值的敏感性较低。</p></li>
<li><p>作为绝对指标，直接反映模型的预测精度。</p></li>
</ul>
<p><strong>相对指标：样本外预测能力</strong></p>
<p>仅在样本数据上评估模型并不足以验证其泛化能力，尤其是心理学数据经常受到时间和抽样偏差的影响。例如：</p>
<ul class="simple">
<li><p>比如，个体的压力状态可能随着季节变化，因此在不同季节收集到的数据会受到时间的影响。</p></li>
<li><p>抽样差异：训练模型的数据可能来自理工科学生，而测试模型的数据来自心理学学生，这种抽样差异可能导致预测性能下降。</p></li>
<li><p>因此，一种更高效的方法是，一次性多收集一些数据，选择其中的一部分作为预测数据。</p></li>
</ul>
<p>相对指标更多的是评估模型在<strong>样本外数据</strong>上的，同时考虑模型的复杂度,这更有利于比较不同模型的预测能力。</p>
</section>
<section id="cross-validation">
<h3>交叉验证(cross validation)<a class="headerlink" href="#cross-validation" title="Link to this heading">#</a></h3>
<p>但问题在于，我们选择哪一部分数据作为预测数据？或者说，我们该如何有效的对数据进行抽取？</p>
<p><strong>交叉验证(cross validation) 的目的就在于：提供不同的抽取预测数据的策略。</strong></p>
<p>其关键在于从已有样本中拿出一部分数据当作预测数据。</p>
<p><img alt="alt text" src="../_images/image-6.png" /></p>
<blockquote>
<div><p>source:【绝对干货】机器学习模型训练全流程！- 知乎 <a class="reference external" href="https://zhuanlan.zhihu.com/p/184673895">https://zhuanlan.zhihu.com/p/184673895</a></p>
</div></blockquote>
<p>常见的交叉验证策略：</p>
<ol class="arabic simple">
<li><p>分半交叉验证 (Split-half cross-validation)</p></li>
</ol>
<p>分半交叉验证将观测数据对半分成两部分，分别在不同的数据集上拟合模型，并在另外一半数据集上验证模型，最后再对比不同的模型在两份数据集作为验证集时的预测准确度。</p>
<ol class="arabic simple" start="2">
<li><p>K 折交叉验证 (K-fold cross-validation)</p></li>
</ol>
<p>K 折交叉验证把数据分成 K 份，其中一份作为训练集（拟合模型，对参数进行估计），其余的 K-1 分数据集作为验证集，总共重复这个流程 K 次。以 K 次验证结果的均值作为验证标准。</p>
<ol class="arabic simple" start="3">
<li><p>留一法交叉验证 (Leave-one-out cross-validation)</p></li>
</ol>
<p>留一法交叉验证是 K 折交叉验证的一个特例，当分折的数量等于数据的数量时，K 折留一法便成了留一法交叉验证。留一法交叉验证相较于普通的交叉验证方法，几乎使用了所有数据去训练模型，因此留一法交叉验证的训练模型时的偏差 (bias) 更小、更鲁棒，但是又因为验证集只有一个数据点，验证模型的时候留一法交叉验证的方差 (Variance) 也会更大。</p>
<p><em><strong>K 折交叉验证 (K-fold cross-validation)</strong></em></p>
<p>K 折交叉验证在分半交叉验证的基础上，将数据集分成 K 份(称为 CV-K)，其中一份作为测试集，其余 K-1 份作为训练集，重复这个流程 K 次。</p>
<p>K 折交叉验证，以 K 次测试结果的均值作为验证标准。例如，在压力-自我控制的例子中：</p>
<ul class="simple">
<li><p>我们可以使用 K=5 折的交叉验证，将数据集分成 5 份，每次使用 4 份数据作为训练集，1份数据作为测试集。</p></li>
<li><p>对每一次迭代，我们使用 4 份数据训练模型，然后使用剩下的一份数据进行测试，并计算相应的MAE。</p></li>
<li><p>重复这个流程 5 次，然后取每次MAE测试结果的均值作为最终的测试结果。</p></li>
</ul>
<p><img alt="alt text" src="../_images/image-7.png" /></p>
<blockquote>
<div><p>source:【绝对干货】机器学习模型训练全流程！- 知乎 <a class="reference external" href="https://zhuanlan.zhihu.com/p/184673895">https://zhuanlan.zhihu.com/p/184673895</a></p>
</div></blockquote>
<p><em><strong>留一法交叉验证 (Leave-one-out cross-validation)</strong></em></p>
<p>留一法交叉验证是 K 折交叉验证的一个特例，当分折的数量K等于数据的数量n时，K 折留一法便成了留一法交叉验证。</p>
<ul class="simple">
<li><p>留一法交叉验证相较于普通的交叉验证方法，几乎使用了所有数据去训练模型。</p></li>
<li><p>留一法交叉验证 (Leave-one-out cross-validation)的缩写为 loo-cv，或者 loo。</p></li>
</ul>
<blockquote>
<div><p>source: <a class="reference external" href="https://www.baeldung.com/cs/cross-validation-k-fold-loo">https://www.baeldung.com/cs/cross-validation-k-fold-loo</a></p>
</div></blockquote>
<p><em><strong>ELPD (Expected log-predictive density)</strong></em></p>
<p>留一法交叉验证 LOO (包括之前的交叉验证方法)是用于评估模型在<strong>未知数据</strong>上预测能力的思想框架，其本身并不提供具体的统计指标。</p>
<p>ELPD (Expected log-predictive density) 是 LOO 方法的具体实现，以对数似然函数作为统计指标。</p>
<p>其计算步骤：</p>
<ul class="simple">
<li><p>同 K 折交叉验证一样，首先将数据集分成 n 份，n为数据总的数量。</p></li>
<li><p>利用 n-1 份数据去训练模型，得到后验模型<span class="math notranslate nohighlight">\(p(\theta_{-i}|y_{-i})\)</span></p></li>
<li><p>使用剩下的一份数据作为测试数据<span class="math notranslate nohighlight">\(y_i\)</span>，计算后验预测模型<span class="math notranslate nohighlight">\(p(y_i|y_{-i})\)</span></p></li>
<li><p>重复以上过程 n 次，得到 n 个后验预测模型,并计算其对数化后的期望值<span class="math notranslate nohighlight">\(E(log(p(y_i|y_{-i})))\)</span></p></li>
</ul>
<p><img alt="alt text" src="../_images/image-8.png" /></p>
<p><em><strong>补充：其他指标</strong></em></p>
<p>之前讨论过模型评估中两种类型的指标：</p>
<ul class="simple">
<li><p>绝对指标，衡量模型对于样本的预测能力。</p></li>
<li><p>相对指标，衡量模型对于样本外数据的预测能力，也考虑了模型的复杂度。</p></li>
</ul>
<p>这两种指标包含了多种具体的统计值：</p>
<p>模型拟合优度的方法包括：</p>
<ul class="simple">
<li><p>MAE or MSE(mean square error)</p></li>
<li><p>对数似然 (log likelihood)</p></li>
<li><p>R²</p></li>
</ul>
<p>模型预测进度的方法包括：</p>
<ul class="simple">
<li><p>AIC</p></li>
<li><p>DIC</p></li>
<li><p>WAIC</p></li>
<li><p>LOO-CV</p></li>
</ul>
<style>
.center 
{
  width: auto;
  display: table;
  margin-left: auto;
  margin-right: auto;
}
</style>
<div class="center">
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p></p></th>
<th class="head text-center"><p>AIC</p></th>
<th class="head text-center"><p>DIC</p></th>
<th class="head text-center"><p>WAIC</p></th>
<th class="head text-center"><p>LOOCV</p></th>
<th class="head text-center"><p>BIC</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>适用框架</p></td>
<td class="text-center"><p>频率论</p></td>
<td class="text-center"><p>贝叶斯</p></td>
<td class="text-center"><p>贝叶斯</p></td>
<td class="text-center"><p>贝叶斯</p></td>
<td class="text-center"><p>贝叶斯/频率论</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>偏差（deviance）</p></td>
<td class="text-center"><p>最大似然参数<span class="math notranslate nohighlight">\(\theta_mle\)</span>的对数似然</p></td>
<td class="text-center"><p>贝叶斯参数均值<span class="math notranslate nohighlight">\(\overline{\theta}\)</span>的对数似然</p></td>
<td class="text-center"><p>LPPD</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(ELPD_{LOO-CV}\)</span></p></td>
<td class="text-center"><p>最大似然参数<span class="math notranslate nohighlight">\(\theta_mle\)</span>的对数似然</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>矫正</p></td>
<td class="text-center"><p>参数数量</p></td>
<td class="text-center"><p>似然的变异</p></td>
<td class="text-center"><p>似然的变异</p></td>
<td class="text-center"><p>由于采用LOO-CV的思想，因此不需要矫正</p></td>
<td class="text-center"><p>参数数量+数据数量</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<p>目前认知建模在科学心理学中得到了广泛应用，而模型比较作为认知建模的核心环节，不仅是评估模型对数据的拟合优度（平衡过拟合与欠拟合），还需要考虑模型复杂度对预测能力的影响。</p>
<p>然而，由于模型比较指标种类繁多，研究者在选用时往往面临困惑。</p>
<p>在郭鸣谦等(2024) 的文章中便把常用指标划分为三类，其中AIC、DIC、WAIC 等基于交叉验证的指标，通过数据分割或后验分布计算预测性能，平衡拟合优度和复杂度。</p>
<p><img alt="alt text" src="../_images/image-9.png" /></p>
<blockquote>
<div><p>source: 郭鸣谦, 潘晚坷, 胡传鹏. (2024). 认知建模中模型比较的方法. 心理科学进展, 32(10), 1736-1756. doi: 10.3724/SP.J.1042.2024.01736</p>
</div></blockquote>
<p><strong>众多指标关心的核心问题：一个是它对于训练样本的预测能力如何；另一个则是它对样本外的预测能力如何。</strong></p>
<ul class="simple">
<li><p>此外，近来也有研究者认为：不一定需要选出一个最优的指标，可以把所有合理的模型都纳入近来，然后对它们的预测进行加权平均，最后做出一个总的预测，也就是“模型平均”的思路。</p></li>
</ul>
</section>
<section id="bias-variance-trade-off">
<h3>偏差-方差权衡 (Bias-Variance Trade-off)<a class="headerlink" href="#bias-variance-trade-off" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>偏差（Bias）：指的是算法的期望预测与真实预测之间的偏差程度， 反映了模型本身的拟合能力，即模型本身对当前数据集的拟合偏差。</p></li>
<li><p>方差（Variance）：与我们通常所说的方差有所不同，是指用不同训练数据进行模型评估时，模型表现的变化程度。</p></li>
</ul>
<p><strong>在模型训练过程中，偏差和方差之间存在一定的权衡关系：</strong></p>
<ul class="simple">
<li><p>高偏差通常伴随着低方差，即模型较为简单，但能够在不同训练数据集上保持较为稳定的表现；</p></li>
<li><p>低偏差通常伴随着高方差，即模型较为复杂，可以在训练数据上做得很好，但在其他数据集上表现不稳定；</p></li>
</ul>
<p>因此，偏差和方差之间需要达到一种平衡，即<strong>偏差-方差权衡</strong>，以避免模型过于简单或过于复杂。</p>
<p>在模型评估中，无论是绝对评估还是相对评估，都可以结合偏差-方差权衡的概念来理解。偏差-方差权衡揭示了以下关键事实：</p>
<ul class="simple">
<li><p>模型越复杂：虽然能够更好地拟合训练数据，但往往会<strong>失去对样本外数据的解释能力（即过拟合）</strong>。</p></li>
<li><p>模型越简单：尽管能够在不同样本间保持一致性，但<strong>对于任何特定样本的解释力可能较弱（即欠拟合）</strong>。</p></li>
</ul>
<p>举例说明：</p>
<ul class="simple">
<li><p>如果我们的目标是建立一个能够准确预测响应变量 ( Y ) 的模型，就需要包含足够多的预测因子，以获得对 ( Y ) 的充分信息。</p></li>
<li><p>然而，加入过多的预测因子可能适得其反。模型不仅会过度拟合训练数据，还可能导致复杂性增加，从而降低泛化能力。</p></li>
</ul>
<p>通过平衡模型的偏差和方差，我们可以选择<strong>一个既能够捕捉数据结构，又具有良好预测能力的模型</strong>。这种权衡是建模过程中不可忽视的核心问题。</p>
<p><img alt="alt text" src="../_images/image-10.png" /></p>
<blockquote>
<div><p>source: <a class="reference external" href="https://vitalflux.com/overfitting-underfitting-concepts-interview-questions/">https://vitalflux.com/overfitting-underfitting-concepts-interview-questions/</a></p>
</div></blockquote>
<ul class="simple">
<li><p>模型评估的核心在于模型捕捉到了数据中的关键模式，既非太简单而错过数据中有价值的信息(欠拟合, underfitting)，也不会太复杂从而将数据中的噪音加入到模型中(过拟合, overfitting)。</p></li>
</ul>
<p><em><strong>欠拟合(underfitting)</strong></em></p>
<p>欠拟合的模型在当前样本的数据拟合效果不好，且其泛化能力(模型在当前样本外新的数据上的预测的准确度)也同样不佳。</p>
<p>导致欠拟合的原因:</p>
<ul class="simple">
<li><p>数据特征较少</p>
<ul>
<li><p>数据特征指的是数据的属性，比如第一部分中展示的数据的各个变量就是数据的特征。在所有变量都能独立地对目标变量做出解释的前提下，数据特征越多，数据拟合程度越好。</p></li>
</ul>
</li>
<li><p>模型复杂度过低</p>
<ul>
<li><p>模型的复杂度代表模型能够描述的所有函数，比如线性回归最多能表示所有的线性函数。</p></li>
<li><p>模型的复杂度和模型的参数数量有关，一般来说，模型参数越多，复杂度越高，模型参数越少，复杂度越低。</p></li>
</ul>
</li>
</ul>
<p><em><strong>如何避免欠拟合</strong></em></p>
<ul class="simple">
<li><p>增加数据的特征</p></li>
<li><p>增加模型复杂度</p></li>
</ul>
<p><em><strong>过拟合(overfitting)</strong></em></p>
<ul class="simple">
<li><p>模型在当前样本的数据上的拟合程度极好，但是泛化能力也较差。</p></li>
<li><p>模型把训练样本学习地“太好了”，把样本自身地一些噪音也当作了所有潜在样本都会具有的一些性质，这样就会导致其泛化性能下降。</p></li>
</ul>
<p>导致过拟合的原因</p>
<ul class="simple">
<li><p>当前样本的噪音过大，模型将噪音当作数据本身的特征</p></li>
<li><p>当数据的有些特征与目标变量无关，这些特征就是噪音，但它也可能被误当作数据特征，这就会造成模型过拟合</p></li>
<li><p>样本选取有误，样本不能代表整体</p></li>
<li><p>模型参数太多，模型复杂度太高</p></li>
</ul>
<p><em><strong>如何避免过拟合</strong></em></p>
<ul class="simple">
<li><p>选择更具代表性的数据</p></li>
<li><p>降低模型复杂度</p></li>
</ul>
<p><img alt="alt text" src="../_images/image-11.png" /></p>
<blockquote>
<div><p>source: <a class="reference external" href="https://blog.csdn.net/weixin_43378396/article/details/90707493">https://blog.csdn.net/weixin_43378396/article/details/90707493</a></p>
</div></blockquote>
<p><strong>问题的本质在于：模型与数据真实的生成模型匹配</strong></p>
<p><strong>⚠需要注意</strong>：</p>
<p>在进行数据分析之前，一定要先看看原始数据长什么样，对原始数据进行可视化，而不是一上来就只看统计结果，这是一个很危险的做法。</p>
</section>
</section>
<section id="id3">
<h2>模型评估指标的代码演示<a class="headerlink" href="#id3" title="Link to this heading">#</a></h2>
<p>在我们了解模型评估的基本原理和方法后，接下来我们通过代码来演示如何使用这些方法来评估模型。包括：</p>
<ul class="simple">
<li><p>绝对指标，MAE</p></li>
<li><p>相对指标，ELPD-LOO</p></li>
</ul>
<section id="mae">
<h3>计算MAE<a class="headerlink" href="#mae" title="Link to this heading">#</a></h3>
<p>MAE是观测值(<span class="math notranslate nohighlight">\(Y_i\)</span>)和后验预测均值(<span class="math notranslate nohighlight">\(Y_i'\)</span>)的绝对误差的中位数，公式为：</p>
<div class="math notranslate nohighlight">
\[
MAE = median(|Y_i-Y_i'|)
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Y_i\)</span>:实际观测值</p></li>
<li><p><span class="math notranslate nohighlight">\(Y_i'\)</span>：模型后验预测的均值</p></li>
</ul>
<p>接下来我们通过代码来演示如何计算 MAE，以 model 1 为例。</p>
<p>1、提取后验预测数据，从模型中提取后验预测数据是后续计算的基础。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 从采样结果中提取后验预测样本</span>
<span class="n">posterior_predictive</span> <span class="o">=</span> <span class="n">model1_trace</span><span class="o">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s2">&quot;Y_obs&quot;</span><span class="p">]</span>

<span class="c1"># 在draw 和 chain 两个维度上计算后验均值</span>
<span class="n">posterior_mean</span> <span class="o">=</span> <span class="n">posterior_predictive</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;chain&quot;</span><span class="p">,</span> <span class="s2">&quot;draw&quot;</span><span class="p">])</span>

<span class="n">posterior_mean</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<p>2、计算 MAE</p>
<p>通过提取的后验预测值，计算 MAE，作为模型预测误差的绝对指标。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 计算 MAE（观测值和后验均值的绝对误差的中位数）</span>
<span class="n">mae</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;RT_sec&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">posterior_mean</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MAE: </span><span class="si">{</span><span class="n">mae</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>3、对于 MAE 的解读。</p>
<ul class="simple">
<li><p>绝对误差的中位数，median absolute error (MAE)衡量了预测观测值<span class="math notranslate nohighlight">\(Y_i\)</span>与后验预测均值之间<span class="math notranslate nohighlight">\(Y_i'\)</span>的差异。</p></li>
<li><p><strong>MAE越小表明后验模型的预测越准确。</strong></p></li>
</ul>
<p>我们可以对比三个模型的 MAE 结果:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mae</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">observed_data</span><span class="p">,</span> <span class="n">dv</span> <span class="o">=</span> <span class="s2">&quot;Y_obs&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    计算后验预测均值和 MAE (Median Absolute Error)。</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    - trace: PyMC 模型的采样结果 (InferenceData 对象)。</span>
<span class="sd">    - observed_data: 包含真实观测值的 Pandas DataFrame。</span>
<span class="sd">    - dv: 需要计算 MAE 的数据列名，默认为 &quot;Y_obs&quot;。</span>

<span class="sd">    Returns:</span>
<span class="sd">    - posterior_mean: 后验预测值的均值。</span>
<span class="sd">    - mae: 后验预测均值与观测值之间的 MAE。</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># 提取后验预测值</span>
    <span class="n">posterior_predictive</span> <span class="o">=</span> <span class="n">trace</span><span class="o">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="n">dv</span><span class="p">]</span>
    
    <span class="c1"># 计算后验预测均值（在 draw 和 chain 两个维度上取平均值）</span>
    <span class="n">posterior_mean</span> <span class="o">=</span> <span class="n">posterior_predictive</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;chain&quot;</span><span class="p">,</span> <span class="s2">&quot;draw&quot;</span><span class="p">])</span>
    
    <span class="c1"># 计算 MAE（绝对误差的中位数）</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">observed_data</span> <span class="o">-</span> <span class="n">posterior_mean</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">mae</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;Model 1&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">calculate_mae</span><span class="p">(</span><span class="n">model1_trace</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;RT_sec&quot;</span><span class="p">],</span> <span class="s2">&quot;Y_obs&quot;</span><span class="p">)],</span>
    <span class="s2">&quot;Model 2&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">calculate_mae</span><span class="p">(</span><span class="n">model2_trace</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;RT_sec&quot;</span><span class="p">],</span> <span class="s2">&quot;Y_obs&quot;</span><span class="p">)],</span>
    <span class="s2">&quot;Model 3&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">calculate_mae</span><span class="p">(</span><span class="n">model3_trace</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;RT_sec&quot;</span><span class="p">],</span> <span class="s2">&quot;Y_obs&quot;</span><span class="p">)],</span>
<span class="p">})</span>
</pre></div>
</div>
<p>Model1:0.087913  ;  Model2:0.088987  ;  Model3:0.089136</p>
</section>
<section id="elpd-loo">
<h3>计算ELPD-LOO<a class="headerlink" href="#elpd-loo" title="Link to this heading">#</a></h3>
<p>在实际操作中，我们通过 ArViz 的函数<code class="docutils literal notranslate"><span class="pre">az.loo</span></code>计算<span class="math notranslate nohighlight">\(ELPD_{LOO-CV}\)</span></p>
<ul class="simple">
<li><p>在<code class="docutils literal notranslate"><span class="pre">az.loo</span></code>返回的值中，<code class="docutils literal notranslate"><span class="pre">elpd_loo</span></code>为<span class="math notranslate nohighlight">\(E(log(p(y_i|y_{-i})))\)</span></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">elpd_loo</span></code>越高表示模型的预测值越精确</p></li>
</ul>
<p>注意：由于<span class="math notranslate nohighlight">\(ELPD_{LOO-CV}\)</span>的计算量也比较大，ArViz 会使用 Pareto Smooth Importance Sampling Leave Once Out Cross Validation (PSIS-LOO-CV) 来近似。</p>
<p>PSIS-LOO-CV 有两大优势：</p>
<ul class="simple">
<li><p>计算速度快，且结果稳健</p></li>
<li><p>提供了丰富的模型诊断指标</p></li>
</ul>
<p>注意：</p>
<ul class="simple">
<li><p>要计算 <code class="docutils literal notranslate"><span class="pre">elpd_loo</span></code> 需要在采样 <code class="docutils literal notranslate"><span class="pre">pm.sample</span></code> 中加入 <code class="docutils literal notranslate"><span class="pre">idata_kwargs={&quot;log_likelihood&quot;:</span> <span class="pre">True}</span></code></p></li>
<li><p>或者，在模型采样完成后计算对数似然，即 <code class="docutils literal notranslate"><span class="pre">with</span> <span class="pre">model:</span> <span class="pre">pm.compute_log_likelihood(model_trace)</span></code>。</p></li>
</ul>
<p>首先，我们以 model 3为例</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 以 model 3 为例计算elpd_loo</span>

<span class="n">az</span><span class="o">.</span><span class="n">loo</span><span class="p">(</span><span class="n">model3_trace</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="alt text" src="../_images/image-12.png" /></p>
<ul class="simple">
<li><p>结果解读：</p></li>
</ul>
<p>如果good的比例（pct.）非常高的话，我们可以认为这个ELPD-LOO的结果是可信的。如果bad或very bad的比例很高的话，那就意味着这个结果可能需要再谨慎考虑一下。</p>
<ul class="simple">
<li><p>然而，仅凭单个值，并不能反映模型的预测精确程度。</p></li>
</ul>
<p>虽然 ELPDs 无法为任何单一模型的后验预测准确性提供可解释的度量，但它在<strong>比较多个模型</strong>的后验预测准确性时非常有用。</p>
<p>我们可以通过 <code class="docutils literal notranslate"><span class="pre">arviz.compare</span></code> 方法来对比多个模型的 elpd:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">comparison_list</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;model1&quot;</span><span class="p">:</span><span class="n">model1_trace</span><span class="p">,</span>
    <span class="s2">&quot;model2&quot;</span><span class="p">:</span><span class="n">model2_trace</span><span class="p">,</span>
    <span class="s2">&quot;model3&quot;</span><span class="p">:</span><span class="n">model3_trace</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">az</span><span class="o">.</span><span class="n">compare</span><span class="p">(</span><span class="n">comparison_list</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="alt text" src="../_images/image-13.png" /></p>
<p>从结果可以看出：</p>
<ul class="simple">
<li><p>模型1的 elpd_loo 最大，表明它对样本外数据的预测性能最好。</p></li>
<li><p>而模型3的 elpd_loo 最小，表明它的预测性能最差。</p></li>
<li><p>并且这些结果与我们通过 MAE 计算及上节课的贝叶斯因子计算和HDI+rope 区间计算得到的判断一致。</p></li>
</ul>
<p>需要注意的是：</p>
<ul class="simple">
<li><p>arviz 提供的结果包括了 elpd se，这使得我们可以判断两个模型的预测差异 elpd_diff 是否超过两至三个标准误se。</p></li>
</ul>
</section>
</section>
<section id="dicpython">
<h2>补充：DIC在python中的实现<a class="headerlink" href="#dicpython" title="Link to this heading">#</a></h2>
<p>DIC（Deviance Information Criterion）是用于模型选择和评估的指标，通常用于贝叶斯模型。在统计学中，DIC 是一种衡量模型拟合优度和复杂度的指标，类似于AIC（Akaike Information Criterion）和BIC（Bayesian Information Criterion）。</p>
<ul class="simple">
<li><p>在贝叶斯统计中，DIC 适用于基于 MCMC (Markov chain Monte Carlo) 采样估计的模型。</p></li>
</ul>
<p>由于PyMc中没有直接计算DIC的方式，我们补充这一内容，方便同学们在练习中参考。</p>
<p>DIC的计算公式：</p>
<div class="math notranslate nohighlight">
\[
DIC = -2D(\overline{\theta})+2×p_D
\]</div>
<ul class="simple">
<li><p>其中，<span class="math notranslate nohighlight">\(\overline{\theta}\)</span>为参数后验分布的均值，而<span class="math notranslate nohighlight">\(D(\theta)\)</span>则是真实数据与模型预测分布之间的偏差（Deviance），用以衡量模型的性能。</p></li>
<li><p>DIC公式的第一项是-2乘上后验分布上的均值的偏差，代表了模型拟合的程度</p></li>
<li><p>第二项<span class="math notranslate nohighlight">\(p_D\)</span>被称为有效参数（effective number of parameters），是模型拟合的复杂度的惩罚项，也就是将模型参数数量增加后所带来的拟合优势平衡一下。</p></li>
</ul>
<p><strong>DIC 综合考虑了模型的拟合优度和复杂度。模型的 DIC 值越低，说明模型在平衡拟合优度与复杂度后表现越好。</strong></p>
<p><strong>偏差的公式为：</strong></p>
<div class="math notranslate nohighlight">
\[
D(\theta_s)=logL(y|\theta_s)
\]</div>
<ul class="simple">
<li><p>其中s代表了MCMC的样本，因此<span class="math notranslate nohighlight">\(\theta_s\)</span>是MCMC样本的参数值</p></li>
</ul>
<p><strong>有效参数<span class="math notranslate nohighlight">\(p_D\)</span></strong></p>
<p><span class="math notranslate nohighlight">\(p_D\)</span>为有效参数(effective number of parameters), 是模型拟合的复杂度的惩罚项, 计算公式如下：</p>
<div class="math notranslate nohighlight">
\[
p_D=Var(D(\theta))=\frac{1}{M}\sum\limits_{m=1}^{M}D(\theta^{(m)})-D(\hat{\theta})
\]</div>
<ul class="simple">
<li><p>其中，<span class="math notranslate nohighlight">\(D(\theta^{(m)})\)</span>是第m个样本的偏差，<span class="math notranslate nohighlight">\(\hat{\theta}\)</span>是后验均值</p></li>
</ul>
<p><strong>代码实现：</strong></p>
<p>要根据模型的 log-likelihood 结果计算 DIC (Deviance Information Criterion)，可以按照以下步骤操作：</p>
<p>假设 <code class="docutils literal notranslate"><span class="pre">model_trace.log_likelihood[&quot;Y_obs&quot;]</span></code> 是后验采样的 log-likelihood 值。</p>
<p>log-likelihood 的结构：</p>
<ul class="simple">
<li><p>log_likelihood 是一个包含多个链和采样的对数似然值矩阵。</p></li>
<li><p>在 chain 和 draw 维度上计算均值可以得到每个观测值的平均 log-likelihood。</p></li>
</ul>
<p>首先，我们以model1为例进行演示</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">calculate_dic</span><span class="p">(</span><span class="n">log_likelihood</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    根据 log-likelihood 计算 DIC (Deviance Information Criterion)。 参考 Evans, N. J. (2019). Assessing the practical differences between model selection methods in inferences about choice response time tasks. Psychonomic Bulletin &amp; Review, 26(4), 1070–1098. https://doi.org/10.3758/s13423-018-01563-9</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    - log_likelihood: xarray 数据集，包含每个链和样本的 log-likelihood 值。</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    - dic: 计算得到的 DIC 值。</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 计算每个样本的Deviance</span>
    <span class="n">deviance_samples</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">log_likelihood</span>
    
    <span class="c1"># 计算平均Deviance</span>
    <span class="n">D_bar</span> <span class="o">=</span> <span class="n">deviance_samples</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    
    <span class="c1"># 计算有效自由度 p_D</span>
    <span class="n">p_D</span> <span class="o">=</span> <span class="n">deviance_samples</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">D_bar</span>
    
    <span class="c1"># 计算DIC</span>
    <span class="n">DIC</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">D_bar</span> <span class="o">-</span> <span class="n">p_D</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">DIC</span><span class="p">[</span><span class="s2">&quot;Y_obs&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 调用 compute_dic 函数</span>
<span class="n">dic_value</span> <span class="o">=</span> <span class="n">calculate_dic</span><span class="p">(</span><span class="n">model1_trace</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DIC 值: </span><span class="si">{</span><span class="n">dic_value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>同样我们可以计算所有模型（model1，model2，model3）的 DIC 值进行对比：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;Model 1&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">calculate_dic</span><span class="p">(</span><span class="n">model1_trace</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">)],</span>
    <span class="s2">&quot;Model 2&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">calculate_dic</span><span class="p">(</span><span class="n">model2_trace</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">)],</span>
    <span class="s2">&quot;Model 3&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">calculate_dic</span><span class="p">(</span><span class="n">model3_trace</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">)],</span>
<span class="p">})</span>
</pre></div>
</div>
<style>
.center 
{
  width: auto;
  display: table;
  margin-left: auto;
  margin-right: auto;
}
</style>
<div class="center">
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p></p></th>
<th class="head text-center"><p>Model1</p></th>
<th class="head text-center"><p>Model2</p></th>
<th class="head text-center"><p>Model3</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>0</p></td>
<td class="text-center"><p>28.29209986121615</p></td>
<td class="text-center"><p>24.679373842803408</p></td>
<td class="text-center"><p>27.387719057819087</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<p>🤔思考：</p>
<p>1、如果你的目标是在不控制任何其他因素的情况下探索反应时间和什么有关，你会使用哪种模型？</p>
<ul class="simple">
<li><p>考虑到模型1优于模型2和模型3–因此，选择模型1可能能更好地反应反应时间的变化。</p></li>
</ul>
<p>2、如果你的目标是最大限度地提高模型的预测能力，而在模型中只能选择一个预测因子，您会选择Label还是Matching？</p>
<ul class="simple">
<li><p>由于模型1优于模型2，如果仅选择一个预测变量的话，选择Label能获得对于反应时间更好的预测。</p></li>
</ul>
<p>3、这四个模型中，哪个模型的总体预测结果最好？</p>
<ul class="simple">
<li><p>模型1以微弱优势超过了使用所有预测因子的模型2。这表明，在建立模型的过程中，预测因子并不是越多越好。</p></li>
<li><p>事实上，模型3比模型2还差一点，这表明Label和matching之间的交互效应很弱，加入两者的交互项，会减弱模型的预测能力。</p></li>
</ul>
<p>因此，为了简单高效，我们更有理由选择模型1。</p>
<p><img alt="alt text" src="../_images/image-14.png" /></p>
<blockquote>
<div><p>source: <a class="reference external" href="http://www.esafety.cn/Blog/u/9490/archives/2018/154367.html">http://www.esafety.cn/Blog/u/9490/archives/2018/154367.html</a></p>
</div></blockquote>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter10"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../chapter9/chapter9_part4.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">练习</p>
      </div>
    </a>
    <a class="right-next"
       href="chapter10_part2.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">练习：当自变量为连续变量</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vs">贝叶斯回归模型 vs 传统线性回归模型</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-evaluation-comparison">模型评估与比较 (Model Evaluation &amp; Comparison)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#is-the-model-fair">模型公正吗？(Is the model fair?)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-wrong-is-the-model">这个模型可能有多错误(How wrong is the model?)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">模型假设的影响</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">模型评估</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#median-absolute-error-mae">绝对误差的中位数，median absolute error (MAE)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation">交叉验证(cross validation)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bias-variance-trade-off">偏差-方差权衡 (Bias-Variance Trade-off)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">模型评估指标的代码演示</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mae">计算MAE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#elpd-loo">计算ELPD-LOO</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dicpython">补充：DIC在python中的实现</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr. Hu Chuan-Peng
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>