# ç»ƒä¹ ï¼šå½“è‡ªå˜é‡ä¸ºè¿ç»­å˜é‡

## æ¨¡å‹å›é¡¾

åœ¨ç¬¬åè¯¾çš„ç»ƒä¹ éƒ¨åˆ†ï¼Œæˆ‘ä»¬æ¢ç©¶äº†è‡ªæˆ‘æ§åˆ¶æ°´å¹³æ˜¯å¦å‹åŠ›å’Œå¸çƒŸæœ‰å…³ï¼Œåˆ†åˆ«å»ºç«‹äº†ä¸‰ä¸ªå›å½’æ¨¡å‹ï¼Œæœ¬èŠ‚è¯¾çš„ç»ƒä¹ å°†åŸºäºä¸ŠèŠ‚è¯¾å»ºç«‹çš„ä¸‰ä¸ªæ¨¡å‹è¿›è¡Œã€‚

ğŸ’¡ å¦‚æœä¸ŠèŠ‚è¯¾çš„ç»ƒä¹ æ²¡æœ‰å®Œæˆï¼Œæ˜¯æ— æ³•å®Œæˆæœ¬èŠ‚è¯¾çš„ç»ƒä¹ çš„å“¦ï¼ï¼ˆéš¾åº¦ ğŸ”ğŸ”ğŸ”ï¼‰

<table>
    <tr>
        <td>æ¨¡å‹</td> 
        <td>model1</td> 
        <td>model2</td> 
        <td>model3</td>
   </tr>
    <tr>
  		<td>è‡ªå˜é‡</td> 
        <td>å‹åŠ›(è¿ç»­å˜é‡)</td> 
        <td>å‹åŠ›(è¿ç»­å˜é‡)ï¼Œå¸çƒŸ(ç¦»æ•£å˜é‡)ã€æ— äº¤äº’ã€‘</td> 
        <td>å‹åŠ›(è¿ç»­å˜é‡)ï¼Œå¸çƒŸ(ç¦»æ•£å˜é‡)ã€æœ‰äº¤äº’ã€‘</td> 
    </tr>
    <tr>
        <td>è‡ªå˜é‡å«ä¹‰</td> 
        <td colspan="3">å‹åŠ›ï¼ˆ14-70çš„å‹åŠ›è¯„çº§ï¼‰ï¼›å¸çƒŸï¼ˆ`0` è¡¨ç¤ºä¸å¸çƒŸï¼Œ`1` è¡¨ç¤ºå¸çƒŸï¼‰</td> 
    </tr>
    <tr>
        <td>å…ˆéªŒ</td> 
        <td>Î²0 ~ N(50, 10);
            Î²1 ~ N(0, 10);
            Ïƒ ~ Exp(0.6)</td> 
        <td>Î²0 ~ N(50, 10);
            Î²1 ~ N(0, 10);
            Î²2 ~ N(0, 10);
            Ïƒ ~ Exp(0.6)</td> 
        <td>Î²0 ~ N(50, 10);
            Î²1 ~ N(0, 10);
            Î²2 ~ N(0, 10);
            Î²3 ~ N(0, 10);
            Ïƒ ~ Exp(0.6)</td>
   </tr>
</table>

```python
# å¯¼å…¥ pymc æ¨¡å‹åŒ…ï¼Œå’Œ arviz ç­‰åˆ†æå·¥å…· 
import pymc as pm
import arviz as az
import seaborn as sns
import scipy.stats as st
import numpy as np
import matplotlib.pyplot as plt
import xarray as xr
import pandas as pd
import os

# å¿½ç•¥ä¸å¿…è¦çš„è­¦å‘Š
import warnings
warnings.filterwarnings("ignore")
```

```python
# é€šè¿‡ pd.read_csv åŠ è½½æ•°æ® Data_Sum_HPP_Multi_Site_Share.csv
try:
  df_re = pd.read_csv('/home/mw/input/bayes3797/Data_Sum_HPP_Multi_Site_Share.csv')
except:
  df_re = pd.read_csv('data/Data_Sum_HPP_Multi_Site_Share.csv')


# ç­›é€‰ç«™ç‚¹ä¸º"Tsinghua"çš„æ•°æ®
df = df_re[df_re["Site"] == "Tsinghua"]

df = df[["stress","scontrol","smoke"]]

#1 è¡¨ç¤ºå¸çƒŸï¼Œ2è¡¨ç¤ºä¸å¸çƒŸ
df["smoke"] =  np.where(df['smoke'] == 2, 0, 1)
df["smoke_recode"] =  np.where(df['smoke'] == 1, "yes", "no")


#è®¾ç½®ç´¢å¼•
df["index"] = range(len(df))
df = df.set_index("index")
```

```python
##-------------------------------------------------
#     å®šä¹‰æ¨¡å‹4ã€5ã€6ï¼Œè¡¥å…¨...éƒ¨åˆ†
#---------------------------------------------------


with pm.Model() as model4:

    beta_0 = pm.Normal("beta_0", mu=..., sigma=...)            
    beta_1 = pm.Normal("beta_1", mu=..., sigma=...)        
    sigma = pm.Exponential("sigma", ...)               

    x = pm.MutableData("smoke",df.stress)                   
    mu = pm.Deterministic("mu", beta_0 + beta_1*x)          

    likelihood = pm.Normal("y_est", mu=mu, sigma=sigma, observed=df.scontrol)


with pm.Model() as model5:

    beta_0 = pm.Normal("beta_0", mu=..., sigma=...)                
    beta_1 = pm.Normal("beta_1", mu=..., sigma=...)          
    beta_2 = pm.Normal("beta_2", mu=..., sigma=...)           
    sigma = pm.Exponential("sigma", ...)                   

    stress = pm.MutableData("stress",df.stress)                          
    smoke = pm.MutableData("smoke",df.smoke)                              
    mu = pm.Deterministic("mu", beta_0 + beta_1*stress + beta_2*smoke)    

    likelihood = pm.Normal("y_est", mu=mu, sigma=sigma, observed=df.scontrol) 

with pm.Model() as model6:
    beta_0 = pm.Normal("beta_0", mu=..., sigma=...)        
    beta_1 = pm.Normal("beta_1", mu=..., sigma=...)        
    beta_2 = pm.Normal("beta_2", mu=..., sigma=...)        
    beta_3 = pm.Normal("beta_3", mu=..., sigma=...)          
    sigma = pm.Exponential("sigma", ...)                 

    stress = pm.MutableData("stress",df.stress)      
    smoke = pm.MutableData("smoke",df.smoke)         
    mu = pm.Deterministic("mu", beta_0 + 
                                beta_1*stress + 
                                beta_2*smoke +
                                beta_3*stress*smoke)      

    likelihood = pm.Normal("y_est", mu=mu, sigma=sigma, observed=df.scontrol)
```

```python
#========================================
#     æ³¨æ„ï¼ï¼ï¼ä»¥ä¸‹ä»£ç å¯èƒ½éœ€è¦è¿è¡Œ 5 åˆ†é’Ÿå·¦å³,ç›´æ¥è¿è¡Œå³å¯
#     ç›´æ¥è¿è¡Œå³å¯ï¼Œæ— éœ€ä¿®æ”¹
#========================================

def run_model_sampling(save_name, model=None, draws=2000, tune=1000, chains=4, random_seed=84735):
    """
    è¿è¡Œæ¨¡å‹é‡‡æ ·ï¼Œå¹¶åœ¨ç»“æœä¸å­˜åœ¨æ—¶è¿›è¡Œé‡‡æ ·ï¼Œå­˜åœ¨æ—¶ç›´æ¥åŠ è½½ç»“æœã€‚

    Parameters:
    - save_name: ç”¨äºä¿å­˜æˆ–åŠ è½½ç»“æœçš„æ–‡ä»¶åï¼ˆæ— æ‰©å±•åï¼‰
    - model: pymc æ¨¡å‹
    - draws: é‡‡æ ·æ¬¡æ•° (é»˜è®¤5000)
    - tune: è°ƒæ•´é‡‡æ ·ç­–ç•¥çš„æ¬¡æ•° (é»˜è®¤1000)
    - chains: é“¾æ•° (é»˜è®¤4)
    - random_seed: éšæœºç§å­ (é»˜è®¤84735)

    Returns:
    - trace: é‡‡æ ·ç»“æœ
    """
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¿å­˜çš„.ncæ–‡ä»¶
    nc_file = f"{save_name}.nc"
    if os.path.exists(nc_file):
        print(f"åŠ è½½ç°æœ‰çš„é‡‡æ ·ç»“æœï¼š{nc_file}")
        # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œåˆ™åŠ è½½é‡‡æ ·ç»“æœ
        trace = az.from_netcdf(nc_file)
    else:

        assert model is not None, "æ¨¡å‹æœªå®šä¹‰ï¼Œè¯·å…ˆå®šä¹‰æ¨¡å‹"

        print(f"æ²¡æœ‰æ‰¾åˆ°ç°æœ‰çš„é‡‡æ ·ç»“æœï¼Œæ­£åœ¨æ‰§è¡Œé‡‡æ ·ï¼š{save_name}")
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™è¿›è¡Œé‡‡æ ·è®¡ç®—
        with model:
            trace = pm.sample_prior_predictive(draws=draws, random_seed=random_seed)
            idata = pm.sample(draws=draws,                   # ä½¿ç”¨mcmcæ–¹æ³•è¿›è¡Œé‡‡æ ·ï¼Œdrawsä¸ºé‡‡æ ·æ¬¡æ•°
                              tune=tune,                    # tuneä¸ºè°ƒæ•´é‡‡æ ·ç­–ç•¥çš„æ¬¡æ•°
                              chains=chains,                # é“¾æ•°
                              discard_tuned_samples=True,   # tuneçš„ç»“æœå°†åœ¨é‡‡æ ·ç»“æŸåè¢«ä¸¢å¼ƒ
                              idata_kwargs={"log_likelihood": True},
                              random_seed=random_seed)      # åéªŒé‡‡æ ·

            trace.extend(idata)
            # è¿›è¡ŒåéªŒé¢„æµ‹å¹¶æ‰©å±•æ¨æ–­æ•°æ®
            pm.sample_posterior_predictive(trace, extend_inferencedata=True, random_seed=random_seed)
            
            # ä¿å­˜ç»“æœåˆ°æŒ‡å®šæ–‡ä»¶
        trace.to_netcdf(nc_file)
        
    return trace


# è¿è¡Œæ‰€æœ‰ä¸‰ä¸ªæ¨¡å‹
model4_trace = run_model_sampling("lec10_model4",model4)
model5_trace = run_model_sampling("lec10_model5",model5)
model6_trace = run_model_sampling("lec10_model6",model6)
```

```python
# ç›´æ¥è¿è¡Œå³å¯ï¼Œæ— éœ€ä¿®æ”¹
# å°†3ä¸ªæ¨¡å‹ä¸­çš„inference data ä¸­çš„ y_est ç»Ÿä¸€æ”¹ä¸º Y_obs

model4_trace = model4_trace.rename({"y_est": "Y_obs"})
model5_trace = model5_trace.rename({"y_est": "Y_obs"})
model6_trace = model6_trace.rename({"y_est": "Y_obs"})
```

## è®¡ç®—MAE

```python
# ç›´æ¥è¿è¡Œå³å¯ï¼Œæ— éœ€ä¿®æ”¹
def calculate_mae(trace, observed_data, dv = "Y_obs"):
    """
    è®¡ç®—åéªŒé¢„æµ‹å‡å€¼å’Œ MAE (Median Absolute Error)ã€‚
    
    Parameters:
    - trace: PyMC æ¨¡å‹çš„é‡‡æ ·ç»“æœ (InferenceData å¯¹è±¡)ã€‚
    - observed_data: åŒ…å«çœŸå®è§‚æµ‹å€¼çš„ Pandas DataFrameã€‚
    - dv: éœ€è¦è®¡ç®— MAE çš„æ•°æ®åˆ—åï¼Œé»˜è®¤ä¸º "Y_obs"ã€‚

    Returns:
    - posterior_mean: åéªŒé¢„æµ‹å€¼çš„å‡å€¼ã€‚
    - mae: åéªŒé¢„æµ‹å‡å€¼ä¸è§‚æµ‹å€¼ä¹‹é—´çš„ MAEã€‚
    """

    # æå–åéªŒé¢„æµ‹å€¼
    posterior_predictive = trace.posterior_predictive[dv]
    
    # è®¡ç®—åéªŒé¢„æµ‹å‡å€¼ï¼ˆåœ¨ draw å’Œ chain ä¸¤ä¸ªç»´åº¦ä¸Šå–å¹³å‡å€¼ï¼‰
    posterior_mean = posterior_predictive.mean(dim=["chain", "draw"])
    
    # è®¡ç®— MAEï¼ˆç»å¯¹è¯¯å·®çš„ä¸­ä½æ•°ï¼‰
    mae = np.median(np.abs(observed_data - posterior_mean))
    
    return mae
```

```python
##================================================
#                ç»ƒä¹ ï¼Œä¿®æ”¹... éƒ¨åˆ†
#                
#================================================

pd.DataFrame({
    "Model 4": [calculate_mae(model4_trace, df["..."], "...")],
    "Model 5": [calculate_mae(model5_trace, df["..."], "...")],
    "Model 6": [calculate_mae(model6_trace, df["..."], "...")],
})
```

<style>
.center 
{
  width: auto;
  display: table;
  margin-left: auto;
  margin-right: auto;
}
</style>
<div class="center">

||Model4|Model5|Model6|
| :-----------: | :-----------: | :-----------: | :-----------: |
|0|3.417442	|3.525749|3.548162|
</div>

## è®¡ç®—elpd_loo

```python
##================================================
#                ç»ƒä¹ ï¼Œä¿®æ”¹... éƒ¨åˆ†       
#================================================

comparison_list = {
    "model4(contiunous)":...,
    "model5(multivariate )":...,
    "model6(interaction)":...,
}
az.compare(comparison_list)
```

## è®¡ç®—DIC

```python
# ç›´æ¥è¿è¡Œå³å¯ï¼Œæ— éœ€ä¿®æ”¹
def calculate_dic(log_likelihood):
    """
    æ ¹æ® log-likelihood è®¡ç®— DIC (Deviance Information Criterion)ã€‚ å‚è€ƒ Evans, N. J. (2019). Assessing the practical differences between model selection methods in inferences about choice response time tasks. Psychonomic Bulletin & Review, 26(4), 1070â€“1098. https://doi.org/10.3758/s13423-018-01563-9
    
    Parameters:
    - log_likelihood: xarray æ•°æ®é›†ï¼ŒåŒ…å«æ¯ä¸ªé“¾å’Œæ ·æœ¬çš„ log-likelihood å€¼ã€‚
    
    Returns:
    - dic: è®¡ç®—å¾—åˆ°çš„ DIC å€¼ã€‚
    """
    # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„Deviance
    deviance_samples = -2 * log_likelihood
    
    # è®¡ç®—å¹³å‡Deviance
    D_bar = deviance_samples.mean()
    
    # è®¡ç®—æœ‰æ•ˆè‡ªç”±åº¦ p_D
    p_D = deviance_samples.max() - D_bar
    
    # è®¡ç®—DIC
    DIC = -2 * (D_bar - p_D)
    
    return DIC["Y_obs"].values
```

```python
##================================================
#                ç»ƒä¹ ï¼Œä¿®æ”¹... éƒ¨åˆ†
#                
#================================================

DIC_list = {
    "m4_dic_value":calculate_dic(...),
    "m5_dic_value":calculate_dic(...),
    "m6_dic_value":calculate_dic(...),
}
```

## æ€»ç»“

æœ¬èŠ‚è¯¾ä»ä¸åŒæ¨¡å‹è¯„ä¼°çš„è§’åº¦ï¼Œä»‹ç»äº†æ¨¡å‹è¯„ä¼°ä¸æ¯”è¾ƒçš„åŸºæœ¬æ€æƒ³ã€‚

é€šè¿‡å­¦ä¹ ï¼Œæˆ‘ä»¬å¯¹è´å¶æ–¯åˆ†æçš„æ•´ä½“æµç¨‹ï¼ˆBayesian workflowï¼‰æœ‰äº†åˆæ­¥çš„ç†è§£ã€‚

åœ¨æ¥ä¸‹æ¥çš„è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä¸æ–­å®è·µè¿™ä¸€æµç¨‹ï¼Œå¸®åŠ©å¤§å®¶æ›´æ·±å…¥åœ°é¢†ç•¥è´å¶æ–¯åˆ†æçš„ç‹¬ç‰¹é­…åŠ›ã€‚

![alt text](image-15.png)