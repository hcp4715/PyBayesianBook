# Lecture14 : Hierarchical Regression Models

## Intro

åœ¨ä¸Šä¸€èŠ‚è¯¾ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†**åˆ†å±‚æ¨¡å‹ (Hierarchical Models) çš„åŸºæœ¬æ¦‚å¿µ**ï¼Œå¹¶æ¢è®¨äº†åˆ†å±‚æ¨¡å‹çš„åº”ç”¨ï¼Œç„¶è€Œè¿™äº›æ¨¡å‹æ²¡æœ‰è€ƒè™‘å®éªŒæ¡ä»¶çš„å½±å“ã€‚

å› æ­¤ï¼Œä¸ºäº†æ£€éªŒå®éªŒæ¡ä»¶åœ¨æ¯ä¸ªè¢«è¯•ä¸­çš„æ•ˆåº”å¤§å°ï¼Œéœ€è¦ç»“åˆå›å½’åˆ†ææ–¹æ³•ã€‚

- æœ¬èŠ‚è¯¾å°†**åˆ†å±‚æ¨¡å‹ä¸å›å½’æ¨¡å‹ç›¸ç»“åˆ**ï¼Œé‡ç‚¹è®²è§£åˆ†å±‚çº¿æ€§æ¨¡å‹ (Hierarchical Regression Models) çš„åº”ç”¨ã€‚

åœ¨å‰å‡ æ¬¡è¯¾çš„ç»ƒä¹ ä¸­è®¨è®ºäº†â€œå‹åŠ›ä¸è‡ªæˆ‘æ§åˆ¶å…³ç³»â€çš„ä¾‹å­ï¼Œæœ¬èŠ‚è¯¾å°†ä»¥è¯¥ä¾‹å­ä»‹ç»**åˆ†å±‚çº¿æ€§æ¨¡å‹**çš„åŸºæœ¬æ¦‚å¿µï¼Œåœ¨ç»ƒä¹ é˜¶æ®µæ—¶å†å›åˆ°éšæœºç‚¹è¿åŠ¨èŒƒå¼çš„æƒ…å¢ƒã€‚

![alt text](image-1.png)

![alt text](image.png)

åœ¨ä¸ŠèŠ‚è¯¾çš„ç»ƒä¹ ä¸­ä»…è€ƒè™‘äº†**è‡ªæˆ‘æ§åˆ¶åˆ†æ•°åœ¨ä¸åŒç«™ç‚¹å’Œä¸åŒä¸ªä½“é—´çš„å˜åŒ–ã€‚**

ğŸ¤” ç„¶è€Œï¼Œæˆ‘ä»¬æ›´æƒ³å›ç­”çš„é—®é¢˜æ˜¯ï¼Œå‹åŠ›å¯¹è‡ªæˆ‘æ§åˆ¶çš„å½±å“æ˜¯å¦åœ¨ä¸åŒç«™ç‚¹é—´å­˜åœ¨å·®å¼‚ï¼Ÿ

![alt text](image-2.png)

- å¦‚å›¾Aï¼šä¸€ç§ä¸å¤ªå¯èƒ½çš„æƒ…æ™¯æ˜¯ï¼Œä¸åŒç«™ç‚¹é—´çš„è‡ªæˆ‘æ§åˆ¶åˆ†æ•°æ²¡æœ‰å·®å¼‚ï¼Œå¹¶ä¸”å‹åŠ›å¯¹è‡ªæˆ‘æ§åˆ¶çš„å½±å“åœ¨ä¸åŒç«™ç‚¹é—´ä¹Ÿç›¸åŒã€‚

- å¦‚å›¾Bï¼šä¸€ç§å¯èƒ½æ˜¯ï¼Œè‡ªæˆ‘æ§åˆ¶åˆ†æ•°åœ¨ä¸åŒç«™ç‚¹é—´å­˜åœ¨å·®å¼‚ï¼Œä½†æ˜¯å‹åŠ›å¯¹è‡ªæˆ‘æ§åˆ¶çš„å½±å“åœ¨ä¸åŒç«™ç‚¹ä¸å­˜åœ¨å·®å¼‚ã€‚

- å¦‚å›¾Cï¼šå¦ä¸€ç§å¯èƒ½æ˜¯ï¼Œç«™ç‚¹åªè°ƒèŠ‚å‹åŠ›å¯¹è‡ªæˆ‘æ§åˆ¶çš„å½±å“ï¼Œè€Œå„ç«™ç‚¹é—´è‡ªæˆ‘æ§åˆ¶åˆ†æ•°ç›¸å½“ã€‚

- å¦‚å›¾Dï¼šæœ€åï¼Œç«™ç‚¹å¯èƒ½æ—¢å½±å“è‡ªæˆ‘æ§åˆ¶åˆ†æ•°ï¼Œåˆå½±å“å‹åŠ›å¯¹è‡ªæˆ‘æ§åˆ¶çš„æ•ˆåº”ã€‚

**åœ¨æœ¬èŠ‚è¯¾ä¸­ï¼Œå°†ä»‹ç»å¼•å…¥åŒ…å«è‡ªå˜é‡æ—¶çš„åˆ†å±‚æ¨¡å‹ï¼Œå¹¶é€šè¿‡ä¸åŒçš„æ¨¡å‹éªŒè¯ä¸åŒçš„å‡è®¾ï¼š**

![alt text](image-3.png)

- $H_0(model 0)$ï¼Œå›¾Aï¼Œæ™®é€šçº¿æ€§æ¨¡å‹ï¼Œä»…è€ƒè™‘å‹åŠ›å¯¹è‡ªæˆ‘æ§åˆ¶çš„å½±å“ã€‚

- $H_1(model 1)$ï¼Œå›¾Bï¼Œå˜åŒ–æˆªè·æ¨¡å‹(æ–œç‡ç›¸åŒ)ï¼Œåœ¨æ¨¡å‹0çš„åŸºç¡€ä¸Šè€ƒè™‘è‡ªæˆ‘æ§åˆ¶åœ¨ä¸åŒç«™ç‚¹çš„å˜åŒ–ã€‚

- $H_2(model 2)$ï¼Œå›¾Cï¼Œå˜åŒ–æ–œç‡æ¨¡å‹ï¼ˆæˆªè·ç›¸åŒï¼‰ï¼Œåœ¨æ¨¡å‹0çš„åŸºç¡€ä¸Šä¸åŒç«™ç‚¹é—´çš„å‹åŠ›å½±å“çš„å˜åŒ–ã€‚

- $H_3(model 3)$ï¼Œå›¾Dï¼Œå˜åŒ–æˆªè·å’Œæ–œç‡æ¨¡å‹ï¼Œç»“åˆæ¨¡å‹1å’Œæ¨¡å‹2ï¼ŒåŒæ—¶è€ƒè™‘ç«™ç‚¹å¯¹è‡ªæˆ‘æ§åˆ¶ä»¥åŠå‹åŠ›å½±å“çš„å˜åŒ–ã€‚

**å›é¡¾ï¼šè´å¶æ–¯å›å½’æ¨¡å‹çš„æ•°å­¦è¡¨è¾¾å¼**

$$
\beta_0 \sim N(m_0,s_0^2)\\
\beta_1 \sim N(m_1,s_1^2)\\
\sigma \sim Exp(\lambda)\\
\downarrow\\
\mu_i=\beta_0+\beta_1X_i\\
\downarrow\\
Y_i|\beta_0,\beta_1,\sigma \sim N(\mu_i,\sigma^2)
$$

**å›å½’æ¨¡å‹éœ€æ»¡è¶³å¦‚ä¸‹å‡è®¾ï¼š**

- ç‹¬ç«‹è§‚æµ‹å‡è®¾ï¼šæ¯ä¸ªè§‚æµ‹å€¼$Y_i$æ˜¯ç›¸äº’ç‹¬ç«‹çš„ã€‚

- çº¿æ€§å…³ç³»å‡è®¾ï¼šé¢„æµ‹å€¼$\mu_i$å’Œè‡ªå˜é‡$X_i$ä¹‹é—´å¯ä»¥ç”¨çº¿æ€§å…³ç³»æ¥æè¿°ï¼Œå³ï¼š$\mu_i=\beta_0+\beta_1X_i$

- æ–¹å·®åŒè´¨æ€§å‡è®¾ï¼šåœ¨ä»»æ„è‡ªå˜é‡çš„å–å€¼ä¸‹ï¼Œè§‚æµ‹å€¼$Y_i$éƒ½ä¼šä»¥$\mu_i$ä¸ºä¸­å¿ƒï¼Œä»¥ç›¸åŒçš„æ ‡å‡†å·®$\sigma$å‘ˆæ­£æ€åˆ†å¸ƒå˜åŒ–ã€‚

**è´å¶æ–¯å›å½’æ¨¡å‹çš„ä¼˜åŠ¿ï¼š**

å…è®¸å°†å®éªŒå‡è®¾ä»¥å›å½’å‚æ•°çš„å½¢å¼è¿›è¡Œè¡¨è¾¾ï¼Œå¹¶é€šè¿‡åéªŒåˆ†å¸ƒæ¥é‡åŒ–è¿™äº›å‡è®¾çš„åˆç†æ€§ã€‚

$$
RT_{sec} \sim N(\beta_0+\beta_1Â·Label,\sigma^2)
$$

- é€šè¿‡åéªŒåˆ†å¸ƒæ£€éªŒ$\beta_1$æ˜¯å¦æ˜¾è‘—ï¼Œä¾‹å¦‚è®¡ç®—$\beta_1>0$æˆ–$\beta_1<0$çš„æ¦‚ç‡ï¼Œè®¡ç®—æœ€é«˜å¯†åº¦åŒºé—´HDIã€‚å¦‚æœ95%HDIä¸åŒ…å«0ï¼Œå¯ä»¥è®¤ä¸ºè‡ªæˆ‘æ¡ä»¶å’Œä»–äººæ¡ä»¶åœ¨ååº”æ—¶ä¸Šçš„å·®å¼‚æ˜¯æ˜¾è‘—çš„ã€‚

- åœ¨è´å¶æ–¯æ¡†æ¶ä¸‹ï¼Œä¸ä»…å¯ä»¥è§‚å¯Ÿå‚æ•°çš„ç‚¹ä¼°è®¡ï¼ˆå¦‚$\beta_1$çš„å‡å€¼ï¼‰ï¼Œè¿˜å¯ä»¥é€šè¿‡åéªŒåˆ†å¸ƒå’Œ HDI æä¾›æ›´åŠ ç›´è§‚çš„ç½®ä¿¡æ°´å¹³è§£é‡Šã€‚

![alt text](image-4.png)

> æ”¹ç¼–è‡ªï¼šhttps: // saylordotorg.github.io/text_introductory-statistics/s14-03-modelling-linear-relationships.html

## Model0: Complete pooling

ä»¥ â€œå‹åŠ›ä¸è‡ªæˆ‘æ§åˆ¶å…³ç³»â€ ä¸ºä¾‹ï¼Œ å¦‚æœå¿½ç•¥æ•°æ®çš„åˆ†å±‚ç»“æ„ï¼Œè®¤ä¸ºæ‰€æœ‰æ•°æ®éƒ½æ¥è‡ªä¸€ä¸ªæ›´å¤§çš„æ€»ä½“(ä¸åŒºåˆ†ç«™ç‚¹)ï¼Œåªéœ€è¦ç”¨ä¸€ä¸ªå›å½’æ–¹ç¨‹æ¥æè¿°è‡ªå˜é‡ä¸å› å˜é‡çš„å…³ç³»ã€‚

data:

$$
Y_i|\beta_0,\beta_1,\sigma~~\overset{ind}{\sim}~~N(\mu_i,\sigma^2)~~with~~\mu_i=\beta_0+\beta_1X_i
$$

priors:

$$
\beta_0~~\sim~~N(0,50^2)\\
\beta_1~~\sim~~N(0,5^2)\\
\sigma~~\sim~~Exp(1)
$$

- å…¶ä¸­ï¼Œ$Y_i$æ˜¯ç¬¬iä¸ªè¢«è¯•çš„è‡ªæˆ‘æ§åˆ¶åˆ†æ•°

- $X_i$æ˜¯ç¬¬iä¸ªè¢«è¯•çš„å‹åŠ›å¾—åˆ†

- $\beta_0å’Œ\beta_1$æ˜¯å›å½’ç³»æ•°ï¼Œ$\sigma$æ˜¯æ®‹å·®çš„æ ‡å‡†å·®

- $\beta_1$ä»£è¡¨äº†å‹åŠ›ä¸è‡ªæˆ‘æ§åˆ¶ä¹‹é—´çš„å…³ç³»

![alt text](image-5.png)

```python
# å¯¼å…¥ pymc æ¨¡å‹åŒ…ï¼Œå’Œ arviz ç­‰åˆ†æå·¥å…· 
import pymc as pm
import arviz as az
import seaborn as sns
import scipy.stats as st
import numpy as np
import matplotlib.pyplot as plt
import xarray as xr
import pandas as pd
import ipywidgets
import bambi as bmb

# å¿½ç•¥ä¸å¿…è¦çš„è­¦å‘Š
import warnings
warnings.filterwarnings("ignore")
```

```python
# é€šè¿‡ pd.read_csv åŠ è½½æ•°æ® Data_Sum_HPP_Multi_Site_Share.csv
try:
  df_raw = pd.read_csv('/home/mw/input/bayes3797/Data_Sum_HPP_Multi_Site_Share.csv')
except:
  df_raw = pd.read_csv('data/Data_Sum_HPP_Multi_Site_Share.csv')

# é€‰å–æ‰€éœ€ç«™ç‚¹
first5_site = ['Southampton','Portugal','Kassel','Tsinghua','UCSB']
df_first5 = df_raw.query("Site in @first5_site")
# ç”Ÿæˆç«™ç‚¹ç´¢å¼•
df_first5["site_idx"] = pd.factorize(df_first5.Site)[0]
# ç”Ÿæˆè¢«è¯•æ•°ç´¢å¼•
df_first5["obs_id"] = range(len(df_first5))
# å°†ç«™ç‚¹ã€è¢«è¯•idè®¾ç½®ä¸ºç´¢å¼•
df_first5.set_index(['Site','obs_id'],inplace=True,drop=False)
df_first5
```

åœ¨å¤„ç†æ•°æ®ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæŒ‰ç…§å®Œå…¨æ± åŒ–çš„æ–¹å¼è¿›è¡Œå¯è§†åŒ–ï¼Œå³ä¸åŒºåˆ†ç«™ç‚¹ï¼ŒæŠŠæ‰€æœ‰è¢«è¯•å½“æˆä¸€ä¸ªç¾¤ä½“ã€‚

```python
# é€šè¿‡å®Œå…¨æ± åŒ–çš„æ–¹å¼å¯è§†åŒ–æ•°æ®
sns.lmplot(df_first5,
           x="stress",
           y="scontrol",
           height=4, aspect=1.5)
```

![alt text](image-6.png)

**æ¨¡å‹å®šä¹‰ä¸é‡‡æ ·**

data:

$$
Y_i|\beta_0,\beta_1,\sigma~~\overset{ind}{\sim}~~N(\mu_i,\sigma^2)~~with~~\mu_i=\beta_0+\beta_1X_i
$$

priors:

$$
\beta_0~~\sim~~N(0,50^2)\\
\beta_1~~\sim~~N(0,5^2)\\
\sigma~~\sim~~Exp(1)
$$

```python
# å®šä¹‰åæ ‡æ˜ å°„
coords = {"obs_id": df_first5.obs_id}

with pm.Model(coords=coords) as complete_pooled_model:

    beta_0 = pm.Normal("beta_0", mu=0, sigma=50)                #å®šä¹‰beta_0          
    beta_1 = pm.Normal("beta_1", mu=0, sigma=5)                 #å®šä¹‰beta_1
    sigma = pm.Exponential("sigma", 1)                          #å®šä¹‰sigma

    x = pm.MutableData("x", df_first5.stress, dims="obs_id")    #xæ˜¯è‡ªå˜é‡å‹åŠ›æ°´å¹³

    mu = pm.Deterministic("mu",beta_0 + beta_1 * x, 
                          dims="obs_id")                        #å®šä¹‰muï¼Œè®²è‡ªå˜é‡ä¸å…ˆéªŒç»“åˆ

    likelihood = pm.Normal("y_est", mu=mu, sigma=sigma, observed=df_first5.scontrol,
                           dims="obs_id")                       #å®šä¹‰ä¼¼ç„¶ï¼šé¢„æµ‹å€¼yç¬¦åˆN(mu, sigma)åˆ†å¸ƒ
                                                                #é€šè¿‡ observed ä¼ å…¥å®é™…æ•°æ®y è‡ªæˆ‘æ§åˆ¶æ°´å¹³
    complete_trace = pm.sample(random_seed=84735)
```

```python
pm.model_to_graphviz(complete_pooled_model)
```

![alt text](image-7.png)

**åéªŒå‚æ•°ä¼°è®¡ï¼š**

ç»“æœæ˜¾ç¤ºï¼š

$$
\mu_i=\beta_0+\beta_1X_i\\
\beta_0=63.17\\
\beta_1=-0.58
$$

- $\beta_1=-0.58$è¡¨æ˜ï¼Œåœ¨ç»™å®šç«™ç‚¹çš„æƒ…å†µä¸‹ï¼Œè‡ªæˆ‘æ§åˆ¶æ°´å¹³ä¸å‹åŠ›æ°´å¹³ä¹‹é—´å­˜åœ¨è´Ÿç›¸å…³å…³ç³»ã€‚å¹¶ä¸”ï¼Œå‹åŠ›åˆ†æ•°æ¯å¢åŠ 1åˆ†ï¼Œè‡ªæˆ‘æ§åˆ¶æ°´å¹³å¹³å‡ä¸‹é™0.58åˆ†ã€‚

```python
az.summary(complete_trace,
           var_names=["~mu"],
           filter_vars="like")
```

![alt text](image-8.png)

**åéªŒé¢„æµ‹å›å½’çº¿**

```python
#æå–ä¸åŒç«™ç‚¹æ•°æ®å¯¹åº”çš„ç´¢å¼•å¹¶å‚¨å­˜ï¼Œä¾¿äºåç»­å°†åéªŒé¢„æµ‹æ•°æ®æŒ‰ç…§ç«™ç‚¹è¿›è¡Œæå–
def get_group_index(data):
    group_index = {}
    for i, group in enumerate(data["Site"].unique()):
        group_index[group] = xr.DataArray(data.query(f"Site == '{group}'"))["obs_id"].values
    return group_index

#å®šä¹‰å‡½æ•°ï¼Œç»˜åˆ¶ä¸åŒç«™ç‚¹ä¸‹çš„åéªŒé¢„æµ‹å›å½’çº¿
def plot_regression(data, trace, group_index):
    # å®šä¹‰ç”»å¸ƒï¼Œæ ¹æ®ç«™ç‚¹æ•°é‡å®šä¹‰ç”»å¸ƒçš„åˆ—æ•°
    fig, ax = plt.subplots(1,len(data["Site"].unique()), 
                       sharex=True,
                       sharey=True,
                       figsize=(15,5))
    
    # æ ¹æ®ç«™ç‚¹æ•°æ¥åˆ†åˆ«ç»˜å›¾
    # éœ€è¦çš„æ•°æ®æœ‰åŸå§‹æ•°æ®ï¼Œæ¯ä¸€ä¸ªå› å˜é‡çš„åéªŒé¢„æµ‹å‡å€¼
    # è¿™äº›æ•°æ®éƒ½å‚¨å­˜åœ¨åéªŒå‚æ•°é‡‡æ ·ç»“æœä¸­ï¼Œä¹Ÿå°±æ˜¯è¿™é‡Œæ‰€ç”¨çš„trace
    for i, group in enumerate(data["Site"].unique()):
        #ç»˜åˆ¶çœŸå®æ•°æ®çš„æ•£ç‚¹å›¾
        x = trace.constant_data.x.sel(obs_id = group_index[f"{group}"])
        y = trace.observed_data.y_est.sel(obs_id = group_index[f"{group}"])
        mu = trace.posterior.mu.sel(obs_id = group_index[f"{group}"])
        ax[i].scatter(x, y,
                color=f"C{i}",
                alpha=0.5)
        #ç»˜åˆ¶å›å½’çº¿
        ax[i].plot(x, mu.stack(sample=("chain","draw")).mean(dim="sample"),
                color=f"C{i}",
                alpha=0.5)
        #ç»˜åˆ¶é¢„æµ‹å€¼95%HDI
        az.plot_hdi(
            x, mu,
            hdi_prob=0.95,
            fill_kwargs={"alpha": 0.25, "linewidth": 0},
            color=f"C{i}",
            ax=ax[i])
    # ç”Ÿæˆæ¨ªåæ ‡åç§°
    fig.text(0.5, 0, 'Stress', ha='center', va='center', fontsize=12)
    # ç”Ÿæˆçºµåæ ‡åç§°
    fig.text(0.08, 0.5, 'Self control', ha='center', va='center', rotation='vertical', fontsize=12)
    # ç”Ÿæˆæ ‡é¢˜
    plt.suptitle("Posterior regression models", fontsize=15)
        
    sns.despine()
```

```python
# è·å–æ¯ä¸ªç«™ç‚¹æ•°æ®çš„ç´¢å¼•
first5_index = get_group_index(data=df_first5)
# è¿›è¡Œå¯è§†åŒ–
plot_regression(data=df_first5,
                trace=complete_trace,
                group_index=first5_index)
```

![alt text](image-9.png)

- é€šè¿‡ä¸Šé¢çš„å›¾å¯ä»¥ç›´è§‚åœ°çœ‹å‡ºï¼Œä¸åŒç«™ç‚¹å›å½’çº¿çš„æ–œç‡å’Œæˆªè·å‡ ä¹æ˜¯ä¸€è‡´çš„ã€‚

- å®Œå…¨æ± åŒ–æ¨¡å‹å‡è®¾ï¼Œæ‰€æœ‰ç«™ç‚¹ä¸­è‡ªæˆ‘æ§åˆ¶åˆ†æ•°ä¸€è‡´ï¼Œå¹¶ä¸”å‹åŠ›çš„å½±å“ä¹Ÿä¸€è‡´ã€‚
