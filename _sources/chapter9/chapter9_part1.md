# Multivariable linear regression

## å›é¡¾

- åœ¨å‰é¢çš„ä¹æ¬¡è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬ç³»ç»Ÿæ€§åœ°ä»‹ç»äº†è´å¶æ–¯ç»Ÿè®¡çš„æ ¸å¿ƒæ¦‚å¿µï¼Œå¹¶é€šè¿‡ä¸€ä¸ªç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹å±•ç¤ºäº†å¦‚ä½•æ„å»ºå’Œåº”ç”¨ä¸€ä¸ªç›¸å¯¹ç®€å•çš„è´å¶æ–¯workflowã€‚

![alt text](image.png)

- è´å¶æ–¯å…¬å¼â€”â€”åŸºç¡€ï¼š

![alt text](image-1.png)

- ä¸ºäº†å¸®åŠ©å¤§å®¶å»ºç«‹å…³äºè´å¶æ–¯æ¨æ–­çš„ç›´è§‰ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸‰ç§æƒ…å¢ƒï¼šå•ä¸€äº‹ä»¶ã€ç¦»æ•£å˜é‡å’Œè¿ç»­å˜é‡ï¼š

<style>
.center 
{
  width: auto;
  display: table;
  margin-left: auto;
  margin-right: auto;
}
</style>
<div class="center">

|çŸ¥è¯†ç‚¹| å†…å®¹æè¿° | å…ˆéªŒ | ä¼¼ç„¶ | è´å¶æ–¯æ›´æ–° |
| :-----------: | :-----------: |:-----------: | :-----------: |:-----------: |
|å•ä¸ªäº‹ä»¶|ä¸€ä¸ªä½¿ç”¨ç‰¹å®šè¯­è¨€é£æ ¼çš„å¿ƒç†å­¦å®éªŒè¢«æˆåŠŸé‡å¤å‡ºæ¥çš„å¯èƒ½æ€§|OSC2015çš„ç»“æœ|	Herzenstein et al 2024å¹´çš„ç ”ç©¶ç»“æœ|	å¯è§†åŒ–çš„æ–¹å¼ + ç®€å•è®¡ç®—|
|ç¦»æ•£å˜é‡|å¤šæ¬¡è¯•éªŒ(å¤šæ¬¡è¿›è¡Œé‡å¤å®éªŒ)çš„æˆåŠŸç‡|äººä¸ºåˆ†é…çš„ä¸‰ç§æˆåŠŸç‡(0.2, 0.5, 0.8)å’Œå®ƒä»¬å‡ºç°çš„å¯èƒ½æ€§|è¿›è¡Œé‡å¤åçš„ç»“æœåœ¨ä¸‰ç§æˆåŠŸç‡ä¸‹å‡ºç°çš„å¯èƒ½æ€§|ç®€å•çš„æ‰‹åŠ¨è®¡ç®—|
|è¿ç»­å˜é‡|å¤šæ¬¡è¯•éªŒ(å¤šæ¬¡è¿›è¡Œé‡å¤å®éªŒ)çš„æˆåŠŸç‡/æ­£ç¡®ç‡|ç¬¦åˆæˆåŠŸç‡/æ­£ç¡®ç‡(0~1)ç‰¹ç‚¹å’Œå…ˆéªŒç»éªŒçš„æ¦‚ç‡åˆ†å¸ƒ|è¿›è¡Œé‡å¤åçš„ç»“æœåœ¨æ‰€æœ‰æˆåŠŸç‡/æ­£ç¡®ç‡ä¸‹å‡ºç°çš„å¯èƒ½æ€§|å·²è¢«è¯æ˜çš„ç»Ÿè®¡å­¦å…¬å¼|
</div>

åœ¨chapter8ã€9ä¸­ï¼Œæˆ‘ä»¬ä»¥ä¸€ä¸ªè®¤çŸ¥å®éªŒä¸­çš„ç ”ç©¶é—®é¢˜â€”â€”**è‡ªæˆ‘å’Œä»–äººæ¡ä»¶ä¸‹çš„ååº”æ—¶é—´æ˜¯å¦æœ‰å·®å¼‚** å‡ºå‘ï¼Œå»ºç«‹äº†ä¸€ä¸ªç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹ï¼Œå¹¶å®Œæˆäº†è´å¶æ–¯æ•°æ®åˆ†æçš„å…¨æµç¨‹ã€‚

![alt text](image-2.png)

> Sui, J., He, X., & Humphreys, G. W. (2012). Perceptual effects of social salience: Evidence from self-prioritization effects on perceptual matching. Journal of Experimental Psychology: Human Perception and Performance, 38(5), 1105â€“1117. https://doi.org/10.1037/a0029792

-ç„¶è€Œï¼Œæˆ‘ä»¬åœ¨çœŸå®çš„å®éªŒç ”ç©¶ä¸­å¾ˆå°‘åªæ¶‰åŠå•å› ç´ ä¸¤æ°´å¹³è®¾è®¡ï¼Œæ›´å¤šä¼šé‡‡ç”¨å¤šå› ç´ çš„è®¾è®¡ï¼Œå¹¶ä¸”éœ€è¦è€ƒå¯Ÿäº¤äº’ä½œç”¨ã€‚è‡³æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹è¿›å…¥æ›´çœŸå®çš„åœºæ™¯ï¼Œä½¿ç”¨è´å¶æ–¯æ•°æ®åˆ†ææ¥è§£å†³ä¸€ä¸ªçœŸå®çš„é—®é¢˜ã€‚

Suiç­‰äºº(2012)çš„çœŸå®æ•°æ®å¦‚ä¸‹(2*3çš„è¢«è¯•å†…è®¾è®¡)ï¼š

```python
# å¯¼å…¥ pymc æ¨¡å‹åŒ…ï¼Œå’Œ arviz ç­‰åˆ†æå·¥å…· 
import pymc as pm
import arviz as az
import seaborn as sns
import scipy.stats as st
import numpy as np
import matplotlib.pyplot as plt
import xarray as xr
import pandas as pd

# å¿½ç•¥ä¸å¿…è¦çš„è­¦å‘Š
import warnings
warnings.filterwarnings("ignore")
```

```python
try:
  df_raw = pd.read_csv('/home/mw/input/bayes3797/Kolvoort_2020_HBM_Exp1_Clean.csv')
except:
  df_raw = pd.read_csv('/data/Kolvoort_2020_HBM_Exp1_Clean.csv')

df = df_raw.groupby(['Subject','Label', 'Matching'], as_index=False)['RT_sec'].mean()

# å°† Label åˆ—çš„æ•°å­—ç¼–ç è½¬ä¸ºæ–‡å­—æ ‡ç­¾
df['Label'] = df['Label'].replace({1: 'Self', 2: 'Friend', 3: 'Stranger'})

df['Matching'] = df['Matching'].replace({'Matching': 'matching', 'Nonmatching': 'nonmatching'})

# è®¾ç½®ç´¢å¼•
df["index"] = range(len(df))
df = df.set_index("index")

df
```

![alt text](image-3.png)

```python
print(f"Labelåˆ—å…±æœ‰ {df['Label'].unique()} ç±»" )
```
Labelåˆ—å…±æœ‰ ['Self' 'Friend' 'Stranger'] ç±»

é€šè¿‡æŸ¥çœ‹æ•°æ®å¯çŸ¥ï¼Œåœ¨è‡ªæˆ‘åŒ¹é…ä»»åŠ¡ä¸­ï¼Œè¢«è¯•å­¦ä¹ å‡ ä½•å›¾å½¢å’Œèº«ä»½æ ‡ç­¾çš„å…³ç³»åº”ä¸ºï¼Œä¾‹å¦‚ï¼Œä¸‰è§’å½¢ä»£è¡¨è‡ªæˆ‘ï¼ˆSelfï¼‰ï¼›åœ†å½¢ä»£è¡¨æœ‹å‹ï¼ˆFriendï¼‰ï¼Œæ­£æ–¹å½¢ä»£è¡¨é™Œç”Ÿäººï¼ˆStrangerï¼‰ï¼Œéšååˆ¤æ–­æ‰€å‘ˆç°çš„å‡ ä½•å›¾å½¢å’Œæ–‡å­—æ ‡ç­¾æ˜¯å¦ä¸ä¹‹å‰å­¦ä¹ çš„å…³ç³»ç›¸åŒ¹é…ã€‚

å› æ­¤ï¼ŒçœŸå®çš„å®éªŒæƒ…å¢ƒæ˜¯ä¸€ä¸ª2*3çš„è¢«è¯•å†…å®éªŒè®¾è®¡çš„æ•°æ®ã€‚å…¶ä¸­ï¼Œæ ‡ç­¾ï¼ˆè‡ªæˆ‘ç›¸å…³æ€§ï¼‰æ˜¯å¯ä»¥æœ‰ä¸‰ä¸ªæ°´å¹³çš„ï¼šè‡ªæˆ‘ã€æœ‹å‹å’Œé™Œç”Ÿäººã€‚

- å¦‚æœæˆ‘ä»¬å¯¹æ ‡ç­¾çš„æ•ˆåº”æ„Ÿå…´è¶£ï¼Œé‚£æˆ‘ä»¬å¯èƒ½å°±è¦å›ç­”ç¬¬ä¸€ä¸ªé—®é¢˜ï¼š**â€œä¸‰ç§Labelæ¡ä»¶ä¸‹çš„ååº”æ—¶å·®å¼‚æ˜¯æ€ä¹ˆæ ·çš„ï¼Ÿâ€**ï¼Œå³**å¦‚ä½•æ„å»ºâ€œLabelâ€å˜é‡ç¼–ç ä¸º3ä¸ªæ°´å¹³çš„çº¿æ€§æ¨¡å‹ï¼Ÿ**

- åŒæ—¶ï¼Œè¯¥å®éªŒè®¾è®¡è¿˜æœ‰å¦ä¸€ä¸ªè‡ªå˜é‡ï¼Œå³åŒ¹é…æ°´å¹³(â€œMatchingâ€)ï¼ŒåŒ…æ‹¬â€œåŒ¹é…â€å’Œâ€œä¸åŒ¹é…â€ä¸¤ä¸ªæ°´å¹³ã€‚è¿™ä¸ªè‡ªå˜é‡ä¼šå¯¹ååº”æ—¶é—´äº§ç”Ÿå½±å“å—ï¼Ÿè¿™æ˜¯ç¬¬äºŒä¸ªç ”ç©¶é—®é¢˜ï¼š**â€œåŒ¹é…æ°´å¹³(â€œmatchingâ€)æ˜¯å¦ä¼šå½±å“ååº”æ—¶é—´ï¼Ÿâ€**

- é€šå¸¸ï¼Œæˆ‘ä»¬ä¹Ÿå¯èƒ½æƒ³çŸ¥é“ç¬¬ä¸‰ä¸ªé—®é¢˜ï¼š**ä¸¤ä¸ªè‡ªå˜é‡ä¹‹é—´æ˜¯å¦æœ‰äº¤äº’ä½œç”¨**ï¼Ÿåœ¨ä¸åŒçš„åŒ¹é…æ°´å¹³(â€œmatchingâ€)ä¸‹ï¼Œæ ‡ç­¾â€œLabelâ€çš„æ•ˆåº”æ˜¯å¦ä¼šå‘ç”Ÿå˜åŒ–ï¼Ÿã€‚

æœ¬èŠ‚è¯¾æˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•åœ¨è´å¶æ–¯ç»Ÿè®¡æ¡†æ¶ä¸‹ï¼Œé€šè¿‡3ä¸ªçº¿æ€§å›å½’æ¨¡å‹æ¥å›ç­”ä»¥ä¸Šé—®é¢˜ï¼š

- ä¸‰æ°´å¹³çš„ç®€å•çº¿æ€§å›å½’æ¨¡å‹

- 2Ã—3çš„å¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹ï¼ˆæ— äº¤äº’ï¼‰

- 2Ã—3çš„å¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹ï¼ˆæœ‰äº¤äº’ï¼‰

æ³¨ï¼šä¸ºäº†ç®€åŒ–ç ”ç©¶é—®é¢˜ï¼Œæœ¬èŠ‚è¯¾ä½¿ç”¨çš„æ˜¯å¤šä¸ªè¢«è¯•çš„æ•°æ®ã€‚â€œSubjectâ€ ä¸ºè¢«è¯•ç¼–å·ï¼Œä»£è¡¨ä¸åŒè¢«è¯•ã€‚

æ­¤å¤–ï¼Œæ•°æ®ä¸­çš„å› å˜é‡ä¸æ˜¯å•ä¸ªè¯•æ¬¡ä¸‹è¢«è¯•çš„ååº”æ—¶å’Œæ­£ç¡®æ€§ï¼Œè€Œæ˜¯åœ¨**ä¸åŒæ¡ä»¶ä¸‹çš„å¹³å‡ååº”æ—¶å’Œæ­£ç¡®ç‡ã€‚**

## æ¨¡å‹ä¸€ï¼šä¸‰æ°´å¹³çš„ç®€å•çº¿æ€§å›å½’æ¨¡å‹

åœ¨å‰é¢ä¸¤æ¬¡è¯¾æ—¶ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†äºŒåˆ†ç±»ç¼–ç ï¼ˆä¾‹å¦‚Self = 0, Other = 1ï¼‰æ¥è¡¨ç¤ºâ€œLabelâ€æ¡ä»¶ï¼Œä½†è¿™æ¬¡æˆ‘ä»¬è€ƒè™‘çš„æ˜¯ä¸‰æ°´å¹³çš„å•å› ç´ â€œlabelâ€æ¡ä»¶ï¼ˆSelfã€Friendã€Strangerï¼‰ã€‚

ä¸ºäº†èƒ½å¯¹ç¦»æ•£çš„å¤šåˆ†ç±»å˜é‡å»ºç«‹å›å½’æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨**å“‘å˜é‡ç¼–ç **(dummy coding)æ¥å¤„ç†è¿™ç±»å¤šæ°´å¹³çš„è‡ªå˜é‡ã€‚

### å“‘å˜é‡ç¼–ç è§„åˆ™

å¯¹äºä¸‰æ°´å¹³åˆ†ç±»å˜é‡ â€œLabelâ€ (Self, Friend, Stranger)ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ **Treatment Coding ç¼–ç **ï¼Œä»¥ç¬¬ä¸€ä¸ªæ°´å¹³ "Self" ä½œä¸ºåŸºå‡†ï¼ˆbaselineï¼‰ã€‚

- åœ¨å›å½’åˆ†æä¸­ï¼Œè‡ªå˜é‡å¯ä»¥æ˜¯æ•°å€¼å‹çš„ï¼ˆå¦‚èº«é«˜ã€ä½“é‡ï¼‰æˆ–åˆ†ç±»å‹çš„ï¼ˆå¦‚æ€§åˆ«ã€å®éªŒç»„åˆ«ï¼‰ã€‚å¯¹äºåˆ†ç±»å˜é‡ï¼ˆå¦‚ Labelï¼šSelfã€Friendã€Strangerï¼‰ï¼Œå› ä¸º**å®ƒä»¬æ˜¯æ–‡æœ¬æˆ–ç±»åˆ«ï¼Œæ— æ³•ç›´æ¥è¾“å…¥åˆ°å›å½’æ¨¡å‹ä¸­ï¼Œå› æ­¤éœ€è¦å°†å®ƒä»¬è½¬æ¢ä¸ºæ•°å€¼å½¢å¼**ã€‚

treatmentç¼–ç æ˜¯å°†åˆ†ç±»å˜é‡è½¬åŒ–ä¸ºæ•°å€¼å‹å˜é‡çš„ä¸€ç§å¸¸è§æ–¹å¼ï¼Œé€šå¸¸æ˜¯ï¼š

- é€‰æ‹©ä¸€ä¸ªåŸºçº¿æ°´å¹³ï¼ˆBaseline levelï¼‰ï¼šé€šå¸¸æ˜¯åˆ†ç±»å˜é‡çš„ç¬¬ä¸€ä¸ªæ°´å¹³ã€‚

- åˆ›å»ºå“‘å˜é‡ï¼šé€šè¿‡ n-1 ä¸ªå¯¹æ¯”åˆ—ï¼Œè¡¨ç¤ºå…¶ä»–æ°´å¹³ç›¸å¯¹äºåŸºå‡†æ°´å¹³çš„å·®å¼‚ã€‚

é‚£ä¹ˆï¼Œå½“æˆ‘ä»¬é€‰æ‹©â€œselfâ€ä½œä¸ºåŸºçº¿æ°´å¹³ï¼Œç¼–ç çŸ©é˜µåº”è¯¥å¦‚ä¸‹ï¼š

<style>
.center 
{
  width: auto;
  display: table;
  margin-left: auto;
  margin-right: auto;
}
</style>
<div class="center">

|Label| æˆªè·(baseline) | å¯¹æ¯”åˆ— 1 (Friend vs Self) | å¯¹æ¯”åˆ— 2 (Stranger vs Self) |
| :-----------: | :-----------: |:-----------: | :-----------: |
|Self|1|0|0|
|Friend|1|1|0|
|Stranger|1|0|1|
</div>

- **æˆªè·(baseline)**ï¼šå¯¹åº” Selfï¼Œå³å½“æ‰€æœ‰å¯¹æ¯”åˆ—å€¼ä¸º 0 æ—¶ï¼Œæˆªè·$\beta_0$å¯¹åº”selfæ¡ä»¶ä¸‹å¹³å‡ååº”æ—¶çš„ä¼°ç®—å€¼ã€‚

- **å¯¹æ¯”åˆ—1ï¼ˆFriend vs Selfï¼‰**ï¼šåœ¨ç¬¬ä¸€åˆ—ä¸­ä¸º1ï¼Œè¡¨ç¤ºFriendç›¸å¯¹äºSelfçš„å·®å¼‚ã€‚

- **å¯¹æ¯”åˆ—2ï¼ˆStranger vs Selfï¼‰**ï¼šåœ¨ç¬¬äºŒåˆ—ä¸­ä¸º1ï¼Œè¡¨ç¤ºStrangerç›¸å¯¹äºSelfçš„å·®å¼‚ã€‚

***å…¶ä»–ç¼–ç æ¨¡å¼***

treatment codingè¿™ç§ä»¥ [0, 1] çš„ç¼–ç æ–¹å¼æ˜¯Rè¯­è¨€ä¸­çš„é»˜è®¤æ–¹å¼ï¼Œä¹Ÿç§°ä¸ºå“‘å˜é‡ç¼–ç ï¼ˆdummy codingï¼‰ã€‚è¿™ç§æ–¹å¼ä»¥ [0, 1] ä¸ºç¼–ç è§„åˆ™ï¼Œé»˜è®¤å°†ç¬¬ä¸€ä¸ªå› å­æ°´å¹³ä½œä¸ºå‚è€ƒç±»åˆ«ï¼ˆreference levelï¼‰ï¼Œå…¶ä»–æ°´å¹³ä¸å…¶è¿›è¡Œæ¯”è¾ƒã€‚

æ­¤å¤–æ— åºå› å­å¸¸ç”¨çš„è¿˜æœ‰sum codingï¼Œé‡‡ç”¨çš„æ˜¯[1, -1]çš„ç¼–ç æ–¹å¼ï¼Œä»¥ä½¿å› å­æ•ˆåº”åœ¨æ¨¡å‹ä¸­è¿›è¡ŒåŠ æƒå¹³å‡ã€‚

- å…¶ä»–çš„ç¼–ç æ–¹å¼è¿˜æœ‰å¾ˆå¤šï¼Œå¦‚æœæ„Ÿå…´è¶£ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹å‚è€ƒèµ„æ–™è‡ªè¡Œäº†è§£ã€‚ï¼ˆå°¤å…¶æ˜¯æœ€åä¸€ç¯‡æ–‡ç« ï¼Œå®ƒæ¯”è¾ƒè¯¦ç»†åœ°ä»‹ç»äº†å„ç§æƒ…å¢ƒä¸‹è¯¥å¦‚ä½•å»ºç«‹ç¼–ç çŸ©é˜µï¼Œè¿›è€Œé¡ºåˆ©è§£å†³ç ”ç©¶é—®é¢˜ï¼‰

<style>
.center 
{
  width: auto;
  display: table;
  margin-left: auto;
  margin-right: auto;
}
</style>
<div class="center">

|ç¼–ç æ–¹å¼|ç¼–ç è§„åˆ™|
| :-----------: | :-----------: |
|Treatment Coding|å‚è€ƒæ°´å¹³ç¼–ç ä¸º 0ï¼Œå…¶ä½™æ°´å¹³ç¼–ç ä¸º 1|
|Sum Coding|ä¸€ä¸ªæ°´å¹³ç¼–ç ä¸º -1ï¼Œå…¶ä½™æ°´å¹³ç¼–ç ä¸º 1ï¼Œæ‰€æœ‰ç³»æ•°å’Œä¸º 0|
|Helmert Coding|æ¯ä¸ªæ°´å¹³ä¸ä¹‹åæ‰€æœ‰æ°´å¹³çš„å¹³å‡å€¼æ¯”è¾ƒ|
|Orthogonal Polynomial Coding|ä½¿ç”¨æ­£äº¤å¤šé¡¹å¼ç¼–ç å‡½æ•°ï¼ˆçº¿æ€§ã€äºŒæ¬¡ã€ä¸‰æ¬¡è¶‹åŠ¿ï¼‰|
|Backward Difference Coding|æ¯ä¸ªæ°´å¹³ä¸å‰ä¸€ä¸ªæ°´å¹³æ¯”è¾ƒ|
|Custom Coding|ç”¨æˆ·è‡ªå®šä¹‰ç¼–ç è§„åˆ™|
</div>

> å‚è€ƒèµ„æ–™ï¼š
> 1.[Chapter 10 Contrasts | Analysing Data using Linear Models](https://bookdown.org/pingapang9/linear_models_bookdown/contrasts.html)
> 2.[Patsy: Contrast Coding Systems for categorical variables - statsmodels 0.15.0 (+522)](https://www.statsmodels.org/devel/contrasts.html)
> 3.[Coding for Categorical Variables in Regression Models | R Learning Modules](https://stats.oarc.ucla.edu/r/modules/coding-for-categorical-variables-in-regression-models/#:~:text=%E2%80%9CDummy%E2%80%9D%20or%20%E2%80%9Ctreatment%E2%80%9D%20coding%20basically%20consists%20of%20creating,variable%20is%20contrasted%20to%20a%20specified%20reference%20level.)
> 4.Schad, D. J., Vasishth, S., Hohenstein, S., & Kliegl, R. (2020). How to capitalize on a priori contrasts in linear (mixed) models: A tutorial.Journal of Memory and Language,110, 104038.

**ä¸ºä»€ä¹ˆéœ€è¦å“‘å˜é‡ç¼–ç ï¼Ÿ**

åœ¨ä¸‰æ°´å¹³ç®€å•çº¿æ€§å›å½’æ¨¡å‹ä¸­ï¼Œå› å˜é‡ï¼ˆYï¼šRT_secï¼‰å’Œåˆ†ç±»è‡ªå˜é‡Xï¼ˆLabelï¼šSelf, Friend, Strangerï¼‰çš„å…³ç³»å¯ä»¥è¡¨ç¤ºä¸ºï¼š

$$
Y=\beta_0+\beta_1Â·X_1+\beta_2Â·X_2+\epsilon_i
$$

- $\beta_0$ï¼šåŸºçº¿æ°´å¹³ï¼ˆbaselineï¼‰ï¼Œå³â€œselfâ€æ¡ä»¶ä¸‹çš„ååº”æ—¶å‡å€¼

- $\beta_1$ï¼šæ˜¯æŒ‡å½“$X_1$å–å€¼ä¸º1æ—¶ï¼Œâ€œfriendâ€æ¡ä»¶ä¸â€œselfâ€æ¡ä»¶çš„ååº”æ—¶ä¹‹å·®

- $\beta_1$ï¼šæ˜¯æŒ‡å½“$X_2$å–å€¼ä¸º1æ—¶ï¼Œâ€œstrangerâ€æ¡ä»¶ä¸â€œselfâ€æ¡ä»¶çš„ååº”æ—¶ä¹‹å·®

é€šè¿‡ Treatment ç¼–ç ï¼š

- $\beta_0$ï¼šç›´æ¥è¡¨ç¤ºåŸºå‡†ç»„ï¼ˆselfï¼‰çš„å‡å€¼

- $\beta_1å’Œ\beta_2$ï¼šè¡¨ç¤ºå…¶ä»–æ°´å¹³ç›¸å¯¹äºåŸºå‡†ç»„çš„å·®å¼‚

å¯ä»¥å‘ç°ï¼Œ$\beta_1å’Œ\beta_2$åˆ†åˆ«å¯¹åº”æˆ‘ä»¬æ„Ÿå…´è¶£çš„ä¸¤ä¸ªç ”ç©¶é—®é¢˜ï¼šè‡ªæˆ‘æ¡ä»¶ä¸‹çš„ååº”æ—¶æ˜¯å¦å¿«äºæœ‹å‹ï¼Ÿä»¥åŠè‡ªæˆ‘æ¡ä»¶ä¸‹çš„ååº”æ—¶æ˜¯å¦å¿«äºé™Œç”Ÿäººï¼Ÿ

### æ¨¡å‹æ‹Ÿåˆä¸æ¨æ–­

ç°åœ¨ï¼Œæˆ‘ä»¬æŒ‰ç…§ä¹‹å‰å­¦ä¹ è¿‡çš„workflowæµç¨‹é€æ­¥è¿›è¡Œï¼š

**é€‰æ‹©æ¨¡å‹å’Œæ•°æ®å¤„ç†**

ç”±äºæ¨¡å‹éœ€è¦X1å’ŒX2è¿™ä¸¤ä¸ªå˜é‡ï¼Œå› æ­¤éœ€è¦å…ˆå¯¹è¿™ä¸¤ä¸ªå˜é‡è¿›è¡Œç¼–ç å¤„ç†ï¼š

```python
# å°† Label åˆ—è½¬æ¢ä¸ºæœ‰åºçš„åˆ†ç±»å˜é‡
# éœ€è¦æ³¨æ„ï¼Œâ€˜Labelâ€™åˆ—åŸæœ¬æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œéœ€è¦å…ˆå°†å…¶è½¬æ¢ä¸ºâ€˜categoricalâ€™çš„ç±»åˆ«å˜é‡
df['Label'] = pd.Categorical(df['Label'], categories=['Self', 'Friend', 'Stranger'], ordered=True)

df['Label']
```

```python
# å°†åˆ†ç±»å˜é‡è½¬æ¢ä¸ºå“‘å˜é‡
X1 = (df['Label'] == 'Friend').astype(int)
X2 = (df['Label'] == 'Stranger').astype(int)
```

**å…ˆéªŒè®¾å®šï¼š**

æˆ‘ä»¬éœ€è¦ä¸º$\beta_0$ï¼ˆæˆªè·ï¼‰ï¼Œ$\beta_1,\beta_2$ï¼ˆæ–œç‡ï¼‰ï¼Œä»¥åŠ$\sigma$ï¼ˆè¯¯å·®é¡¹ï¼‰è®¾ç½®å…ˆéªŒåˆ†å¸ƒï¼š

- æˆªè·$\beta_0$ï¼šåŸºçº¿æ°´å¹³ï¼ˆselfï¼‰çš„å‡å€¼

$$
\beta_0 \sim N(5,2^2)
$$

å³ï¼Œå‡è®¾selfæ¡ä»¶ä¸‹çš„å¹³å‡ååº”æ—¶ä¸º5ç§’ï¼Œæ ‡å‡†å·®ä¸º2ï¼Œè¡¨ç¤ºåœ¨3è‡³7ç§’èŒƒå›´å†…æœ‰è¾ƒé«˜çš„æ¦‚ç‡ã€‚

â€”â€”æ³¨æ„ï¼šè¿™é‡Œä¸ºæˆªè·è®¾ç½®çš„å…ˆéªŒæ˜¯ä¸€ä¸ªæ¯”è¾ƒæ¨¡ç³Šçš„å…ˆéªŒï¼Œç›®çš„æ˜¯ä¸ºäº†é¿å…å‡ºç°è´Ÿååº”æ—¶çš„é”™è¯¯å…ˆéªŒï¼Œä½†å®é™…ç ”ç©¶ä¸­è¯¥å…ˆéªŒçš„åˆç†ç¨‹åº¦ä»ç„¶è¾ƒä½ï¼Œæˆ‘ä»¬åé¢å¯ä»¥è€ƒè™‘å¯¹è¯¥å…ˆéªŒè¿›è¡Œæ”¹è¿›ã€‚

- $\beta_1$ï¼šfriendç›¸å¯¹äºselfçš„å‡å€¼å·®å¼‚ï¼›$\beta_2$ï¼šstrangerç›¸å¯¹äºself çš„å‡å€¼å·®å¼‚ã€‚

$$
\beta_1 \sim N(0,1^2) , \beta_2 \sim N(0,1^2)
$$

friendæˆ–strangerç›¸æ¯”äºselfçš„ååº”æ—¶å‡å€¼å·®å¼‚å¤§è‡´åœ¨-1è‡³1çš„åŒºé—´å†…ï¼Œå³å¿«1ç§’æˆ–æ…¢1ç§’ã€‚

- è¯¯å·®é¡¹$\sigma$ï¼šæ•°æ®å›´ç»•é¢„æµ‹å‡å€¼$\mu_i$çš„æ³¢åŠ¨ï¼Œä½¿ç”¨æŒ‡æ•°åˆ†å¸ƒï¼š

$$
\sigma \sim Exp(0.3)
$$

å³ï¼Œå‡è®¾ååº”æ—¶çš„æ³¢åŠ¨é›†ä¸­åœ¨å°èŒƒå›´å†…ï¼Œå…è®¸ä¸­ç­‰ç¨‹åº¦çš„æ³¢åŠ¨ã€‚å¹¶ä¸”ç”±äº$\sigma$æ˜¯ä¸€ä¸ªæ­£å€¼ï¼Œå› æ­¤ä½¿ç”¨æŒ‡æ•°åˆ†å¸ƒã€‚

**å®Œæ•´æ¨¡å‹è®¾å®š**

æ¨¡å‹å¯è¡¨ç¤ºä¸ºï¼š

$$
Y|\beta_0,\beta_1,\beta_2,\sigma \sim N(\mu_i,\sigma^2)ï¼Œ\mu_i=\beta_0+\beta_1Â·X_1+\beta_2Â·X_2
$$

å…ˆéªŒè®¾ç½®ï¼š

- $Y_i \sim N(\mu_i,\sigma^2),\sigma \sim Exp(0.3),\beta_0 \sim N(5,2^2),\beta_1 \sim N(0,1^2) , \beta_2 \sim N(0,1^2)$

å®šä¹‰å›å½’æ¨¡å‹ï¼š

$\mu_i=\beta_0+\beta_1Â·X_1+\beta_2Â·X_2$

æˆ‘ä»¬å¯ä»¥é€šè¿‡ PyMC æ„å»ºè¯¥æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨ MCMC ç®—æ³•è¿›è¡Œé‡‡æ ·:

```python
import pymc as pm

# å»ºç«‹æ¨¡å‹
with pm.Model() as model1:
    # å®šä¹‰å…ˆéªŒåˆ†å¸ƒå‚æ•°
    beta_0 = pm.Normal('beta_0', mu=5, sigma=2)
    beta_1 = pm.Normal('beta_1', mu=0, sigma=1)
    beta_2 = pm.Normal('beta_2', mu=0, sigma=1)
    sigma = pm.Exponential('sigma', lam=0.3)
    
    # çº¿æ€§æ¨¡å‹è¡¨è¾¾å¼
    mu = beta_0 + beta_1 * X1 + beta_2 * X2
    
    # è§‚æµ‹æ•°æ®çš„ä¼¼ç„¶å‡½æ•°
    likelihood = pm.Normal('Y_obs', mu=mu, sigma=sigma, observed=df['RT_sec'])
```

**è¿›è¡ŒåéªŒé‡‡æ ·:**

```python
with model1:
    model1_trace = pm.sample(draws=5000,            # ä½¿ç”¨mcmcæ–¹æ³•è¿›è¡Œé‡‡æ ·ï¼Œdrawsä¸ºé‡‡æ ·æ¬¡æ•°
                      tune=1000,                    # tuneä¸ºè°ƒæ•´é‡‡æ ·ç­–ç•¥çš„æ¬¡æ•°ï¼Œå¯ä»¥å†³å®šè¿™äº›ç»“æœæ˜¯å¦è¦è¢«ä¿ç•™
                      chains=4,                     # é“¾æ•°
                      discard_tuned_samples=True,  # tuneçš„ç»“æœå°†åœ¨é‡‡æ ·ç»“æŸåè¢«ä¸¢å¼ƒ
                      random_seed=84735)           # åéªŒé‡‡æ ·
```

**MCMCè¯Šæ–­å’ŒåéªŒæ¨æ–­**

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`az.summary`å‡½æ•°æ¥æŸ¥çœ‹è¯Šæ–­å’ŒåéªŒæ¨æ–­çš„æ‘˜è¦ã€‚

```python
az.summary(model1_trace)
```

![alt text](image-4.png)

ä½¿ç”¨ ROPE+HDI å¯¹å‚æ•°è¿›è¡Œæ£€éªŒ:

```python
# å®šä¹‰ ROPE åŒºé—´ï¼Œæ ¹æ®ç ”ç©¶çš„éœ€è¦æŒ‡å®šå®é™…ç­‰æ•ˆèŒƒå›´
rope_interval = [-0.05, 0.05]

# ç»˜åˆ¶åéªŒåˆ†å¸ƒï¼Œæ˜¾ç¤º HDI å’Œ ROPE
az.plot_posterior(
    model1_trace,
    var_names=["beta_1", "beta_2"],
    hdi_prob=0.95,
    rope=rope_interval,
    figsize=(9, 3),
    textsize=12
)

plt.show()
```

![alt text](image-5.png)

- ä»ä¸Šå›¾å¯ä»¥çœ‹å‡ºï¼Œ$\beta_1å’Œ\beta_2$å‚æ•°çš„HDIå†…ä¸åŒ…å«0ï¼Œä½†ä¸¤è€…å‡ä¸ROPEé‡å ï¼Œè¡¨æ˜æ•ˆåº”ä¸æ˜æ˜¾ã€‚å¯ä»¥ä½¿ç”¨è´å¶æ–¯å› å­è¿›è¡Œè¿›ä¸€æ­¥å‡è®¾æ£€éªŒã€‚

- æ­¤å¤–ï¼Œ$\beta_1$çš„æ•ˆåº”åœ¨å‡å€¼å’ŒHDIèŒƒå›´å‡å¤§äº$\beta_2$ã€‚

**ä½¿ç”¨è´å¶æ–¯å› å­è¿›è¡Œå·®å¼‚æ£€éªŒ**

```python
# è¿›è¡Œè´å¶æ–¯å› å­è®¡ç®—ï¼Œéœ€è¦é‡‡æ ·å…ˆéªŒåˆ†å¸ƒ
with model1:
    model1_trace.extend(pm.sample_prior_predictive(5000, random_seed=84735) )

fig, axes = plt.subplots(1,2, figsize=(10, 3.5))

# ç»˜åˆ¶è´å¶æ–¯å› å­å›¾
ax = axes[0]
az.plot_bf(model1_trace, var_name="beta_1", ref_val=0, ax=ax)
# è®¾ç½® x è½´çš„èŒƒå›´
ax.set_xlim(-0.5, 0.5) 
ax = axes[1]
az.plot_bf(model1_trace, var_name="beta_2", ref_val=0, ax=ax)
# è®¾ç½® x è½´çš„èŒƒå›´
ax.set_xlim(-0.5, 0.5) 

# å»é™¤ä¸Šæ¡†çº¿å’Œå³æ¡†çº¿
sns.despine()
plt.show()
```

![alt text](image-6.png)

- å¯ä»¥çœ‹å‡ºï¼Œæ— è®ºå¯¹äº$\beta_1è¿˜æ˜¯\beta_2$ï¼Œ$BF_{10}$éƒ½æ¥è¿‘äº1ï¼Œè¡¨æ˜ä¸¤ä¸ªå‚æ•°éƒ½æ²¡æœ‰è¯æ®æ”¯æŒå®ƒä»¬ä¸0æœ‰åŒºåˆ«ã€‚

**åéªŒé¢„æµ‹**

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`pm.sample_posterior_predictive`å‡½æ•°æ¥ç”ŸæˆåéªŒé¢„æµ‹ã€‚

å¹¶é€šè¿‡`az.plot_ppc`å‡½æ•°æ¥ç»˜åˆ¶åéªŒé¢„æµ‹çš„åŸºæœ¬ç»“æœã€‚

```python
with model1:
    model1_ppc = pm.sample_posterior_predictiv(model1_trace, random_seed=84735)
az.plot_ppc(model1_ppc, num_pp_samples = 500)
```

![alt text](image-7.png)

ä»åéªŒé¢„æµ‹å›¾å¯ä»¥çœ‹å‡ºï¼Œå¤§éƒ¨åˆ†æ˜¯æ¯”è¾ƒç¬¦åˆçš„ï¼Œä½†æ¨¡å‹åœ¨æ¯”è¾ƒæç«¯çš„åœ°æ–¹è¡¨ç°å¾—æ²¡é‚£ä¹ˆå¥½ã€‚

ğŸ¤”é‚£ä¹ˆï¼Œæˆ‘ä»¬åœ¨çœŸå®çš„ç ”ç©¶ä¸­ä¹Ÿä¼šé‡åˆ°è¿™ç§æƒ…å†µï¼Œæ­¤æ—¶éœ€è¦æˆ‘ä»¬è¿›è¡Œæƒè¡¡ï¼šï¼ˆ1ï¼‰æ¥å—è¿™ç§ç¨å¾®æ²¡æœ‰é‚£ä¹ˆå®Œç¾çš„æ¨¡å‹ï¼ˆ2ï¼‰åˆ©ç”¨æ›´å¤æ‚çš„æ¨¡å‹æ¥è¿›è¡Œæ›´å®Œç¾çš„æ‹Ÿåˆã€‚

```python
import xarray as xr

# å¯¼å…¥çœŸå®çš„è‡ªå˜é‡
X1 = xr.DataArray((df['Label'] == 'Friend').astype(int))
X2 = xr.DataArray((df['Label'] == 'Stranger').astype(int))

# åŸºäºåéªŒå‚æ•°ç”Ÿæˆy_model
model1_trace.posterior["y_model"] = model1_trace.posterior["beta_0"] + model1_trace.posterior["beta_1"] * X1 + model1_trace.posterior["beta_2"] * X2
df['Mean RT'] = df.groupby('Label')['RT_sec'].transform('mean')

# ç»˜åˆ¶åéªŒé¢„æµ‹çº¿æ€§æ¨¡å‹
az.plot_lm(
           y= df['Mean RT'],
           x= df.Label,
           y_model = model1_trace.posterior["y_model"],
           y_model_mean_kwargs={"color":"black", "linewidth":2},
           figsize=(6,4),
           textsize=16,
           grid=False)

# è®¾ç½®åæ ‡è½´æ ‡é¢˜ã€å­—ä½“å¤§å°
plt.xlim(-0.5, 2.5) 
plt.xticks([0, 1, 2]) 
plt.xlabel('Label')  
plt.ylabel('RT (sec)')  
plt.legend(['observed mean', 'Uncertainty in mean', 'Mean']) 

sns.despine()
```

![alt text](image-8.png)

åœ¨å®é™…çš„è®¤çŸ¥å®éªŒä¸­ï¼Œæˆ‘ä»¬é€šå¸¸è¦çœ‹æ¯ä¸ªæ¡ä»¶ä¸‹çš„å¹³å‡ååº”æ—¶ï¼Œç°åœ¨æˆ‘ä»¬ç”¨ç®±å‹å›¾è¿›è¡Œç»˜åˆ¶ï¼Œå¹¶è§‚å¯Ÿé¢„æµ‹å€¼å’ŒçœŸå®è§‚æµ‹å€¼ä¹‹é—´çš„å·®å¼‚ï¼š

```python
def plot_prediction(df, predicted_y="prediction", ax=None):

    if ax is None:
        fig, ax = plt.subplots(figsize=(5, 4))
    
    sns.boxplot(x='Label', y='RT_sec', hue='Matching', data=df, palette='Set2', ax=ax)

    prediction = df.groupby(["Label", "Matching"])[predicted_y].mean().reset_index()
    # åˆ›å»ºæ˜ å°„å­—å…¸ï¼šLabelåˆ°xä½ç½®
    label_to_x = {'Self': 0, 'Friend': 1, 'Stranger': 2}
    # å°† Label æ˜ å°„åˆ°ç›¸åº”çš„ x å€¼
    prediction['x_position'] = prediction['Label'].map(label_to_x)
    # æ ¹æ® Matching è®¾ç½®åç§»é‡
    prediction['x_offset'] = np.where(prediction['Matching'] == 'matching', -0.2, 0.2)
    # è®¡ç®—æœ€ç»ˆçš„ x ä½ç½®
    prediction['final_x'] = prediction['x_position'].to_numpy() + prediction['x_offset'].to_numpy()

    ax.plot(prediction['final_x'], prediction[predicted_y], marker='o', linestyle='', color='red', label="prediction")
    ax.legend()
```

```python
import xarray as xr

# å¯¼å…¥çœŸå®çš„è‡ªå˜é‡
X1 = xr.DataArray((df['Label'] == 'Friend').astype(int))
X2 = xr.DataArray((df['Label'] == 'Stranger').astype(int))

model1_trace.posterior["y_model"] = model1_trace.posterior["beta_0"] + model1_trace.posterior["beta_1"] * X1 + model1_trace.posterior["beta_2"] * X2

df["model1_prediction"] = model1_trace.posterior.y_model.mean(dim=["chain","draw"]).values
```

```python
plot_prediction(df, "model1_prediction")

# æ˜¾ç¤ºå›¾å½¢
sns.despine()
plt.tight_layout()
plt.show()
```

![alt text](image-9.png)

å¯ä»¥çœ‹åˆ°ï¼Œå½“ä»…è€ƒè™‘â€œLabelâ€æ¡ä»¶æ—¶ï¼Œç”±äºæ²¡æœ‰è€ƒè™‘åˆ°â€œMatchingâ€æ¡ä»¶çš„å½±å“ï¼Œæ¨¡å‹é¢„æµ‹çš„ y å€¼ä¸çœŸå®å€¼å­˜åœ¨è¾ƒå¤§çš„åå·®ã€‚
